{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The storagetransfer1 command-line interface (CLI) allows to use most features of the Google storagetransfer service from the comfort of your terminal. By default all output is printed to standard out, but flags can be set to direct it into a file independent of your shell's capabilities. Errors will be printed to standard error, and cause the program's exit code to be non-zero. If data-structures are requested, these will be returned as pretty-printed JSON, to be useful as input to other tools. Everything else about the storagetransfer API can be found at the official documentation site . Installation and Source Code Install the command-line interface with cargo using: cargo install google-storagetransfer1-cli Find the source code on github . Usage This documentation was generated from the storagetransfer API at revision 20240224 . The CLI is at version 5.0.4 . storagetransfer1 [options] google-service-accounts get <project-id> [-p <v>]... [-o <out>] projects agent-pools-create <project-id> (-r <kv>)... [-p <v>]... [-o <out>] agent-pools-delete <name> [-p <v>]... [-o <out>] agent-pools-get <name> [-p <v>]... [-o <out>] agent-pools-list <project-id> [-p <v>]... [-o <out>] agent-pools-patch <name> (-r <kv>)... [-p <v>]... [-o <out>] transfer-jobs create (-r <kv>)... [-p <v>]... [-o <out>] delete <job-name> <project-id> [-p <v>]... [-o <out>] get <job-name> <project-id> [-p <v>]... [-o <out>] list <filter> [-p <v>]... [-o <out>] patch <job-name> (-r <kv>)... [-p <v>]... [-o <out>] run <job-name> (-r <kv>)... [-p <v>]... [-o <out>] transfer-operations cancel <name> (-r <kv>)... [-p <v>]... [-o <out>] get <name> [-p <v>]... [-o <out>] list <name> <filter> [-p <v>]... [-o <out>] pause <name> (-r <kv>)... [-p <v>]... [-o <out>] resume <name> (-r <kv>)... [-p <v>]... [-o <out>] storagetransfer1 --help Configuration: [--scope <url>]... Specify the authentication a method should be executed in. Each scope requires the user to grant this application permission to use it. If unset, it defaults to the shortest scope url for a particular method. --config-dir <folder> A directory into which we will store our persistent data. Defaults to a user-writable directory that we will create during the first invocation. [default: ~/.google-service-cli] Configuration The program will store all persistent data in the ~/.google-service-cli directory in JSON files prefixed with storagetransfer1- . You can change the directory used to store configuration with the --config-dir flag on a per-invocation basis. More information about the various kinds of persistent data are given in the following paragraphs. Authentication Most APIs require a user to authenticate any request. If this is the case, the scope determines the set of permissions granted. The granularity of these is usually no more than read-only or full-access . If not set, the system will automatically select the smallest feasible scope, e.g. when invoking a method that is read-only, it will ask only for a read-only scope. You may use the --scope flag to specify a scope directly. All applicable scopes are documented in the respective method's CLI documentation. The first time a scope is used, the user is asked for permission. Follow the instructions given by the CLI to grant permissions, or to decline. If a scope was authenticated by the user, the respective information will be stored as JSON in the configuration directory, e.g. ~/.google-service-cli/storagetransfer1-token-<scope-hash>.json . No manual management of these tokens is necessary. To revoke granted authentication, please refer to the official documentation . Application Secrets In order to allow any application to use Google services, it will need to be registered using the Google Developer Console . APIs the application may use are then enabled for it one by one. Most APIs can be used for free and have a daily quota. To allow more comfortable usage of the CLI without forcing anyone to register an own application, the CLI comes with a default application secret that is configured accordingly. This also means that heavy usage all around the world may deplete the daily quota. You can workaround this limitation by putting your own secrets file at this location: ~/.google-service-cli/storagetransfer1-secret.json , assuming that the required storagetransfer API was enabled for it. Such a secret file can be downloaded in the Google Developer Console at APIs & auth -> Credentials -> Download JSON and used as is. Learn more about how to setup Google projects and enable APIs using the official documentation . Debugging Even though the CLI does its best to provide usable error messages, sometimes it might be desirable to know what exactly led to a particular issue. This is done by allowing all client-server communication to be output to standard error as-is . The --debug flag will print errors using the Debug representation to standard error. You may consider redirecting standard error into a file for ease of use, e.g. storagetransfer1 --debug <resource> <method> [options] 2>debug.txt .","title":"Home"},{"location":"#installation-and-source-code","text":"Install the command-line interface with cargo using: cargo install google-storagetransfer1-cli Find the source code on github .","title":"Installation and Source Code"},{"location":"#usage","text":"This documentation was generated from the storagetransfer API at revision 20240224 . The CLI is at version 5.0.4 . storagetransfer1 [options] google-service-accounts get <project-id> [-p <v>]... [-o <out>] projects agent-pools-create <project-id> (-r <kv>)... [-p <v>]... [-o <out>] agent-pools-delete <name> [-p <v>]... [-o <out>] agent-pools-get <name> [-p <v>]... [-o <out>] agent-pools-list <project-id> [-p <v>]... [-o <out>] agent-pools-patch <name> (-r <kv>)... [-p <v>]... [-o <out>] transfer-jobs create (-r <kv>)... [-p <v>]... [-o <out>] delete <job-name> <project-id> [-p <v>]... [-o <out>] get <job-name> <project-id> [-p <v>]... [-o <out>] list <filter> [-p <v>]... [-o <out>] patch <job-name> (-r <kv>)... [-p <v>]... [-o <out>] run <job-name> (-r <kv>)... [-p <v>]... [-o <out>] transfer-operations cancel <name> (-r <kv>)... [-p <v>]... [-o <out>] get <name> [-p <v>]... [-o <out>] list <name> <filter> [-p <v>]... [-o <out>] pause <name> (-r <kv>)... [-p <v>]... [-o <out>] resume <name> (-r <kv>)... [-p <v>]... [-o <out>] storagetransfer1 --help Configuration: [--scope <url>]... Specify the authentication a method should be executed in. Each scope requires the user to grant this application permission to use it. If unset, it defaults to the shortest scope url for a particular method. --config-dir <folder> A directory into which we will store our persistent data. Defaults to a user-writable directory that we will create during the first invocation. [default: ~/.google-service-cli]","title":"Usage"},{"location":"#configuration","text":"The program will store all persistent data in the ~/.google-service-cli directory in JSON files prefixed with storagetransfer1- . You can change the directory used to store configuration with the --config-dir flag on a per-invocation basis. More information about the various kinds of persistent data are given in the following paragraphs.","title":"Configuration"},{"location":"#authentication","text":"Most APIs require a user to authenticate any request. If this is the case, the scope determines the set of permissions granted. The granularity of these is usually no more than read-only or full-access . If not set, the system will automatically select the smallest feasible scope, e.g. when invoking a method that is read-only, it will ask only for a read-only scope. You may use the --scope flag to specify a scope directly. All applicable scopes are documented in the respective method's CLI documentation. The first time a scope is used, the user is asked for permission. Follow the instructions given by the CLI to grant permissions, or to decline. If a scope was authenticated by the user, the respective information will be stored as JSON in the configuration directory, e.g. ~/.google-service-cli/storagetransfer1-token-<scope-hash>.json . No manual management of these tokens is necessary. To revoke granted authentication, please refer to the official documentation .","title":"Authentication"},{"location":"#application-secrets","text":"In order to allow any application to use Google services, it will need to be registered using the Google Developer Console . APIs the application may use are then enabled for it one by one. Most APIs can be used for free and have a daily quota. To allow more comfortable usage of the CLI without forcing anyone to register an own application, the CLI comes with a default application secret that is configured accordingly. This also means that heavy usage all around the world may deplete the daily quota. You can workaround this limitation by putting your own secrets file at this location: ~/.google-service-cli/storagetransfer1-secret.json , assuming that the required storagetransfer API was enabled for it. Such a secret file can be downloaded in the Google Developer Console at APIs & auth -> Credentials -> Download JSON and used as is. Learn more about how to setup Google projects and enable APIs using the official documentation .","title":"Application Secrets"},{"location":"#debugging","text":"Even though the CLI does its best to provide usable error messages, sometimes it might be desirable to know what exactly led to a particular issue. This is done by allowing all client-server communication to be output to standard error as-is . The --debug flag will print errors using the Debug representation to standard error. You may consider redirecting standard error into a file for ease of use, e.g. storagetransfer1 --debug <resource> <method> [options] 2>debug.txt .","title":"Debugging"},{"location":"google-service-accounts_get/","text":"Returns the Google service account that is used by Storage Transfer Service to access buckets in the project where transfers run or in other projects. Each Google service account is associated with one Google Cloud project. Users should add this service account to the Google Cloud Storage bucket ACLs to grant access to Storage Transfer Service. This service account is created and owned by Storage Transfer Service and can only be used by Storage Transfer Service. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> google-service-accounts get ... Required Scalar Argument <project-id> (string) Required. The ID of the Google Cloud project that the Google service account is associated with. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Get"},{"location":"google-service-accounts_get/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> google-service-accounts get ...","title":"Scopes"},{"location":"google-service-accounts_get/#required-scalar-argument","text":"<project-id> (string) Required. The ID of the Google Cloud project that the Google service account is associated with.","title":"Required Scalar Argument"},{"location":"google-service-accounts_get/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"google-service-accounts_get/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_agent-pools-create/","text":"Creates an agent pool resource. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> projects agent-pools-create ... Required Scalar Argument <project-id> (string) Required. The ID of the Google Cloud project that owns the agent pool. Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: AgentPool: bandwidth-limit: limit-mbps: string display-name: string name: string state: string can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r .bandwidth-limit limit-mbps=et Bandwidth rate in megabytes per second, distributed across all the agents in the pool. .. display-name=magna Specifies the client-specified AgentPool description. name=no Required. Specifies a unique string that identifies the agent pool. Format: projects/{project_id}/agentPools/{agent_pool_id} state=ipsum Output only. Specifies the state of the AgentPool. About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional Method Properties You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p agent-pool-id=string Required. The ID of the agent pool to create. The agent_pool_id must meet the following requirements: * Length of 128 characters or less. * Not start with the string goog . * Start with a lowercase ASCII character, followed by: * Zero or more: lowercase Latin alphabet characters, numerals, hyphens ( - ), periods ( . ), underscores ( _ ), or tildes ( ~ ). * One or more numerals or lowercase ASCII characters. As expressed by the regular expression: ^(?!goog)[a-z]([a-z0-9-._~]*[a-z0-9])?$ . Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Agent Pools Create"},{"location":"projects_agent-pools-create/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> projects agent-pools-create ...","title":"Scopes"},{"location":"projects_agent-pools-create/#required-scalar-argument","text":"<project-id> (string) Required. The ID of the Google Cloud project that owns the agent pool.","title":"Required Scalar Argument"},{"location":"projects_agent-pools-create/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: AgentPool: bandwidth-limit: limit-mbps: string display-name: string name: string state: string can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r .bandwidth-limit limit-mbps=et Bandwidth rate in megabytes per second, distributed across all the agents in the pool. .. display-name=magna Specifies the client-specified AgentPool description. name=no Required. Specifies a unique string that identifies the agent pool. Format: projects/{project_id}/agentPools/{agent_pool_id} state=ipsum Output only. Specifies the state of the AgentPool.","title":"Required Request Value"},{"location":"projects_agent-pools-create/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"projects_agent-pools-create/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_agent-pools-create/#optional-method-properties","text":"You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p agent-pool-id=string Required. The ID of the agent pool to create. The agent_pool_id must meet the following requirements: * Length of 128 characters or less. * Not start with the string goog . * Start with a lowercase ASCII character, followed by: * Zero or more: lowercase Latin alphabet characters, numerals, hyphens ( - ), periods ( . ), underscores ( _ ), or tildes ( ~ ). * One or more numerals or lowercase ASCII characters. As expressed by the regular expression: ^(?!goog)[a-z]([a-z0-9-._~]*[a-z0-9])?$ .","title":"Optional Method Properties"},{"location":"projects_agent-pools-create/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_agent-pools-delete/","text":"Deletes an agent pool. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> projects agent-pools-delete ... Required Scalar Argument <name> (string) Required. The name of the agent pool to delete. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Agent Pools Delete"},{"location":"projects_agent-pools-delete/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> projects agent-pools-delete ...","title":"Scopes"},{"location":"projects_agent-pools-delete/#required-scalar-argument","text":"<name> (string) Required. The name of the agent pool to delete.","title":"Required Scalar Argument"},{"location":"projects_agent-pools-delete/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_agent-pools-delete/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_agent-pools-get/","text":"Gets an agent pool. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> projects agent-pools-get ... Required Scalar Argument <name> (string) Required. The name of the agent pool to get. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Agent Pools Get"},{"location":"projects_agent-pools-get/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> projects agent-pools-get ...","title":"Scopes"},{"location":"projects_agent-pools-get/#required-scalar-argument","text":"<name> (string) Required. The name of the agent pool to get.","title":"Required Scalar Argument"},{"location":"projects_agent-pools-get/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_agent-pools-get/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_agent-pools-list/","text":"Lists agent pools. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> projects agent-pools-list ... Required Scalar Argument <project-id> (string) Required. The ID of the Google Cloud project that owns the job. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional Method Properties You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p filter=string An optional list of query parameters specified as JSON text in the form of: {&#34;agentPoolNames&#34;:[&#34;agentpool1&#34;,&#34;agentpool2&#34;,...]} Since agentPoolNames support multiple values, its values must be specified with array notation. When the filter is either empty or not provided, the list returns all agent pools for the project. -p page-size=integer The list page size. The max allowed value is 256 . -p page-token=string The list page token. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Agent Pools List"},{"location":"projects_agent-pools-list/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> projects agent-pools-list ...","title":"Scopes"},{"location":"projects_agent-pools-list/#required-scalar-argument","text":"<project-id> (string) Required. The ID of the Google Cloud project that owns the job.","title":"Required Scalar Argument"},{"location":"projects_agent-pools-list/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_agent-pools-list/#optional-method-properties","text":"You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p filter=string An optional list of query parameters specified as JSON text in the form of: {&#34;agentPoolNames&#34;:[&#34;agentpool1&#34;,&#34;agentpool2&#34;,...]} Since agentPoolNames support multiple values, its values must be specified with array notation. When the filter is either empty or not provided, the list returns all agent pools for the project. -p page-size=integer The list page size. The max allowed value is 256 . -p page-token=string The list page token.","title":"Optional Method Properties"},{"location":"projects_agent-pools-list/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_agent-pools-patch/","text":"Updates an existing agent pool resource. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> projects agent-pools-patch ... Required Scalar Argument <name> (string) Required. Specifies a unique string that identifies the agent pool. Format: projects/{project_id}/agentPools/{agent_pool_id} Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: AgentPool: bandwidth-limit: limit-mbps: string display-name: string name: string state: string can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r .bandwidth-limit limit-mbps=voluptua. Bandwidth rate in megabytes per second, distributed across all the agents in the pool. .. display-name=at Specifies the client-specified AgentPool description. name=sanctus Required. Specifies a unique string that identifies the agent pool. Format: projects/{project_id}/agentPools/{agent_pool_id} state=sed Output only. Specifies the state of the AgentPool. About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional Method Properties You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p update-mask=string The [field mask] (https://developers.google.com/protocol-buffers/docs/reference/google.protobuf) of the fields in agentPool to update in this request. The following agentPool fields can be updated: * display_name * bandwidth_limit Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Agent Pools Patch"},{"location":"projects_agent-pools-patch/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> projects agent-pools-patch ...","title":"Scopes"},{"location":"projects_agent-pools-patch/#required-scalar-argument","text":"<name> (string) Required. Specifies a unique string that identifies the agent pool. Format: projects/{project_id}/agentPools/{agent_pool_id}","title":"Required Scalar Argument"},{"location":"projects_agent-pools-patch/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: AgentPool: bandwidth-limit: limit-mbps: string display-name: string name: string state: string can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r .bandwidth-limit limit-mbps=voluptua. Bandwidth rate in megabytes per second, distributed across all the agents in the pool. .. display-name=at Specifies the client-specified AgentPool description. name=sanctus Required. Specifies a unique string that identifies the agent pool. Format: projects/{project_id}/agentPools/{agent_pool_id} state=sed Output only. Specifies the state of the AgentPool.","title":"Required Request Value"},{"location":"projects_agent-pools-patch/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"projects_agent-pools-patch/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_agent-pools-patch/#optional-method-properties","text":"You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p update-mask=string The [field mask] (https://developers.google.com/protocol-buffers/docs/reference/google.protobuf) of the fields in agentPool to update in this request. The following agentPool fields can be updated: * display_name * bandwidth_limit","title":"Optional Method Properties"},{"location":"projects_agent-pools-patch/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"transfer-jobs_create/","text":"Creates a transfer job that runs periodically. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> transfer-jobs create ... Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: TransferJob: creation-time: string deletion-time: string description: string event-stream: event-stream-expiration-time: string event-stream-start-time: string name: string last-modification-time: string latest-operation-name: string logging-config: enable-onprem-gcs-transfer-logs: boolean log-action-states: [string] log-actions: [string] name: string notification-config: event-types: [string] payload-format: string pubsub-topic: string project-id: string schedule: end-time-of-day: hours: integer minutes: integer nanos: integer seconds: integer repeat-interval: string schedule-end-date: day: integer month: integer year: integer schedule-start-date: day: integer month: integer year: integer start-time-of-day: hours: integer minutes: integer nanos: integer seconds: integer status: string transfer-spec: aws-s3-compatible-data-source: bucket-name: string endpoint: string path: string region: string s3-metadata: auth-method: string list-api: string protocol: string request-model: string aws-s3-data-source: aws-access-key: access-key-id: string secret-access-key: string bucket-name: string cloudfront-domain: string credentials-secret: string path: string role-arn: string azure-blob-storage-data-source: azure-credentials: sas-token: string container: string credentials-secret: string path: string storage-account: string gcs-data-sink: bucket-name: string managed-folder-transfer-enabled: boolean path: string gcs-data-source: bucket-name: string managed-folder-transfer-enabled: boolean path: string gcs-intermediate-data-location: bucket-name: string managed-folder-transfer-enabled: boolean path: string hdfs-data-source: path: string http-data-source: list-url: string object-conditions: exclude-prefixes: [string] include-prefixes: [string] last-modified-before: string last-modified-since: string max-time-elapsed-since-last-modification: string min-time-elapsed-since-last-modification: string posix-data-sink: root-directory: string posix-data-source: root-directory: string sink-agent-pool-name: string source-agent-pool-name: string transfer-manifest: location: string transfer-options: delete-objects-from-source-after-transfer: boolean delete-objects-unique-in-sink: boolean metadata-options: acl: string gid: string kms-key: string mode: string storage-class: string symlink: string temporary-hold: string time-created: string uid: string overwrite-objects-already-existing-in-sink: boolean overwrite-when: string can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r . creation-time=amet. Output only. The time that the transfer job was created. deletion-time=takimata Output only. The time that the transfer job was deleted. description=amet. A description provided by the user for the job. Its max length is 1024 bytes when Unicode-encoded. event-stream event-stream-expiration-time=duo Specifies the data and time at which Storage Transfer Service stops listening for events from this stream. After this time, any transfers in progress will complete, but no new transfers are initiated. event-stream-start-time=ipsum Specifies the date and time that Storage Transfer Service starts listening for events from this stream. If no start time is specified or start time is in the past, Storage Transfer Service starts listening immediately. name=gubergren Required. Specifies a unique name of the resource such as AWS SQS ARN in the form 'arn:aws:sqs:region:account_id:queue_name', or Pub/Sub subscription resource name in the form 'projects/{project}/subscriptions/{sub}'. .. last-modification-time=lorem Output only. The time that the transfer job was last modified. latest-operation-name=gubergren The name of the most recently started TransferOperation of this JobConfig. Present if a TransferOperation has been created for this JobConfig. logging-config enable-onprem-gcs-transfer-logs=false For transfers with a PosixFilesystem source, this option enables the Cloud Storage transfer logs for this transfer. log-action-states=dolor States in which log_actions are logged. If empty, no logs are generated. Not supported for transfers with PosixFilesystem data sources; use enable_onprem_gcs_transfer_logs instead. Each invocation of this argument appends the given value to the array. log-actions=ea Specifies the actions to be logged. If empty, no logs are generated. Not supported for transfers with PosixFilesystem data sources; use enable_onprem_gcs_transfer_logs instead. Each invocation of this argument appends the given value to the array. .. name=ipsum A unique name (within the transfer project) assigned when the job is created. If this field is empty in a CreateTransferJobRequest, Storage Transfer Service assigns a unique name. Otherwise, the specified name is used as the unique name for this job. If the specified name is in use by a job, the creation request fails with an ALREADY_EXISTS error. This name must start with &#34;transferJobs/&#34; prefix and end with a letter or a number, and should be no more than 128 characters. For transfers involving PosixFilesystem, this name must start with transferJobs/OPI specifically. For all other transfer types, this name must not start with transferJobs/OPI . Non-PosixFilesystem example: &#34;transferJobs/^(?!OPI)[A-Za-z0-9-._~]*[A-Za-z0-9]$&#34; PosixFilesystem example: &#34;transferJobs/OPI^[A-Za-z0-9-._~]*[A-Za-z0-9]$&#34; Applications must not rely on the enforcement of naming requirements involving OPI. Invalid job names fail with an INVALID_ARGUMENT error. notification-config event-types=invidunt Event types for which a notification is desired. If empty, send notifications for all event types. Each invocation of this argument appends the given value to the array. payload-format=amet Required. The desired format of the notification message payloads. pubsub-topic=duo Required. The Topic.name of the Pub/Sub topic to which to publish notifications. Must be of the format: projects/{project}/topics/{topic} . Not matching this format results in an INVALID_ARGUMENT error. .. project-id=ipsum The ID of the Google Cloud project that owns the job. schedule.end-time-of-day hours=8 Hours of day in 24 hour format. Should be from 0 to 23. An API may choose to allow the value \"24:00:00\" for scenarios like business closing time. minutes=64 Minutes of hour of day. Must be from 0 to 59. nanos=89 Fractions of seconds in nanoseconds. Must be from 0 to 999,999,999. seconds=85 Seconds of minutes of the time. Must normally be from 0 to 59. An API may allow the value 60 if it allows leap-seconds. .. repeat-interval=est Interval between the start of each scheduled TransferOperation. If unspecified, the default value is 24 hours. This value may not be less than 1 hour. schedule-end-date day=51 Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant. month=51 Month of a year. Must be from 1 to 12, or 0 to specify a year without a month and day. year=94 Year of the date. Must be from 1 to 9999, or 0 to specify a date without a year. ..schedule-start-date day=39 Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant. month=84 Month of a year. Must be from 1 to 12, or 0 to specify a year without a month and day. year=2 Year of the date. Must be from 1 to 9999, or 0 to specify a date without a year. ..start-time-of-day hours=45 Hours of day in 24 hour format. Should be from 0 to 23. An API may choose to allow the value \"24:00:00\" for scenarios like business closing time. minutes=76 Minutes of hour of day. Must be from 0 to 59. nanos=15 Fractions of seconds in nanoseconds. Must be from 0 to 999,999,999. seconds=58 Seconds of minutes of the time. Must normally be from 0 to 59. An API may allow the value 60 if it allows leap-seconds. ... status=duo Status of the job. This value MUST be specified for CreateTransferJobRequests . Note: The effect of the new job status takes place during a subsequent job run. For example, if you change the job status from ENABLED to DISABLED, and an operation spawned by the transfer is running, the status change would not affect the current operation. transfer-spec.aws-s3-compatible-data-source bucket-name=sed Required. Specifies the name of the bucket. endpoint=no Required. Specifies the endpoint of the storage service. path=stet Specifies the root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'. region=kasd Specifies the region to sign requests with. This can be left blank if requests should be signed with an empty region. s3-metadata auth-method=et Specifies the authentication and authorization method used by the storage service. When not specified, Transfer Service will attempt to determine right auth method to use. list-api=sed The Listing API to use for discovering objects. When not specified, Transfer Service will attempt to determine the right API to use. protocol=et Specifies the network protocol of the agent. When not specified, the default value of NetworkProtocol NETWORK_PROTOCOL_HTTPS is used. request-model=et Specifies the API request model used to call the storage service. When not specified, the default value of RequestModel REQUEST_MODEL_VIRTUAL_HOSTED_STYLE is used. ...aws-s3-data-source.aws-access-key access-key-id=vero Required. AWS access key ID. secret-access-key=erat Required. AWS secret access key. This field is not returned in RPC responses. .. bucket-name=sed Required. S3 Bucket name (see Creating a bucket ). cloudfront-domain=duo Optional. Cloudfront domain name pointing to this bucket (as origin), to use when fetching. Format: https://{id}.cloudfront.net or any valid custom domain https://... credentials-secret=dolore Optional. The Resource name of a secret in Secret Manager. AWS credentials must be stored in Secret Manager in JSON format: { \"access_key_id\": \"ACCESS_KEY_ID\", \"secret_access_key\": \"SECRET_ACCESS_KEY\" } GoogleServiceAccount must be granted roles/secretmanager.secretAccessor for the resource. See [Configure access to a source: Amazon S3] (https://cloud.google.com/storage-transfer/docs/source-amazon-s3#secret_manager) for more information. If credentials_secret is specified, do not specify role_arn or aws_access_key. This feature is in preview . Format: projects/{project_number}/secrets/{secret_name} path=et Root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'. role-arn=voluptua. The Amazon Resource Name (ARN) of the role to support temporary credentials via AssumeRoleWithWebIdentity . For more information about ARNs, see IAM ARNs . When a role ARN is provided, Transfer Service fetches temporary credentials for the session using a AssumeRoleWithWebIdentity call for the provided role using the GoogleServiceAccount for this project. ..azure-blob-storage-data-source.azure-credentials sas-token=amet. Required. Azure shared access signature (SAS). For more information about SAS, see Grant limited access to Azure Storage resources using shared access signatures (SAS) . .. container=consetetur Required. The container to transfer from the Azure Storage account. credentials-secret=diam Optional. The Resource name of a secret in Secret Manager. The Azure SAS token must be stored in Secret Manager in JSON format: { \"sas_token\" : \"SAS_TOKEN\" } GoogleServiceAccount must be granted roles/secretmanager.secretAccessor for the resource. See [Configure access to a source: Microsoft Azure Blob Storage] (https://cloud.google.com/storage-transfer/docs/source-microsoft-azure#secret_manager) for more information. If credentials_secret is specified, do not specify azure_credentials. This feature is in preview . Format: projects/{project_number}/secrets/{secret_name} path=dolor Root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'. storage-account=et Required. The name of the Azure Storage account. ..gcs-data-sink bucket-name=et Required. Cloud Storage bucket name. Must meet Bucket Name Requirements . managed-folder-transfer-enabled=false Transfer managed folders is in public preview. This option is only applicable to the Cloud Storage source bucket. If set to true: - The source managed folder will be transferred to the destination bucket - The destination managed folder will always be overwritten, other OVERWRITE options will not be supported path=stet Root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'. The root path value must meet Object Name Requirements . ..gcs-data-source bucket-name=dolor Required. Cloud Storage bucket name. Must meet Bucket Name Requirements . managed-folder-transfer-enabled=false Transfer managed folders is in public preview. This option is only applicable to the Cloud Storage source bucket. If set to true: - The source managed folder will be transferred to the destination bucket - The destination managed folder will always be overwritten, other OVERWRITE options will not be supported path=vero Root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'. The root path value must meet Object Name Requirements . ..gcs-intermediate-data-location bucket-name=invidunt Required. Cloud Storage bucket name. Must meet Bucket Name Requirements . managed-folder-transfer-enabled=true Transfer managed folders is in public preview. This option is only applicable to the Cloud Storage source bucket. If set to true: - The source managed folder will be transferred to the destination bucket - The destination managed folder will always be overwritten, other OVERWRITE options will not be supported path=vero Root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'. The root path value must meet Object Name Requirements . ..hdfs-data-source path=elitr Root path to transfer files. ..http-data-source list-url=lorem Required. The URL that points to the file that stores the object list entries. This file must allow public access. Currently, only URLs with HTTP and HTTPS schemes are supported. ..object-conditions exclude-prefixes=diam If you specify exclude_prefixes , Storage Transfer Service uses the items in the exclude_prefixes array to determine which objects to exclude from a transfer. Objects must not start with one of the matching exclude_prefixes for inclusion in a transfer. The following are requirements of exclude_prefixes : * Each exclude-prefix can contain any sequence of Unicode characters, to a max length of 1024 bytes when UTF8-encoded, and must not contain Carriage Return or Line Feed characters. Wildcard matching and regular expression matching are not supported. * Each exclude-prefix must omit the leading slash. For example, to exclude the object s3://my-aws-bucket/logs/y=2015/requests.gz , specify the exclude-prefix as logs/y=2015/requests.gz . * None of the exclude-prefix values can be empty, if specified. * Each exclude-prefix must exclude a distinct portion of the object namespace. No exclude-prefix may be a prefix of another exclude-prefix. * If include_prefixes is specified, then each exclude-prefix must start with the value of a path explicitly included by include_prefixes . The max size of exclude_prefixes is 1000. For more information, see Filtering objects from transfers . Each invocation of this argument appends the given value to the array. include-prefixes=no If you specify include_prefixes , Storage Transfer Service uses the items in the include_prefixes array to determine which objects to include in a transfer. Objects must start with one of the matching include_prefixes for inclusion in the transfer. If exclude_prefixes is specified, objects must not start with any of the exclude_prefixes specified for inclusion in the transfer. The following are requirements of include_prefixes : * Each include-prefix can contain any sequence of Unicode characters, to a max length of 1024 bytes when UTF8-encoded, and must not contain Carriage Return or Line Feed characters. Wildcard matching and regular expression matching are not supported. * Each include-prefix must omit the leading slash. For example, to include the object s3://my-aws-bucket/logs/y=2015/requests.gz , specify the include-prefix as logs/y=2015/requests.gz . * None of the include-prefix values can be empty, if specified. * Each include-prefix must include a distinct portion of the object namespace. No include-prefix may be a prefix of another include-prefix. The max size of include_prefixes is 1000. For more information, see Filtering objects from transfers . Each invocation of this argument appends the given value to the array. last-modified-before=ipsum If specified, only objects with a \"last modification time\" before this timestamp and objects that don't have a \"last modification time\" are transferred. last-modified-since=accusam If specified, only objects with a \"last modification time\" on or after this timestamp and objects that don't have a \"last modification time\" are transferred. The last_modified_since and last_modified_before fields can be used together for chunked data processing. For example, consider a script that processes each day's worth of data at a time. For that you'd set each of the fields as follows: * last_modified_since to the start of the day * last_modified_before to the end of the day max-time-elapsed-since-last-modification=takimata Ensures that objects are not transferred if a specific maximum time has elapsed since the \"last modification time\". When a TransferOperation begins, objects with a \"last modification time\" are transferred only if the elapsed time between the start_time of the TransferOperation and the \"last modification time\" of the object is less than the value of max_time_elapsed_since_last_modification`. Objects that do not have a \"last modification time\" are also transferred. min-time-elapsed-since-last-modification=consetetur Ensures that objects are not transferred until a specific minimum time has elapsed after the \"last modification time\". When a TransferOperation begins, objects with a \"last modification time\" are transferred only if the elapsed time between the start_time of the TransferOperation and the \"last modification time\" of the object is equal to or greater than the value of min_time_elapsed_since_last_modification`. Objects that do not have a \"last modification time\" are also transferred. ..posix-data-sink root-directory=voluptua. Root directory path to the filesystem. ..posix-data-source root-directory=et Root directory path to the filesystem. .. sink-agent-pool-name=erat Specifies the agent pool name associated with the posix data sink. When unspecified, the default name is used. source-agent-pool-name=consetetur Specifies the agent pool name associated with the posix data source. When unspecified, the default name is used. transfer-manifest location=amet. Specifies the path to the manifest in Cloud Storage. The Google-managed service account for the transfer must have storage.objects.get permission for this object. An example path is gs://bucket_name/path/manifest.csv . ..transfer-options delete-objects-from-source-after-transfer=true Whether objects should be deleted from the source after they are transferred to the sink. Note: This option and delete_objects_unique_in_sink are mutually exclusive. delete-objects-unique-in-sink=false Whether objects that exist only in the sink should be deleted. Note: This option and delete_objects_from_source_after_transfer are mutually exclusive. metadata-options acl=accusam Specifies how each object's ACLs should be preserved for transfers between Google Cloud Storage buckets. If unspecified, the default behavior is the same as ACL_DESTINATION_BUCKET_DEFAULT. gid=voluptua. Specifies how each file's POSIX group ID (GID) attribute should be handled by the transfer. By default, GID is not preserved. Only applicable to transfers involving POSIX file systems, and ignored for other transfers. kms-key=dolore Specifies how each object's Cloud KMS customer-managed encryption key (CMEK) is preserved for transfers between Google Cloud Storage buckets. If unspecified, the default behavior is the same as KMS_KEY_DESTINATION_BUCKET_DEFAULT. mode=dolore Specifies how each file's mode attribute should be handled by the transfer. By default, mode is not preserved. Only applicable to transfers involving POSIX file systems, and ignored for other transfers. storage-class=dolore Specifies the storage class to set on objects being transferred to Google Cloud Storage buckets. If unspecified, the default behavior is the same as STORAGE_CLASS_DESTINATION_BUCKET_DEFAULT. symlink=voluptua. Specifies how symlinks should be handled by the transfer. By default, symlinks are not preserved. Only applicable to transfers involving POSIX file systems, and ignored for other transfers. temporary-hold=amet. Specifies how each object's temporary hold status should be preserved for transfers between Google Cloud Storage buckets. If unspecified, the default behavior is the same as TEMPORARY_HOLD_PRESERVE. time-created=ea Specifies how each object's timeCreated metadata is preserved for transfers. If unspecified, the default behavior is the same as TIME_CREATED_SKIP. uid=sadipscing Specifies how each file's POSIX user ID (UID) attribute should be handled by the transfer. By default, UID is not preserved. Only applicable to transfers involving POSIX file systems, and ignored for other transfers. .. overwrite-objects-already-existing-in-sink=true When to overwrite objects that already exist in the sink. The default is that only objects that are different from the source are ovewritten. If true, all objects in the sink whose name matches an object in the source are overwritten with the source object. overwrite-when=no When to overwrite objects that already exist in the sink. If not set, overwrite behavior is determined by overwrite_objects_already_existing_in_sink. About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Create"},{"location":"transfer-jobs_create/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> transfer-jobs create ...","title":"Scopes"},{"location":"transfer-jobs_create/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: TransferJob: creation-time: string deletion-time: string description: string event-stream: event-stream-expiration-time: string event-stream-start-time: string name: string last-modification-time: string latest-operation-name: string logging-config: enable-onprem-gcs-transfer-logs: boolean log-action-states: [string] log-actions: [string] name: string notification-config: event-types: [string] payload-format: string pubsub-topic: string project-id: string schedule: end-time-of-day: hours: integer minutes: integer nanos: integer seconds: integer repeat-interval: string schedule-end-date: day: integer month: integer year: integer schedule-start-date: day: integer month: integer year: integer start-time-of-day: hours: integer minutes: integer nanos: integer seconds: integer status: string transfer-spec: aws-s3-compatible-data-source: bucket-name: string endpoint: string path: string region: string s3-metadata: auth-method: string list-api: string protocol: string request-model: string aws-s3-data-source: aws-access-key: access-key-id: string secret-access-key: string bucket-name: string cloudfront-domain: string credentials-secret: string path: string role-arn: string azure-blob-storage-data-source: azure-credentials: sas-token: string container: string credentials-secret: string path: string storage-account: string gcs-data-sink: bucket-name: string managed-folder-transfer-enabled: boolean path: string gcs-data-source: bucket-name: string managed-folder-transfer-enabled: boolean path: string gcs-intermediate-data-location: bucket-name: string managed-folder-transfer-enabled: boolean path: string hdfs-data-source: path: string http-data-source: list-url: string object-conditions: exclude-prefixes: [string] include-prefixes: [string] last-modified-before: string last-modified-since: string max-time-elapsed-since-last-modification: string min-time-elapsed-since-last-modification: string posix-data-sink: root-directory: string posix-data-source: root-directory: string sink-agent-pool-name: string source-agent-pool-name: string transfer-manifest: location: string transfer-options: delete-objects-from-source-after-transfer: boolean delete-objects-unique-in-sink: boolean metadata-options: acl: string gid: string kms-key: string mode: string storage-class: string symlink: string temporary-hold: string time-created: string uid: string overwrite-objects-already-existing-in-sink: boolean overwrite-when: string can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r . creation-time=amet. Output only. The time that the transfer job was created. deletion-time=takimata Output only. The time that the transfer job was deleted. description=amet. A description provided by the user for the job. Its max length is 1024 bytes when Unicode-encoded. event-stream event-stream-expiration-time=duo Specifies the data and time at which Storage Transfer Service stops listening for events from this stream. After this time, any transfers in progress will complete, but no new transfers are initiated. event-stream-start-time=ipsum Specifies the date and time that Storage Transfer Service starts listening for events from this stream. If no start time is specified or start time is in the past, Storage Transfer Service starts listening immediately. name=gubergren Required. Specifies a unique name of the resource such as AWS SQS ARN in the form 'arn:aws:sqs:region:account_id:queue_name', or Pub/Sub subscription resource name in the form 'projects/{project}/subscriptions/{sub}'. .. last-modification-time=lorem Output only. The time that the transfer job was last modified. latest-operation-name=gubergren The name of the most recently started TransferOperation of this JobConfig. Present if a TransferOperation has been created for this JobConfig. logging-config enable-onprem-gcs-transfer-logs=false For transfers with a PosixFilesystem source, this option enables the Cloud Storage transfer logs for this transfer. log-action-states=dolor States in which log_actions are logged. If empty, no logs are generated. Not supported for transfers with PosixFilesystem data sources; use enable_onprem_gcs_transfer_logs instead. Each invocation of this argument appends the given value to the array. log-actions=ea Specifies the actions to be logged. If empty, no logs are generated. Not supported for transfers with PosixFilesystem data sources; use enable_onprem_gcs_transfer_logs instead. Each invocation of this argument appends the given value to the array. .. name=ipsum A unique name (within the transfer project) assigned when the job is created. If this field is empty in a CreateTransferJobRequest, Storage Transfer Service assigns a unique name. Otherwise, the specified name is used as the unique name for this job. If the specified name is in use by a job, the creation request fails with an ALREADY_EXISTS error. This name must start with &#34;transferJobs/&#34; prefix and end with a letter or a number, and should be no more than 128 characters. For transfers involving PosixFilesystem, this name must start with transferJobs/OPI specifically. For all other transfer types, this name must not start with transferJobs/OPI . Non-PosixFilesystem example: &#34;transferJobs/^(?!OPI)[A-Za-z0-9-._~]*[A-Za-z0-9]$&#34; PosixFilesystem example: &#34;transferJobs/OPI^[A-Za-z0-9-._~]*[A-Za-z0-9]$&#34; Applications must not rely on the enforcement of naming requirements involving OPI. Invalid job names fail with an INVALID_ARGUMENT error. notification-config event-types=invidunt Event types for which a notification is desired. If empty, send notifications for all event types. Each invocation of this argument appends the given value to the array. payload-format=amet Required. The desired format of the notification message payloads. pubsub-topic=duo Required. The Topic.name of the Pub/Sub topic to which to publish notifications. Must be of the format: projects/{project}/topics/{topic} . Not matching this format results in an INVALID_ARGUMENT error. .. project-id=ipsum The ID of the Google Cloud project that owns the job. schedule.end-time-of-day hours=8 Hours of day in 24 hour format. Should be from 0 to 23. An API may choose to allow the value \"24:00:00\" for scenarios like business closing time. minutes=64 Minutes of hour of day. Must be from 0 to 59. nanos=89 Fractions of seconds in nanoseconds. Must be from 0 to 999,999,999. seconds=85 Seconds of minutes of the time. Must normally be from 0 to 59. An API may allow the value 60 if it allows leap-seconds. .. repeat-interval=est Interval between the start of each scheduled TransferOperation. If unspecified, the default value is 24 hours. This value may not be less than 1 hour. schedule-end-date day=51 Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant. month=51 Month of a year. Must be from 1 to 12, or 0 to specify a year without a month and day. year=94 Year of the date. Must be from 1 to 9999, or 0 to specify a date without a year. ..schedule-start-date day=39 Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant. month=84 Month of a year. Must be from 1 to 12, or 0 to specify a year without a month and day. year=2 Year of the date. Must be from 1 to 9999, or 0 to specify a date without a year. ..start-time-of-day hours=45 Hours of day in 24 hour format. Should be from 0 to 23. An API may choose to allow the value \"24:00:00\" for scenarios like business closing time. minutes=76 Minutes of hour of day. Must be from 0 to 59. nanos=15 Fractions of seconds in nanoseconds. Must be from 0 to 999,999,999. seconds=58 Seconds of minutes of the time. Must normally be from 0 to 59. An API may allow the value 60 if it allows leap-seconds. ... status=duo Status of the job. This value MUST be specified for CreateTransferJobRequests . Note: The effect of the new job status takes place during a subsequent job run. For example, if you change the job status from ENABLED to DISABLED, and an operation spawned by the transfer is running, the status change would not affect the current operation. transfer-spec.aws-s3-compatible-data-source bucket-name=sed Required. Specifies the name of the bucket. endpoint=no Required. Specifies the endpoint of the storage service. path=stet Specifies the root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'. region=kasd Specifies the region to sign requests with. This can be left blank if requests should be signed with an empty region. s3-metadata auth-method=et Specifies the authentication and authorization method used by the storage service. When not specified, Transfer Service will attempt to determine right auth method to use. list-api=sed The Listing API to use for discovering objects. When not specified, Transfer Service will attempt to determine the right API to use. protocol=et Specifies the network protocol of the agent. When not specified, the default value of NetworkProtocol NETWORK_PROTOCOL_HTTPS is used. request-model=et Specifies the API request model used to call the storage service. When not specified, the default value of RequestModel REQUEST_MODEL_VIRTUAL_HOSTED_STYLE is used. ...aws-s3-data-source.aws-access-key access-key-id=vero Required. AWS access key ID. secret-access-key=erat Required. AWS secret access key. This field is not returned in RPC responses. .. bucket-name=sed Required. S3 Bucket name (see Creating a bucket ). cloudfront-domain=duo Optional. Cloudfront domain name pointing to this bucket (as origin), to use when fetching. Format: https://{id}.cloudfront.net or any valid custom domain https://... credentials-secret=dolore Optional. The Resource name of a secret in Secret Manager. AWS credentials must be stored in Secret Manager in JSON format: { \"access_key_id\": \"ACCESS_KEY_ID\", \"secret_access_key\": \"SECRET_ACCESS_KEY\" } GoogleServiceAccount must be granted roles/secretmanager.secretAccessor for the resource. See [Configure access to a source: Amazon S3] (https://cloud.google.com/storage-transfer/docs/source-amazon-s3#secret_manager) for more information. If credentials_secret is specified, do not specify role_arn or aws_access_key. This feature is in preview . Format: projects/{project_number}/secrets/{secret_name} path=et Root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'. role-arn=voluptua. The Amazon Resource Name (ARN) of the role to support temporary credentials via AssumeRoleWithWebIdentity . For more information about ARNs, see IAM ARNs . When a role ARN is provided, Transfer Service fetches temporary credentials for the session using a AssumeRoleWithWebIdentity call for the provided role using the GoogleServiceAccount for this project. ..azure-blob-storage-data-source.azure-credentials sas-token=amet. Required. Azure shared access signature (SAS). For more information about SAS, see Grant limited access to Azure Storage resources using shared access signatures (SAS) . .. container=consetetur Required. The container to transfer from the Azure Storage account. credentials-secret=diam Optional. The Resource name of a secret in Secret Manager. The Azure SAS token must be stored in Secret Manager in JSON format: { \"sas_token\" : \"SAS_TOKEN\" } GoogleServiceAccount must be granted roles/secretmanager.secretAccessor for the resource. See [Configure access to a source: Microsoft Azure Blob Storage] (https://cloud.google.com/storage-transfer/docs/source-microsoft-azure#secret_manager) for more information. If credentials_secret is specified, do not specify azure_credentials. This feature is in preview . Format: projects/{project_number}/secrets/{secret_name} path=dolor Root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'. storage-account=et Required. The name of the Azure Storage account. ..gcs-data-sink bucket-name=et Required. Cloud Storage bucket name. Must meet Bucket Name Requirements . managed-folder-transfer-enabled=false Transfer managed folders is in public preview. This option is only applicable to the Cloud Storage source bucket. If set to true: - The source managed folder will be transferred to the destination bucket - The destination managed folder will always be overwritten, other OVERWRITE options will not be supported path=stet Root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'. The root path value must meet Object Name Requirements . ..gcs-data-source bucket-name=dolor Required. Cloud Storage bucket name. Must meet Bucket Name Requirements . managed-folder-transfer-enabled=false Transfer managed folders is in public preview. This option is only applicable to the Cloud Storage source bucket. If set to true: - The source managed folder will be transferred to the destination bucket - The destination managed folder will always be overwritten, other OVERWRITE options will not be supported path=vero Root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'. The root path value must meet Object Name Requirements . ..gcs-intermediate-data-location bucket-name=invidunt Required. Cloud Storage bucket name. Must meet Bucket Name Requirements . managed-folder-transfer-enabled=true Transfer managed folders is in public preview. This option is only applicable to the Cloud Storage source bucket. If set to true: - The source managed folder will be transferred to the destination bucket - The destination managed folder will always be overwritten, other OVERWRITE options will not be supported path=vero Root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'. The root path value must meet Object Name Requirements . ..hdfs-data-source path=elitr Root path to transfer files. ..http-data-source list-url=lorem Required. The URL that points to the file that stores the object list entries. This file must allow public access. Currently, only URLs with HTTP and HTTPS schemes are supported. ..object-conditions exclude-prefixes=diam If you specify exclude_prefixes , Storage Transfer Service uses the items in the exclude_prefixes array to determine which objects to exclude from a transfer. Objects must not start with one of the matching exclude_prefixes for inclusion in a transfer. The following are requirements of exclude_prefixes : * Each exclude-prefix can contain any sequence of Unicode characters, to a max length of 1024 bytes when UTF8-encoded, and must not contain Carriage Return or Line Feed characters. Wildcard matching and regular expression matching are not supported. * Each exclude-prefix must omit the leading slash. For example, to exclude the object s3://my-aws-bucket/logs/y=2015/requests.gz , specify the exclude-prefix as logs/y=2015/requests.gz . * None of the exclude-prefix values can be empty, if specified. * Each exclude-prefix must exclude a distinct portion of the object namespace. No exclude-prefix may be a prefix of another exclude-prefix. * If include_prefixes is specified, then each exclude-prefix must start with the value of a path explicitly included by include_prefixes . The max size of exclude_prefixes is 1000. For more information, see Filtering objects from transfers . Each invocation of this argument appends the given value to the array. include-prefixes=no If you specify include_prefixes , Storage Transfer Service uses the items in the include_prefixes array to determine which objects to include in a transfer. Objects must start with one of the matching include_prefixes for inclusion in the transfer. If exclude_prefixes is specified, objects must not start with any of the exclude_prefixes specified for inclusion in the transfer. The following are requirements of include_prefixes : * Each include-prefix can contain any sequence of Unicode characters, to a max length of 1024 bytes when UTF8-encoded, and must not contain Carriage Return or Line Feed characters. Wildcard matching and regular expression matching are not supported. * Each include-prefix must omit the leading slash. For example, to include the object s3://my-aws-bucket/logs/y=2015/requests.gz , specify the include-prefix as logs/y=2015/requests.gz . * None of the include-prefix values can be empty, if specified. * Each include-prefix must include a distinct portion of the object namespace. No include-prefix may be a prefix of another include-prefix. The max size of include_prefixes is 1000. For more information, see Filtering objects from transfers . Each invocation of this argument appends the given value to the array. last-modified-before=ipsum If specified, only objects with a \"last modification time\" before this timestamp and objects that don't have a \"last modification time\" are transferred. last-modified-since=accusam If specified, only objects with a \"last modification time\" on or after this timestamp and objects that don't have a \"last modification time\" are transferred. The last_modified_since and last_modified_before fields can be used together for chunked data processing. For example, consider a script that processes each day's worth of data at a time. For that you'd set each of the fields as follows: * last_modified_since to the start of the day * last_modified_before to the end of the day max-time-elapsed-since-last-modification=takimata Ensures that objects are not transferred if a specific maximum time has elapsed since the \"last modification time\". When a TransferOperation begins, objects with a \"last modification time\" are transferred only if the elapsed time between the start_time of the TransferOperation and the \"last modification time\" of the object is less than the value of max_time_elapsed_since_last_modification`. Objects that do not have a \"last modification time\" are also transferred. min-time-elapsed-since-last-modification=consetetur Ensures that objects are not transferred until a specific minimum time has elapsed after the \"last modification time\". When a TransferOperation begins, objects with a \"last modification time\" are transferred only if the elapsed time between the start_time of the TransferOperation and the \"last modification time\" of the object is equal to or greater than the value of min_time_elapsed_since_last_modification`. Objects that do not have a \"last modification time\" are also transferred. ..posix-data-sink root-directory=voluptua. Root directory path to the filesystem. ..posix-data-source root-directory=et Root directory path to the filesystem. .. sink-agent-pool-name=erat Specifies the agent pool name associated with the posix data sink. When unspecified, the default name is used. source-agent-pool-name=consetetur Specifies the agent pool name associated with the posix data source. When unspecified, the default name is used. transfer-manifest location=amet. Specifies the path to the manifest in Cloud Storage. The Google-managed service account for the transfer must have storage.objects.get permission for this object. An example path is gs://bucket_name/path/manifest.csv . ..transfer-options delete-objects-from-source-after-transfer=true Whether objects should be deleted from the source after they are transferred to the sink. Note: This option and delete_objects_unique_in_sink are mutually exclusive. delete-objects-unique-in-sink=false Whether objects that exist only in the sink should be deleted. Note: This option and delete_objects_from_source_after_transfer are mutually exclusive. metadata-options acl=accusam Specifies how each object's ACLs should be preserved for transfers between Google Cloud Storage buckets. If unspecified, the default behavior is the same as ACL_DESTINATION_BUCKET_DEFAULT. gid=voluptua. Specifies how each file's POSIX group ID (GID) attribute should be handled by the transfer. By default, GID is not preserved. Only applicable to transfers involving POSIX file systems, and ignored for other transfers. kms-key=dolore Specifies how each object's Cloud KMS customer-managed encryption key (CMEK) is preserved for transfers between Google Cloud Storage buckets. If unspecified, the default behavior is the same as KMS_KEY_DESTINATION_BUCKET_DEFAULT. mode=dolore Specifies how each file's mode attribute should be handled by the transfer. By default, mode is not preserved. Only applicable to transfers involving POSIX file systems, and ignored for other transfers. storage-class=dolore Specifies the storage class to set on objects being transferred to Google Cloud Storage buckets. If unspecified, the default behavior is the same as STORAGE_CLASS_DESTINATION_BUCKET_DEFAULT. symlink=voluptua. Specifies how symlinks should be handled by the transfer. By default, symlinks are not preserved. Only applicable to transfers involving POSIX file systems, and ignored for other transfers. temporary-hold=amet. Specifies how each object's temporary hold status should be preserved for transfers between Google Cloud Storage buckets. If unspecified, the default behavior is the same as TEMPORARY_HOLD_PRESERVE. time-created=ea Specifies how each object's timeCreated metadata is preserved for transfers. If unspecified, the default behavior is the same as TIME_CREATED_SKIP. uid=sadipscing Specifies how each file's POSIX user ID (UID) attribute should be handled by the transfer. By default, UID is not preserved. Only applicable to transfers involving POSIX file systems, and ignored for other transfers. .. overwrite-objects-already-existing-in-sink=true When to overwrite objects that already exist in the sink. The default is that only objects that are different from the source are ovewritten. If true, all objects in the sink whose name matches an object in the source are overwritten with the source object. overwrite-when=no When to overwrite objects that already exist in the sink. If not set, overwrite behavior is determined by overwrite_objects_already_existing_in_sink.","title":"Required Request Value"},{"location":"transfer-jobs_create/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"transfer-jobs_create/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"transfer-jobs_create/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"transfer-jobs_delete/","text":"Deletes a transfer job. Deleting a transfer job sets its status to DELETED. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> transfer-jobs delete ... Required Scalar Arguments <job-name> (string) Required. The job to delete. <project-id> (string) Required. The ID of the Google Cloud project that owns the job. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Delete"},{"location":"transfer-jobs_delete/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> transfer-jobs delete ...","title":"Scopes"},{"location":"transfer-jobs_delete/#required-scalar-arguments","text":"<job-name> (string) Required. The job to delete. <project-id> (string) Required. The ID of the Google Cloud project that owns the job.","title":"Required Scalar Arguments"},{"location":"transfer-jobs_delete/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"transfer-jobs_delete/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"transfer-jobs_get/","text":"Gets a transfer job. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> transfer-jobs get ... Required Scalar Arguments <job-name> (string) Required. The job to get. <project-id> (string) Required. The ID of the Google Cloud project that owns the job. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Get"},{"location":"transfer-jobs_get/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> transfer-jobs get ...","title":"Scopes"},{"location":"transfer-jobs_get/#required-scalar-arguments","text":"<job-name> (string) Required. The job to get. <project-id> (string) Required. The ID of the Google Cloud project that owns the job.","title":"Required Scalar Arguments"},{"location":"transfer-jobs_get/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"transfer-jobs_get/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"transfer-jobs_list/","text":"Lists transfer jobs. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> transfer-jobs list ... Required Scalar Argument <filter> (string) Required. A list of query parameters specified as JSON text in the form of: {&#34;projectId&#34;:&#34;my_project_id&#34;, &#34;jobNames&#34;:[&#34;jobid1&#34;,&#34;jobid2&#34;,...], &#34;jobStatuses&#34;:[&#34;status1&#34;,&#34;status2&#34;,...]} Since jobNames and jobStatuses support multiple values, their values must be specified with array notation. projectId is required. jobNames and jobStatuses are optional. The valid values for jobStatuses are case-insensitive: ENABLED, DISABLED, and DELETED. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional Method Properties You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p page-size=integer The list page size. The max allowed value is 256. -p page-token=string The list page token. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"List"},{"location":"transfer-jobs_list/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> transfer-jobs list ...","title":"Scopes"},{"location":"transfer-jobs_list/#required-scalar-argument","text":"<filter> (string) Required. A list of query parameters specified as JSON text in the form of: {&#34;projectId&#34;:&#34;my_project_id&#34;, &#34;jobNames&#34;:[&#34;jobid1&#34;,&#34;jobid2&#34;,...], &#34;jobStatuses&#34;:[&#34;status1&#34;,&#34;status2&#34;,...]} Since jobNames and jobStatuses support multiple values, their values must be specified with array notation. projectId is required. jobNames and jobStatuses are optional. The valid values for jobStatuses are case-insensitive: ENABLED, DISABLED, and DELETED.","title":"Required Scalar Argument"},{"location":"transfer-jobs_list/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"transfer-jobs_list/#optional-method-properties","text":"You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p page-size=integer The list page size. The max allowed value is 256. -p page-token=string The list page token.","title":"Optional Method Properties"},{"location":"transfer-jobs_list/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"transfer-jobs_patch/","text":"Updates a transfer job. Updating a job's transfer spec does not affect transfer operations that are running already. Note: The job's status field can be modified using this RPC (for example, to set a job's status to DELETED, DISABLED, or ENABLED). Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> transfer-jobs patch ... Required Scalar Argument <job-name> (string) Required. The name of job to update. Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: UpdateTransferJobRequest: project-id: string transfer-job: creation-time: string deletion-time: string description: string event-stream: event-stream-expiration-time: string event-stream-start-time: string name: string last-modification-time: string latest-operation-name: string logging-config: enable-onprem-gcs-transfer-logs: boolean log-action-states: [string] log-actions: [string] name: string notification-config: event-types: [string] payload-format: string pubsub-topic: string project-id: string schedule: end-time-of-day: hours: integer minutes: integer nanos: integer seconds: integer repeat-interval: string schedule-end-date: day: integer month: integer year: integer schedule-start-date: day: integer month: integer year: integer start-time-of-day: hours: integer minutes: integer nanos: integer seconds: integer status: string transfer-spec: aws-s3-compatible-data-source: bucket-name: string endpoint: string path: string region: string s3-metadata: auth-method: string list-api: string protocol: string request-model: string aws-s3-data-source: aws-access-key: access-key-id: string secret-access-key: string bucket-name: string cloudfront-domain: string credentials-secret: string path: string role-arn: string azure-blob-storage-data-source: azure-credentials: sas-token: string container: string credentials-secret: string path: string storage-account: string gcs-data-sink: bucket-name: string managed-folder-transfer-enabled: boolean path: string gcs-data-source: bucket-name: string managed-folder-transfer-enabled: boolean path: string gcs-intermediate-data-location: bucket-name: string managed-folder-transfer-enabled: boolean path: string hdfs-data-source: path: string http-data-source: list-url: string object-conditions: exclude-prefixes: [string] include-prefixes: [string] last-modified-before: string last-modified-since: string max-time-elapsed-since-last-modification: string min-time-elapsed-since-last-modification: string posix-data-sink: root-directory: string posix-data-source: root-directory: string sink-agent-pool-name: string source-agent-pool-name: string transfer-manifest: location: string transfer-options: delete-objects-from-source-after-transfer: boolean delete-objects-unique-in-sink: boolean metadata-options: acl: string gid: string kms-key: string mode: string storage-class: string symlink: string temporary-hold: string time-created: string uid: string overwrite-objects-already-existing-in-sink: boolean overwrite-when: string update-transfer-job-field-mask: string can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r . project-id=est Required. The ID of the Google Cloud project that owns the job. transfer-job creation-time=at Output only. The time that the transfer job was created. deletion-time=sed Output only. The time that the transfer job was deleted. description=sit A description provided by the user for the job. Its max length is 1024 bytes when Unicode-encoded. event-stream event-stream-expiration-time=et Specifies the data and time at which Storage Transfer Service stops listening for events from this stream. After this time, any transfers in progress will complete, but no new transfers are initiated. event-stream-start-time=tempor Specifies the date and time that Storage Transfer Service starts listening for events from this stream. If no start time is specified or start time is in the past, Storage Transfer Service starts listening immediately. name=aliquyam Required. Specifies a unique name of the resource such as AWS SQS ARN in the form 'arn:aws:sqs:region:account_id:queue_name', or Pub/Sub subscription resource name in the form 'projects/{project}/subscriptions/{sub}'. .. last-modification-time=ipsum Output only. The time that the transfer job was last modified. latest-operation-name=et The name of the most recently started TransferOperation of this JobConfig. Present if a TransferOperation has been created for this JobConfig. logging-config enable-onprem-gcs-transfer-logs=true For transfers with a PosixFilesystem source, this option enables the Cloud Storage transfer logs for this transfer. log-action-states=est States in which log_actions are logged. If empty, no logs are generated. Not supported for transfers with PosixFilesystem data sources; use enable_onprem_gcs_transfer_logs instead. Each invocation of this argument appends the given value to the array. log-actions=sed Specifies the actions to be logged. If empty, no logs are generated. Not supported for transfers with PosixFilesystem data sources; use enable_onprem_gcs_transfer_logs instead. Each invocation of this argument appends the given value to the array. .. name=diam A unique name (within the transfer project) assigned when the job is created. If this field is empty in a CreateTransferJobRequest, Storage Transfer Service assigns a unique name. Otherwise, the specified name is used as the unique name for this job. If the specified name is in use by a job, the creation request fails with an ALREADY_EXISTS error. This name must start with &#34;transferJobs/&#34; prefix and end with a letter or a number, and should be no more than 128 characters. For transfers involving PosixFilesystem, this name must start with transferJobs/OPI specifically. For all other transfer types, this name must not start with transferJobs/OPI . Non-PosixFilesystem example: &#34;transferJobs/^(?!OPI)[A-Za-z0-9-._~]*[A-Za-z0-9]$&#34; PosixFilesystem example: &#34;transferJobs/OPI^[A-Za-z0-9-._~]*[A-Za-z0-9]$&#34; Applications must not rely on the enforcement of naming requirements involving OPI. Invalid job names fail with an INVALID_ARGUMENT error. notification-config event-types=dolores Event types for which a notification is desired. If empty, send notifications for all event types. Each invocation of this argument appends the given value to the array. payload-format=dolores Required. The desired format of the notification message payloads. pubsub-topic=et Required. The Topic.name of the Pub/Sub topic to which to publish notifications. Must be of the format: projects/{project}/topics/{topic} . Not matching this format results in an INVALID_ARGUMENT error. .. project-id=sed The ID of the Google Cloud project that owns the job. schedule.end-time-of-day hours=90 Hours of day in 24 hour format. Should be from 0 to 23. An API may choose to allow the value \"24:00:00\" for scenarios like business closing time. minutes=16 Minutes of hour of day. Must be from 0 to 59. nanos=7 Fractions of seconds in nanoseconds. Must be from 0 to 999,999,999. seconds=21 Seconds of minutes of the time. Must normally be from 0 to 59. An API may allow the value 60 if it allows leap-seconds. .. repeat-interval=no Interval between the start of each scheduled TransferOperation. If unspecified, the default value is 24 hours. This value may not be less than 1 hour. schedule-end-date day=10 Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant. month=24 Month of a year. Must be from 1 to 12, or 0 to specify a year without a month and day. year=56 Year of the date. Must be from 1 to 9999, or 0 to specify a date without a year. ..schedule-start-date day=69 Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant. month=32 Month of a year. Must be from 1 to 12, or 0 to specify a year without a month and day. year=6 Year of the date. Must be from 1 to 9999, or 0 to specify a date without a year. ..start-time-of-day hours=70 Hours of day in 24 hour format. Should be from 0 to 23. An API may choose to allow the value \"24:00:00\" for scenarios like business closing time. minutes=19 Minutes of hour of day. Must be from 0 to 59. nanos=54 Fractions of seconds in nanoseconds. Must be from 0 to 999,999,999. seconds=44 Seconds of minutes of the time. Must normally be from 0 to 59. An API may allow the value 60 if it allows leap-seconds. ... status=et Status of the job. This value MUST be specified for CreateTransferJobRequests . Note: The effect of the new job status takes place during a subsequent job run. For example, if you change the job status from ENABLED to DISABLED, and an operation spawned by the transfer is running, the status change would not affect the current operation. transfer-spec.aws-s3-compatible-data-source bucket-name=sea Required. Specifies the name of the bucket. endpoint=consetetur Required. Specifies the endpoint of the storage service. path=consetetur Specifies the root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'. region=stet Specifies the region to sign requests with. This can be left blank if requests should be signed with an empty region. s3-metadata auth-method=est Specifies the authentication and authorization method used by the storage service. When not specified, Transfer Service will attempt to determine right auth method to use. list-api=aliquyam The Listing API to use for discovering objects. When not specified, Transfer Service will attempt to determine the right API to use. protocol=elitr Specifies the network protocol of the agent. When not specified, the default value of NetworkProtocol NETWORK_PROTOCOL_HTTPS is used. request-model=duo Specifies the API request model used to call the storage service. When not specified, the default value of RequestModel REQUEST_MODEL_VIRTUAL_HOSTED_STYLE is used. ...aws-s3-data-source.aws-access-key access-key-id=diam Required. AWS access key ID. secret-access-key=est Required. AWS secret access key. This field is not returned in RPC responses. .. bucket-name=sit Required. S3 Bucket name (see Creating a bucket ). cloudfront-domain=sed Optional. Cloudfront domain name pointing to this bucket (as origin), to use when fetching. Format: https://{id}.cloudfront.net or any valid custom domain https://... credentials-secret=eos Optional. The Resource name of a secret in Secret Manager. AWS credentials must be stored in Secret Manager in JSON format: { \"access_key_id\": \"ACCESS_KEY_ID\", \"secret_access_key\": \"SECRET_ACCESS_KEY\" } GoogleServiceAccount must be granted roles/secretmanager.secretAccessor for the resource. See [Configure access to a source: Amazon S3] (https://cloud.google.com/storage-transfer/docs/source-amazon-s3#secret_manager) for more information. If credentials_secret is specified, do not specify role_arn or aws_access_key. This feature is in preview . Format: projects/{project_number}/secrets/{secret_name} path=lorem Root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'. role-arn=ea The Amazon Resource Name (ARN) of the role to support temporary credentials via AssumeRoleWithWebIdentity . For more information about ARNs, see IAM ARNs . When a role ARN is provided, Transfer Service fetches temporary credentials for the session using a AssumeRoleWithWebIdentity call for the provided role using the GoogleServiceAccount for this project. ..azure-blob-storage-data-source.azure-credentials sas-token=stet Required. Azure shared access signature (SAS). For more information about SAS, see Grant limited access to Azure Storage resources using shared access signatures (SAS) . .. container=dolores Required. The container to transfer from the Azure Storage account. credentials-secret=eos Optional. The Resource name of a secret in Secret Manager. The Azure SAS token must be stored in Secret Manager in JSON format: { \"sas_token\" : \"SAS_TOKEN\" } GoogleServiceAccount must be granted roles/secretmanager.secretAccessor for the resource. See [Configure access to a source: Microsoft Azure Blob Storage] (https://cloud.google.com/storage-transfer/docs/source-microsoft-azure#secret_manager) for more information. If credentials_secret is specified, do not specify azure_credentials. This feature is in preview . Format: projects/{project_number}/secrets/{secret_name} path=et Root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'. storage-account=sea Required. The name of the Azure Storage account. ..gcs-data-sink bucket-name=et Required. Cloud Storage bucket name. Must meet Bucket Name Requirements . managed-folder-transfer-enabled=false Transfer managed folders is in public preview. This option is only applicable to the Cloud Storage source bucket. If set to true: - The source managed folder will be transferred to the destination bucket - The destination managed folder will always be overwritten, other OVERWRITE options will not be supported path=dolore Root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'. The root path value must meet Object Name Requirements . ..gcs-data-source bucket-name=eirmod Required. Cloud Storage bucket name. Must meet Bucket Name Requirements . managed-folder-transfer-enabled=true Transfer managed folders is in public preview. This option is only applicable to the Cloud Storage source bucket. If set to true: - The source managed folder will be transferred to the destination bucket - The destination managed folder will always be overwritten, other OVERWRITE options will not be supported path=accusam Root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'. The root path value must meet Object Name Requirements . ..gcs-intermediate-data-location bucket-name=amet Required. Cloud Storage bucket name. Must meet Bucket Name Requirements . managed-folder-transfer-enabled=true Transfer managed folders is in public preview. This option is only applicable to the Cloud Storage source bucket. If set to true: - The source managed folder will be transferred to the destination bucket - The destination managed folder will always be overwritten, other OVERWRITE options will not be supported path=erat Root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'. The root path value must meet Object Name Requirements . ..hdfs-data-source path=accusam Root path to transfer files. ..http-data-source list-url=sea Required. The URL that points to the file that stores the object list entries. This file must allow public access. Currently, only URLs with HTTP and HTTPS schemes are supported. ..object-conditions exclude-prefixes=takimata If you specify exclude_prefixes , Storage Transfer Service uses the items in the exclude_prefixes array to determine which objects to exclude from a transfer. Objects must not start with one of the matching exclude_prefixes for inclusion in a transfer. The following are requirements of exclude_prefixes : * Each exclude-prefix can contain any sequence of Unicode characters, to a max length of 1024 bytes when UTF8-encoded, and must not contain Carriage Return or Line Feed characters. Wildcard matching and regular expression matching are not supported. * Each exclude-prefix must omit the leading slash. For example, to exclude the object s3://my-aws-bucket/logs/y=2015/requests.gz , specify the exclude-prefix as logs/y=2015/requests.gz . * None of the exclude-prefix values can be empty, if specified. * Each exclude-prefix must exclude a distinct portion of the object namespace. No exclude-prefix may be a prefix of another exclude-prefix. * If include_prefixes is specified, then each exclude-prefix must start with the value of a path explicitly included by include_prefixes . The max size of exclude_prefixes is 1000. For more information, see Filtering objects from transfers . Each invocation of this argument appends the given value to the array. include-prefixes=lorem If you specify include_prefixes , Storage Transfer Service uses the items in the include_prefixes array to determine which objects to include in a transfer. Objects must start with one of the matching include_prefixes for inclusion in the transfer. If exclude_prefixes is specified, objects must not start with any of the exclude_prefixes specified for inclusion in the transfer. The following are requirements of include_prefixes : * Each include-prefix can contain any sequence of Unicode characters, to a max length of 1024 bytes when UTF8-encoded, and must not contain Carriage Return or Line Feed characters. Wildcard matching and regular expression matching are not supported. * Each include-prefix must omit the leading slash. For example, to include the object s3://my-aws-bucket/logs/y=2015/requests.gz , specify the include-prefix as logs/y=2015/requests.gz . * None of the include-prefix values can be empty, if specified. * Each include-prefix must include a distinct portion of the object namespace. No include-prefix may be a prefix of another include-prefix. The max size of include_prefixes is 1000. For more information, see Filtering objects from transfers . Each invocation of this argument appends the given value to the array. last-modified-before=et If specified, only objects with a \"last modification time\" before this timestamp and objects that don't have a \"last modification time\" are transferred. last-modified-since=at If specified, only objects with a \"last modification time\" on or after this timestamp and objects that don't have a \"last modification time\" are transferred. The last_modified_since and last_modified_before fields can be used together for chunked data processing. For example, consider a script that processes each day's worth of data at a time. For that you'd set each of the fields as follows: * last_modified_since to the start of the day * last_modified_before to the end of the day max-time-elapsed-since-last-modification=dolor Ensures that objects are not transferred if a specific maximum time has elapsed since the \"last modification time\". When a TransferOperation begins, objects with a \"last modification time\" are transferred only if the elapsed time between the start_time of the TransferOperation and the \"last modification time\" of the object is less than the value of max_time_elapsed_since_last_modification`. Objects that do not have a \"last modification time\" are also transferred. min-time-elapsed-since-last-modification=et Ensures that objects are not transferred until a specific minimum time has elapsed after the \"last modification time\". When a TransferOperation begins, objects with a \"last modification time\" are transferred only if the elapsed time between the start_time of the TransferOperation and the \"last modification time\" of the object is equal to or greater than the value of min_time_elapsed_since_last_modification`. Objects that do not have a \"last modification time\" are also transferred. ..posix-data-sink root-directory=sit Root directory path to the filesystem. ..posix-data-source root-directory=erat Root directory path to the filesystem. .. sink-agent-pool-name=sea Specifies the agent pool name associated with the posix data sink. When unspecified, the default name is used. source-agent-pool-name=nonumy Specifies the agent pool name associated with the posix data source. When unspecified, the default name is used. transfer-manifest location=et Specifies the path to the manifest in Cloud Storage. The Google-managed service account for the transfer must have storage.objects.get permission for this object. An example path is gs://bucket_name/path/manifest.csv . ..transfer-options delete-objects-from-source-after-transfer=true Whether objects should be deleted from the source after they are transferred to the sink. Note: This option and delete_objects_unique_in_sink are mutually exclusive. delete-objects-unique-in-sink=false Whether objects that exist only in the sink should be deleted. Note: This option and delete_objects_from_source_after_transfer are mutually exclusive. metadata-options acl=sit Specifies how each object's ACLs should be preserved for transfers between Google Cloud Storage buckets. If unspecified, the default behavior is the same as ACL_DESTINATION_BUCKET_DEFAULT. gid=aliquyam Specifies how each file's POSIX group ID (GID) attribute should be handled by the transfer. By default, GID is not preserved. Only applicable to transfers involving POSIX file systems, and ignored for other transfers. kms-key=eos Specifies how each object's Cloud KMS customer-managed encryption key (CMEK) is preserved for transfers between Google Cloud Storage buckets. If unspecified, the default behavior is the same as KMS_KEY_DESTINATION_BUCKET_DEFAULT. mode=at Specifies how each file's mode attribute should be handled by the transfer. By default, mode is not preserved. Only applicable to transfers involving POSIX file systems, and ignored for other transfers. storage-class=dolores Specifies the storage class to set on objects being transferred to Google Cloud Storage buckets. If unspecified, the default behavior is the same as STORAGE_CLASS_DESTINATION_BUCKET_DEFAULT. symlink=consetetur Specifies how symlinks should be handled by the transfer. By default, symlinks are not preserved. Only applicable to transfers involving POSIX file systems, and ignored for other transfers. temporary-hold=gubergren Specifies how each object's temporary hold status should be preserved for transfers between Google Cloud Storage buckets. If unspecified, the default behavior is the same as TEMPORARY_HOLD_PRESERVE. time-created=dolor Specifies how each object's timeCreated metadata is preserved for transfers. If unspecified, the default behavior is the same as TIME_CREATED_SKIP. uid=aliquyam Specifies how each file's POSIX user ID (UID) attribute should be handled by the transfer. By default, UID is not preserved. Only applicable to transfers involving POSIX file systems, and ignored for other transfers. .. overwrite-objects-already-existing-in-sink=true When to overwrite objects that already exist in the sink. The default is that only objects that are different from the source are ovewritten. If true, all objects in the sink whose name matches an object in the source are overwritten with the source object. overwrite-when=amet. When to overwrite objects that already exist in the sink. If not set, overwrite behavior is determined by overwrite_objects_already_existing_in_sink. .... update-transfer-job-field-mask=ipsum The field mask of the fields in transferJob that are to be updated in this request. Fields in transferJob that can be updated are: description, transfer_spec, notification_config, logging_config, and status. To update the transfer_spec of the job, a complete transfer specification must be provided. An incomplete specification missing any required fields is rejected with the error INVALID_ARGUMENT. About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Patch"},{"location":"transfer-jobs_patch/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> transfer-jobs patch ...","title":"Scopes"},{"location":"transfer-jobs_patch/#required-scalar-argument","text":"<job-name> (string) Required. The name of job to update.","title":"Required Scalar Argument"},{"location":"transfer-jobs_patch/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: UpdateTransferJobRequest: project-id: string transfer-job: creation-time: string deletion-time: string description: string event-stream: event-stream-expiration-time: string event-stream-start-time: string name: string last-modification-time: string latest-operation-name: string logging-config: enable-onprem-gcs-transfer-logs: boolean log-action-states: [string] log-actions: [string] name: string notification-config: event-types: [string] payload-format: string pubsub-topic: string project-id: string schedule: end-time-of-day: hours: integer minutes: integer nanos: integer seconds: integer repeat-interval: string schedule-end-date: day: integer month: integer year: integer schedule-start-date: day: integer month: integer year: integer start-time-of-day: hours: integer minutes: integer nanos: integer seconds: integer status: string transfer-spec: aws-s3-compatible-data-source: bucket-name: string endpoint: string path: string region: string s3-metadata: auth-method: string list-api: string protocol: string request-model: string aws-s3-data-source: aws-access-key: access-key-id: string secret-access-key: string bucket-name: string cloudfront-domain: string credentials-secret: string path: string role-arn: string azure-blob-storage-data-source: azure-credentials: sas-token: string container: string credentials-secret: string path: string storage-account: string gcs-data-sink: bucket-name: string managed-folder-transfer-enabled: boolean path: string gcs-data-source: bucket-name: string managed-folder-transfer-enabled: boolean path: string gcs-intermediate-data-location: bucket-name: string managed-folder-transfer-enabled: boolean path: string hdfs-data-source: path: string http-data-source: list-url: string object-conditions: exclude-prefixes: [string] include-prefixes: [string] last-modified-before: string last-modified-since: string max-time-elapsed-since-last-modification: string min-time-elapsed-since-last-modification: string posix-data-sink: root-directory: string posix-data-source: root-directory: string sink-agent-pool-name: string source-agent-pool-name: string transfer-manifest: location: string transfer-options: delete-objects-from-source-after-transfer: boolean delete-objects-unique-in-sink: boolean metadata-options: acl: string gid: string kms-key: string mode: string storage-class: string symlink: string temporary-hold: string time-created: string uid: string overwrite-objects-already-existing-in-sink: boolean overwrite-when: string update-transfer-job-field-mask: string can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r . project-id=est Required. The ID of the Google Cloud project that owns the job. transfer-job creation-time=at Output only. The time that the transfer job was created. deletion-time=sed Output only. The time that the transfer job was deleted. description=sit A description provided by the user for the job. Its max length is 1024 bytes when Unicode-encoded. event-stream event-stream-expiration-time=et Specifies the data and time at which Storage Transfer Service stops listening for events from this stream. After this time, any transfers in progress will complete, but no new transfers are initiated. event-stream-start-time=tempor Specifies the date and time that Storage Transfer Service starts listening for events from this stream. If no start time is specified or start time is in the past, Storage Transfer Service starts listening immediately. name=aliquyam Required. Specifies a unique name of the resource such as AWS SQS ARN in the form 'arn:aws:sqs:region:account_id:queue_name', or Pub/Sub subscription resource name in the form 'projects/{project}/subscriptions/{sub}'. .. last-modification-time=ipsum Output only. The time that the transfer job was last modified. latest-operation-name=et The name of the most recently started TransferOperation of this JobConfig. Present if a TransferOperation has been created for this JobConfig. logging-config enable-onprem-gcs-transfer-logs=true For transfers with a PosixFilesystem source, this option enables the Cloud Storage transfer logs for this transfer. log-action-states=est States in which log_actions are logged. If empty, no logs are generated. Not supported for transfers with PosixFilesystem data sources; use enable_onprem_gcs_transfer_logs instead. Each invocation of this argument appends the given value to the array. log-actions=sed Specifies the actions to be logged. If empty, no logs are generated. Not supported for transfers with PosixFilesystem data sources; use enable_onprem_gcs_transfer_logs instead. Each invocation of this argument appends the given value to the array. .. name=diam A unique name (within the transfer project) assigned when the job is created. If this field is empty in a CreateTransferJobRequest, Storage Transfer Service assigns a unique name. Otherwise, the specified name is used as the unique name for this job. If the specified name is in use by a job, the creation request fails with an ALREADY_EXISTS error. This name must start with &#34;transferJobs/&#34; prefix and end with a letter or a number, and should be no more than 128 characters. For transfers involving PosixFilesystem, this name must start with transferJobs/OPI specifically. For all other transfer types, this name must not start with transferJobs/OPI . Non-PosixFilesystem example: &#34;transferJobs/^(?!OPI)[A-Za-z0-9-._~]*[A-Za-z0-9]$&#34; PosixFilesystem example: &#34;transferJobs/OPI^[A-Za-z0-9-._~]*[A-Za-z0-9]$&#34; Applications must not rely on the enforcement of naming requirements involving OPI. Invalid job names fail with an INVALID_ARGUMENT error. notification-config event-types=dolores Event types for which a notification is desired. If empty, send notifications for all event types. Each invocation of this argument appends the given value to the array. payload-format=dolores Required. The desired format of the notification message payloads. pubsub-topic=et Required. The Topic.name of the Pub/Sub topic to which to publish notifications. Must be of the format: projects/{project}/topics/{topic} . Not matching this format results in an INVALID_ARGUMENT error. .. project-id=sed The ID of the Google Cloud project that owns the job. schedule.end-time-of-day hours=90 Hours of day in 24 hour format. Should be from 0 to 23. An API may choose to allow the value \"24:00:00\" for scenarios like business closing time. minutes=16 Minutes of hour of day. Must be from 0 to 59. nanos=7 Fractions of seconds in nanoseconds. Must be from 0 to 999,999,999. seconds=21 Seconds of minutes of the time. Must normally be from 0 to 59. An API may allow the value 60 if it allows leap-seconds. .. repeat-interval=no Interval between the start of each scheduled TransferOperation. If unspecified, the default value is 24 hours. This value may not be less than 1 hour. schedule-end-date day=10 Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant. month=24 Month of a year. Must be from 1 to 12, or 0 to specify a year without a month and day. year=56 Year of the date. Must be from 1 to 9999, or 0 to specify a date without a year. ..schedule-start-date day=69 Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant. month=32 Month of a year. Must be from 1 to 12, or 0 to specify a year without a month and day. year=6 Year of the date. Must be from 1 to 9999, or 0 to specify a date without a year. ..start-time-of-day hours=70 Hours of day in 24 hour format. Should be from 0 to 23. An API may choose to allow the value \"24:00:00\" for scenarios like business closing time. minutes=19 Minutes of hour of day. Must be from 0 to 59. nanos=54 Fractions of seconds in nanoseconds. Must be from 0 to 999,999,999. seconds=44 Seconds of minutes of the time. Must normally be from 0 to 59. An API may allow the value 60 if it allows leap-seconds. ... status=et Status of the job. This value MUST be specified for CreateTransferJobRequests . Note: The effect of the new job status takes place during a subsequent job run. For example, if you change the job status from ENABLED to DISABLED, and an operation spawned by the transfer is running, the status change would not affect the current operation. transfer-spec.aws-s3-compatible-data-source bucket-name=sea Required. Specifies the name of the bucket. endpoint=consetetur Required. Specifies the endpoint of the storage service. path=consetetur Specifies the root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'. region=stet Specifies the region to sign requests with. This can be left blank if requests should be signed with an empty region. s3-metadata auth-method=est Specifies the authentication and authorization method used by the storage service. When not specified, Transfer Service will attempt to determine right auth method to use. list-api=aliquyam The Listing API to use for discovering objects. When not specified, Transfer Service will attempt to determine the right API to use. protocol=elitr Specifies the network protocol of the agent. When not specified, the default value of NetworkProtocol NETWORK_PROTOCOL_HTTPS is used. request-model=duo Specifies the API request model used to call the storage service. When not specified, the default value of RequestModel REQUEST_MODEL_VIRTUAL_HOSTED_STYLE is used. ...aws-s3-data-source.aws-access-key access-key-id=diam Required. AWS access key ID. secret-access-key=est Required. AWS secret access key. This field is not returned in RPC responses. .. bucket-name=sit Required. S3 Bucket name (see Creating a bucket ). cloudfront-domain=sed Optional. Cloudfront domain name pointing to this bucket (as origin), to use when fetching. Format: https://{id}.cloudfront.net or any valid custom domain https://... credentials-secret=eos Optional. The Resource name of a secret in Secret Manager. AWS credentials must be stored in Secret Manager in JSON format: { \"access_key_id\": \"ACCESS_KEY_ID\", \"secret_access_key\": \"SECRET_ACCESS_KEY\" } GoogleServiceAccount must be granted roles/secretmanager.secretAccessor for the resource. See [Configure access to a source: Amazon S3] (https://cloud.google.com/storage-transfer/docs/source-amazon-s3#secret_manager) for more information. If credentials_secret is specified, do not specify role_arn or aws_access_key. This feature is in preview . Format: projects/{project_number}/secrets/{secret_name} path=lorem Root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'. role-arn=ea The Amazon Resource Name (ARN) of the role to support temporary credentials via AssumeRoleWithWebIdentity . For more information about ARNs, see IAM ARNs . When a role ARN is provided, Transfer Service fetches temporary credentials for the session using a AssumeRoleWithWebIdentity call for the provided role using the GoogleServiceAccount for this project. ..azure-blob-storage-data-source.azure-credentials sas-token=stet Required. Azure shared access signature (SAS). For more information about SAS, see Grant limited access to Azure Storage resources using shared access signatures (SAS) . .. container=dolores Required. The container to transfer from the Azure Storage account. credentials-secret=eos Optional. The Resource name of a secret in Secret Manager. The Azure SAS token must be stored in Secret Manager in JSON format: { \"sas_token\" : \"SAS_TOKEN\" } GoogleServiceAccount must be granted roles/secretmanager.secretAccessor for the resource. See [Configure access to a source: Microsoft Azure Blob Storage] (https://cloud.google.com/storage-transfer/docs/source-microsoft-azure#secret_manager) for more information. If credentials_secret is specified, do not specify azure_credentials. This feature is in preview . Format: projects/{project_number}/secrets/{secret_name} path=et Root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'. storage-account=sea Required. The name of the Azure Storage account. ..gcs-data-sink bucket-name=et Required. Cloud Storage bucket name. Must meet Bucket Name Requirements . managed-folder-transfer-enabled=false Transfer managed folders is in public preview. This option is only applicable to the Cloud Storage source bucket. If set to true: - The source managed folder will be transferred to the destination bucket - The destination managed folder will always be overwritten, other OVERWRITE options will not be supported path=dolore Root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'. The root path value must meet Object Name Requirements . ..gcs-data-source bucket-name=eirmod Required. Cloud Storage bucket name. Must meet Bucket Name Requirements . managed-folder-transfer-enabled=true Transfer managed folders is in public preview. This option is only applicable to the Cloud Storage source bucket. If set to true: - The source managed folder will be transferred to the destination bucket - The destination managed folder will always be overwritten, other OVERWRITE options will not be supported path=accusam Root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'. The root path value must meet Object Name Requirements . ..gcs-intermediate-data-location bucket-name=amet Required. Cloud Storage bucket name. Must meet Bucket Name Requirements . managed-folder-transfer-enabled=true Transfer managed folders is in public preview. This option is only applicable to the Cloud Storage source bucket. If set to true: - The source managed folder will be transferred to the destination bucket - The destination managed folder will always be overwritten, other OVERWRITE options will not be supported path=erat Root path to transfer objects. Must be an empty string or full path name that ends with a '/'. This field is treated as an object prefix. As such, it should generally not begin with a '/'. The root path value must meet Object Name Requirements . ..hdfs-data-source path=accusam Root path to transfer files. ..http-data-source list-url=sea Required. The URL that points to the file that stores the object list entries. This file must allow public access. Currently, only URLs with HTTP and HTTPS schemes are supported. ..object-conditions exclude-prefixes=takimata If you specify exclude_prefixes , Storage Transfer Service uses the items in the exclude_prefixes array to determine which objects to exclude from a transfer. Objects must not start with one of the matching exclude_prefixes for inclusion in a transfer. The following are requirements of exclude_prefixes : * Each exclude-prefix can contain any sequence of Unicode characters, to a max length of 1024 bytes when UTF8-encoded, and must not contain Carriage Return or Line Feed characters. Wildcard matching and regular expression matching are not supported. * Each exclude-prefix must omit the leading slash. For example, to exclude the object s3://my-aws-bucket/logs/y=2015/requests.gz , specify the exclude-prefix as logs/y=2015/requests.gz . * None of the exclude-prefix values can be empty, if specified. * Each exclude-prefix must exclude a distinct portion of the object namespace. No exclude-prefix may be a prefix of another exclude-prefix. * If include_prefixes is specified, then each exclude-prefix must start with the value of a path explicitly included by include_prefixes . The max size of exclude_prefixes is 1000. For more information, see Filtering objects from transfers . Each invocation of this argument appends the given value to the array. include-prefixes=lorem If you specify include_prefixes , Storage Transfer Service uses the items in the include_prefixes array to determine which objects to include in a transfer. Objects must start with one of the matching include_prefixes for inclusion in the transfer. If exclude_prefixes is specified, objects must not start with any of the exclude_prefixes specified for inclusion in the transfer. The following are requirements of include_prefixes : * Each include-prefix can contain any sequence of Unicode characters, to a max length of 1024 bytes when UTF8-encoded, and must not contain Carriage Return or Line Feed characters. Wildcard matching and regular expression matching are not supported. * Each include-prefix must omit the leading slash. For example, to include the object s3://my-aws-bucket/logs/y=2015/requests.gz , specify the include-prefix as logs/y=2015/requests.gz . * None of the include-prefix values can be empty, if specified. * Each include-prefix must include a distinct portion of the object namespace. No include-prefix may be a prefix of another include-prefix. The max size of include_prefixes is 1000. For more information, see Filtering objects from transfers . Each invocation of this argument appends the given value to the array. last-modified-before=et If specified, only objects with a \"last modification time\" before this timestamp and objects that don't have a \"last modification time\" are transferred. last-modified-since=at If specified, only objects with a \"last modification time\" on or after this timestamp and objects that don't have a \"last modification time\" are transferred. The last_modified_since and last_modified_before fields can be used together for chunked data processing. For example, consider a script that processes each day's worth of data at a time. For that you'd set each of the fields as follows: * last_modified_since to the start of the day * last_modified_before to the end of the day max-time-elapsed-since-last-modification=dolor Ensures that objects are not transferred if a specific maximum time has elapsed since the \"last modification time\". When a TransferOperation begins, objects with a \"last modification time\" are transferred only if the elapsed time between the start_time of the TransferOperation and the \"last modification time\" of the object is less than the value of max_time_elapsed_since_last_modification`. Objects that do not have a \"last modification time\" are also transferred. min-time-elapsed-since-last-modification=et Ensures that objects are not transferred until a specific minimum time has elapsed after the \"last modification time\". When a TransferOperation begins, objects with a \"last modification time\" are transferred only if the elapsed time between the start_time of the TransferOperation and the \"last modification time\" of the object is equal to or greater than the value of min_time_elapsed_since_last_modification`. Objects that do not have a \"last modification time\" are also transferred. ..posix-data-sink root-directory=sit Root directory path to the filesystem. ..posix-data-source root-directory=erat Root directory path to the filesystem. .. sink-agent-pool-name=sea Specifies the agent pool name associated with the posix data sink. When unspecified, the default name is used. source-agent-pool-name=nonumy Specifies the agent pool name associated with the posix data source. When unspecified, the default name is used. transfer-manifest location=et Specifies the path to the manifest in Cloud Storage. The Google-managed service account for the transfer must have storage.objects.get permission for this object. An example path is gs://bucket_name/path/manifest.csv . ..transfer-options delete-objects-from-source-after-transfer=true Whether objects should be deleted from the source after they are transferred to the sink. Note: This option and delete_objects_unique_in_sink are mutually exclusive. delete-objects-unique-in-sink=false Whether objects that exist only in the sink should be deleted. Note: This option and delete_objects_from_source_after_transfer are mutually exclusive. metadata-options acl=sit Specifies how each object's ACLs should be preserved for transfers between Google Cloud Storage buckets. If unspecified, the default behavior is the same as ACL_DESTINATION_BUCKET_DEFAULT. gid=aliquyam Specifies how each file's POSIX group ID (GID) attribute should be handled by the transfer. By default, GID is not preserved. Only applicable to transfers involving POSIX file systems, and ignored for other transfers. kms-key=eos Specifies how each object's Cloud KMS customer-managed encryption key (CMEK) is preserved for transfers between Google Cloud Storage buckets. If unspecified, the default behavior is the same as KMS_KEY_DESTINATION_BUCKET_DEFAULT. mode=at Specifies how each file's mode attribute should be handled by the transfer. By default, mode is not preserved. Only applicable to transfers involving POSIX file systems, and ignored for other transfers. storage-class=dolores Specifies the storage class to set on objects being transferred to Google Cloud Storage buckets. If unspecified, the default behavior is the same as STORAGE_CLASS_DESTINATION_BUCKET_DEFAULT. symlink=consetetur Specifies how symlinks should be handled by the transfer. By default, symlinks are not preserved. Only applicable to transfers involving POSIX file systems, and ignored for other transfers. temporary-hold=gubergren Specifies how each object's temporary hold status should be preserved for transfers between Google Cloud Storage buckets. If unspecified, the default behavior is the same as TEMPORARY_HOLD_PRESERVE. time-created=dolor Specifies how each object's timeCreated metadata is preserved for transfers. If unspecified, the default behavior is the same as TIME_CREATED_SKIP. uid=aliquyam Specifies how each file's POSIX user ID (UID) attribute should be handled by the transfer. By default, UID is not preserved. Only applicable to transfers involving POSIX file systems, and ignored for other transfers. .. overwrite-objects-already-existing-in-sink=true When to overwrite objects that already exist in the sink. The default is that only objects that are different from the source are ovewritten. If true, all objects in the sink whose name matches an object in the source are overwritten with the source object. overwrite-when=amet. When to overwrite objects that already exist in the sink. If not set, overwrite behavior is determined by overwrite_objects_already_existing_in_sink. .... update-transfer-job-field-mask=ipsum The field mask of the fields in transferJob that are to be updated in this request. Fields in transferJob that can be updated are: description, transfer_spec, notification_config, logging_config, and status. To update the transfer_spec of the job, a complete transfer specification must be provided. An incomplete specification missing any required fields is rejected with the error INVALID_ARGUMENT.","title":"Required Request Value"},{"location":"transfer-jobs_patch/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"transfer-jobs_patch/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"transfer-jobs_patch/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"transfer-jobs_run/","text":"Starts a new operation for the specified transfer job. A TransferJob has a maximum of one active TransferOperation . If this method is called while a TransferOperation is active, an error is returned. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> transfer-jobs run ... Required Scalar Argument <job-name> (string) Required. The name of the transfer job. Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: RunTransferJobRequest: project-id: string can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r . project-id=lorem Required. The ID of the Google Cloud project that owns the transfer job. About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Run"},{"location":"transfer-jobs_run/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> transfer-jobs run ...","title":"Scopes"},{"location":"transfer-jobs_run/#required-scalar-argument","text":"<job-name> (string) Required. The name of the transfer job.","title":"Required Scalar Argument"},{"location":"transfer-jobs_run/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: RunTransferJobRequest: project-id: string can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r . project-id=lorem Required. The ID of the Google Cloud project that owns the transfer job.","title":"Required Request Value"},{"location":"transfer-jobs_run/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"transfer-jobs_run/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"transfer-jobs_run/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"transfer-operations_cancel/","text":"Cancels a transfer. Use the transferOperations.get method to check if the cancellation succeeded or if the operation completed despite the cancel request. When you cancel an operation, the currently running transfer is interrupted. For recurring transfer jobs, the next instance of the transfer job will still run. For example, if your job is configured to run every day at 1pm and you cancel Monday's operation at 1:05pm, Monday's transfer will stop. However, a transfer job will still be attempted on Tuesday. This applies only to currently running operations. If an operation is not currently running, cancel does nothing. Caution: Canceling a transfer job can leave your data in an unknown state. We recommend that you restore the state at both the destination and the source after the cancel request completes so that your data is in a consistent state. When you cancel a job, the next job computes a delta of files and may repair any inconsistent state. For instance, if you run a job every day, and today's job found 10 new files and transferred five files before you canceled the job, tomorrow's transfer operation will compute a new delta with the five files that were not copied today plus any new files discovered tomorrow. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> transfer-operations cancel ... Required Scalar Argument <name> (string) The name of the operation resource to be cancelled. Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: CancelOperationRequest: can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Cancel"},{"location":"transfer-operations_cancel/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> transfer-operations cancel ...","title":"Scopes"},{"location":"transfer-operations_cancel/#required-scalar-argument","text":"<name> (string) The name of the operation resource to be cancelled.","title":"Required Scalar Argument"},{"location":"transfer-operations_cancel/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: CancelOperationRequest: can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.","title":"Required Request Value"},{"location":"transfer-operations_cancel/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"transfer-operations_cancel/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"transfer-operations_cancel/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"transfer-operations_get/","text":"Gets the latest state of a long-running operation. Clients can use this method to poll the operation result at intervals as recommended by the API service. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> transfer-operations get ... Required Scalar Argument <name> (string) The name of the operation resource. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Get"},{"location":"transfer-operations_get/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> transfer-operations get ...","title":"Scopes"},{"location":"transfer-operations_get/#required-scalar-argument","text":"<name> (string) The name of the operation resource.","title":"Required Scalar Argument"},{"location":"transfer-operations_get/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"transfer-operations_get/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"transfer-operations_list/","text":"Lists transfer operations. Operations are ordered by their creation time in reverse chronological order. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> transfer-operations list ... Required Scalar Arguments <name> (string) Required. The name of the type being listed; must be transferOperations . <filter> (string) Required. A list of query parameters specified as JSON text in the form of: {&#34;projectId&#34;:&#34;my_project_id&#34;, &#34;jobNames&#34;:[&#34;jobid1&#34;,&#34;jobid2&#34;,...], &#34;jobNamePattern&#34;: &#34;job_name_pattern&#34;, &#34;operationNames&#34;:[&#34;opid1&#34;,&#34;opid2&#34;,...], &#34;operationNamePattern&#34;: &#34;operation_name_pattern&#34;, &#34;minCreationTime&#34;: &#34;min_creation_time&#34;, &#34;maxCreationTime&#34;: &#34;max_creation_time&#34;, &#34;transferStatuses&#34;:[&#34;status1&#34;,&#34;status2&#34;,...]} Since jobNames , operationNames , and transferStatuses support multiple values, they must be specified with array notation. projectId is the only argument that is required. If specified, jobNamePattern and operationNamePattern must match the full job or operation name respectively. '*' is a wildcard matching 0 or more characters. minCreationTime and maxCreationTime should be timestamps encoded as a string in the RFC 3339 format. The valid values for transferStatuses are case-insensitive: IN_PROGRESS, PAUSED, SUCCESS, FAILED, and ABORTED. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional Method Properties You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p page-size=integer The list page size. The max allowed value is 256. -p page-token=string The list page token. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"List"},{"location":"transfer-operations_list/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> transfer-operations list ...","title":"Scopes"},{"location":"transfer-operations_list/#required-scalar-arguments","text":"<name> (string) Required. The name of the type being listed; must be transferOperations . <filter> (string) Required. A list of query parameters specified as JSON text in the form of: {&#34;projectId&#34;:&#34;my_project_id&#34;, &#34;jobNames&#34;:[&#34;jobid1&#34;,&#34;jobid2&#34;,...], &#34;jobNamePattern&#34;: &#34;job_name_pattern&#34;, &#34;operationNames&#34;:[&#34;opid1&#34;,&#34;opid2&#34;,...], &#34;operationNamePattern&#34;: &#34;operation_name_pattern&#34;, &#34;minCreationTime&#34;: &#34;min_creation_time&#34;, &#34;maxCreationTime&#34;: &#34;max_creation_time&#34;, &#34;transferStatuses&#34;:[&#34;status1&#34;,&#34;status2&#34;,...]} Since jobNames , operationNames , and transferStatuses support multiple values, they must be specified with array notation. projectId is the only argument that is required. If specified, jobNamePattern and operationNamePattern must match the full job or operation name respectively. '*' is a wildcard matching 0 or more characters. minCreationTime and maxCreationTime should be timestamps encoded as a string in the RFC 3339 format. The valid values for transferStatuses are case-insensitive: IN_PROGRESS, PAUSED, SUCCESS, FAILED, and ABORTED.","title":"Required Scalar Arguments"},{"location":"transfer-operations_list/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"transfer-operations_list/#optional-method-properties","text":"You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p page-size=integer The list page size. The max allowed value is 256. -p page-token=string The list page token.","title":"Optional Method Properties"},{"location":"transfer-operations_list/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"transfer-operations_pause/","text":"Pauses a transfer operation. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> transfer-operations pause ... Required Scalar Argument <name> (string) Required. The name of the transfer operation. Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: PauseTransferOperationRequest: can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Pause"},{"location":"transfer-operations_pause/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> transfer-operations pause ...","title":"Scopes"},{"location":"transfer-operations_pause/#required-scalar-argument","text":"<name> (string) Required. The name of the transfer operation.","title":"Required Scalar Argument"},{"location":"transfer-operations_pause/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: PauseTransferOperationRequest: can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.","title":"Required Request Value"},{"location":"transfer-operations_pause/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"transfer-operations_pause/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"transfer-operations_pause/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"transfer-operations_resume/","text":"Resumes a transfer operation that is paused. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> transfer-operations resume ... Required Scalar Argument <name> (string) Required. The name of the transfer operation. Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: ResumeTransferOperationRequest: can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Resume"},{"location":"transfer-operations_resume/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: storagetransfer1 --scope <scope> transfer-operations resume ...","title":"Scopes"},{"location":"transfer-operations_resume/#required-scalar-argument","text":"<name> (string) Required. The name of the transfer operation.","title":"Required Scalar Argument"},{"location":"transfer-operations_resume/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: ResumeTransferOperationRequest: can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.","title":"Required Request Value"},{"location":"transfer-operations_resume/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"transfer-operations_resume/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"transfer-operations_resume/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"}]}