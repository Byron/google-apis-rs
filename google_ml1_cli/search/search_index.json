{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The ml1 command-line interface (CLI) allows to use most features of the Google Cloud Machine Learning Engine service from the comfort of your terminal. By default all output is printed to standard out, but flags can be set to direct it into a file independent of your shell's capabilities. Errors will be printed to standard error, and cause the program's exit code to be non-zero. If data-structures are requested, these will be returned as pretty-printed JSON, to be useful as input to other tools. Everything else about the Cloud Machine Learning Engine API can be found at the official documentation site . Installation and Source Code Install the command-line interface with cargo using: cargo install google-ml1-cli Find the source code on github . Usage This documentation was generated from the Cloud Machine Learning Engine API at revision 20240127 . The CLI is at version 5.0.4 . ml1 [options] projects explain <name> (-r <kv>)... [-p <v>]... [-o <out>] get-config <name> [-p <v>]... [-o <out>] jobs-cancel <name> (-r <kv>)... [-p <v>]... [-o <out>] jobs-create <parent> (-r <kv>)... [-p <v>]... [-o <out>] jobs-get <name> [-p <v>]... [-o <out>] jobs-get-iam-policy <resource> [-p <v>]... [-o <out>] jobs-list <parent> [-p <v>]... [-o <out>] jobs-patch <name> (-r <kv>)... [-p <v>]... [-o <out>] jobs-set-iam-policy <resource> (-r <kv>)... [-p <v>]... [-o <out>] jobs-test-iam-permissions <resource> (-r <kv>)... [-p <v>]... [-o <out>] locations-get <name> [-p <v>]... [-o <out>] locations-list <parent> [-p <v>]... [-o <out>] locations-operations-cancel <name> [-p <v>]... [-o <out>] locations-operations-get <name> [-p <v>]... [-o <out>] locations-studies-create <parent> (-r <kv>)... [-p <v>]... [-o <out>] locations-studies-delete <name> [-p <v>]... [-o <out>] locations-studies-get <name> [-p <v>]... [-o <out>] locations-studies-list <parent> [-p <v>]... [-o <out>] locations-studies-trials-add-measurement <name> (-r <kv>)... [-p <v>]... [-o <out>] locations-studies-trials-check-early-stopping-state <name> (-r <kv>)... [-p <v>]... [-o <out>] locations-studies-trials-complete <name> (-r <kv>)... [-p <v>]... [-o <out>] locations-studies-trials-create <parent> (-r <kv>)... [-p <v>]... [-o <out>] locations-studies-trials-delete <name> [-p <v>]... [-o <out>] locations-studies-trials-get <name> [-p <v>]... [-o <out>] locations-studies-trials-list <parent> [-p <v>]... [-o <out>] locations-studies-trials-list-optimal-trials <parent> (-r <kv>)... [-p <v>]... [-o <out>] locations-studies-trials-stop <name> (-r <kv>)... [-p <v>]... [-o <out>] locations-studies-trials-suggest <parent> (-r <kv>)... [-p <v>]... [-o <out>] models-create <parent> (-r <kv>)... [-p <v>]... [-o <out>] models-delete <name> [-p <v>]... [-o <out>] models-get <name> [-p <v>]... [-o <out>] models-get-iam-policy <resource> [-p <v>]... [-o <out>] models-list <parent> [-p <v>]... [-o <out>] models-patch <name> (-r <kv>)... [-p <v>]... [-o <out>] models-set-iam-policy <resource> (-r <kv>)... [-p <v>]... [-o <out>] models-test-iam-permissions <resource> (-r <kv>)... [-p <v>]... [-o <out>] models-versions-create <parent> (-r <kv>)... [-p <v>]... [-o <out>] models-versions-delete <name> [-p <v>]... [-o <out>] models-versions-get <name> [-p <v>]... [-o <out>] models-versions-list <parent> [-p <v>]... [-o <out>] models-versions-patch <name> (-r <kv>)... [-p <v>]... [-o <out>] models-versions-set-default <name> (-r <kv>)... [-p <v>]... [-o <out>] operations-cancel <name> [-p <v>]... [-o <out>] operations-get <name> [-p <v>]... [-o <out>] operations-list <name> [-p <v>]... [-o <out>] predict <name> (-r <kv>)... [-p <v>]... [-o <out>] ml1 --help Configuration: [--scope <url>]... Specify the authentication a method should be executed in. Each scope requires the user to grant this application permission to use it. If unset, it defaults to the shortest scope url for a particular method. --config-dir <folder> A directory into which we will store our persistent data. Defaults to a user-writable directory that we will create during the first invocation. [default: ~/.google-service-cli] Configuration The program will store all persistent data in the ~/.google-service-cli directory in JSON files prefixed with ml1- . You can change the directory used to store configuration with the --config-dir flag on a per-invocation basis. More information about the various kinds of persistent data are given in the following paragraphs. Authentication Most APIs require a user to authenticate any request. If this is the case, the scope determines the set of permissions granted. The granularity of these is usually no more than read-only or full-access . If not set, the system will automatically select the smallest feasible scope, e.g. when invoking a method that is read-only, it will ask only for a read-only scope. You may use the --scope flag to specify a scope directly. All applicable scopes are documented in the respective method's CLI documentation. The first time a scope is used, the user is asked for permission. Follow the instructions given by the CLI to grant permissions, or to decline. If a scope was authenticated by the user, the respective information will be stored as JSON in the configuration directory, e.g. ~/.google-service-cli/ml1-token-<scope-hash>.json . No manual management of these tokens is necessary. To revoke granted authentication, please refer to the official documentation . Application Secrets In order to allow any application to use Google services, it will need to be registered using the Google Developer Console . APIs the application may use are then enabled for it one by one. Most APIs can be used for free and have a daily quota. To allow more comfortable usage of the CLI without forcing anyone to register an own application, the CLI comes with a default application secret that is configured accordingly. This also means that heavy usage all around the world may deplete the daily quota. You can workaround this limitation by putting your own secrets file at this location: ~/.google-service-cli/ml1-secret.json , assuming that the required ml API was enabled for it. Such a secret file can be downloaded in the Google Developer Console at APIs & auth -> Credentials -> Download JSON and used as is. Learn more about how to setup Google projects and enable APIs using the official documentation . Debugging Even though the CLI does its best to provide usable error messages, sometimes it might be desirable to know what exactly led to a particular issue. This is done by allowing all client-server communication to be output to standard error as-is . The --debug flag will print errors using the Debug representation to standard error. You may consider redirecting standard error into a file for ease of use, e.g. ml1 --debug <resource> <method> [options] 2>debug.txt .","title":"Home"},{"location":"#installation-and-source-code","text":"Install the command-line interface with cargo using: cargo install google-ml1-cli Find the source code on github .","title":"Installation and Source Code"},{"location":"#usage","text":"This documentation was generated from the Cloud Machine Learning Engine API at revision 20240127 . The CLI is at version 5.0.4 . ml1 [options] projects explain <name> (-r <kv>)... [-p <v>]... [-o <out>] get-config <name> [-p <v>]... [-o <out>] jobs-cancel <name> (-r <kv>)... [-p <v>]... [-o <out>] jobs-create <parent> (-r <kv>)... [-p <v>]... [-o <out>] jobs-get <name> [-p <v>]... [-o <out>] jobs-get-iam-policy <resource> [-p <v>]... [-o <out>] jobs-list <parent> [-p <v>]... [-o <out>] jobs-patch <name> (-r <kv>)... [-p <v>]... [-o <out>] jobs-set-iam-policy <resource> (-r <kv>)... [-p <v>]... [-o <out>] jobs-test-iam-permissions <resource> (-r <kv>)... [-p <v>]... [-o <out>] locations-get <name> [-p <v>]... [-o <out>] locations-list <parent> [-p <v>]... [-o <out>] locations-operations-cancel <name> [-p <v>]... [-o <out>] locations-operations-get <name> [-p <v>]... [-o <out>] locations-studies-create <parent> (-r <kv>)... [-p <v>]... [-o <out>] locations-studies-delete <name> [-p <v>]... [-o <out>] locations-studies-get <name> [-p <v>]... [-o <out>] locations-studies-list <parent> [-p <v>]... [-o <out>] locations-studies-trials-add-measurement <name> (-r <kv>)... [-p <v>]... [-o <out>] locations-studies-trials-check-early-stopping-state <name> (-r <kv>)... [-p <v>]... [-o <out>] locations-studies-trials-complete <name> (-r <kv>)... [-p <v>]... [-o <out>] locations-studies-trials-create <parent> (-r <kv>)... [-p <v>]... [-o <out>] locations-studies-trials-delete <name> [-p <v>]... [-o <out>] locations-studies-trials-get <name> [-p <v>]... [-o <out>] locations-studies-trials-list <parent> [-p <v>]... [-o <out>] locations-studies-trials-list-optimal-trials <parent> (-r <kv>)... [-p <v>]... [-o <out>] locations-studies-trials-stop <name> (-r <kv>)... [-p <v>]... [-o <out>] locations-studies-trials-suggest <parent> (-r <kv>)... [-p <v>]... [-o <out>] models-create <parent> (-r <kv>)... [-p <v>]... [-o <out>] models-delete <name> [-p <v>]... [-o <out>] models-get <name> [-p <v>]... [-o <out>] models-get-iam-policy <resource> [-p <v>]... [-o <out>] models-list <parent> [-p <v>]... [-o <out>] models-patch <name> (-r <kv>)... [-p <v>]... [-o <out>] models-set-iam-policy <resource> (-r <kv>)... [-p <v>]... [-o <out>] models-test-iam-permissions <resource> (-r <kv>)... [-p <v>]... [-o <out>] models-versions-create <parent> (-r <kv>)... [-p <v>]... [-o <out>] models-versions-delete <name> [-p <v>]... [-o <out>] models-versions-get <name> [-p <v>]... [-o <out>] models-versions-list <parent> [-p <v>]... [-o <out>] models-versions-patch <name> (-r <kv>)... [-p <v>]... [-o <out>] models-versions-set-default <name> (-r <kv>)... [-p <v>]... [-o <out>] operations-cancel <name> [-p <v>]... [-o <out>] operations-get <name> [-p <v>]... [-o <out>] operations-list <name> [-p <v>]... [-o <out>] predict <name> (-r <kv>)... [-p <v>]... [-o <out>] ml1 --help Configuration: [--scope <url>]... Specify the authentication a method should be executed in. Each scope requires the user to grant this application permission to use it. If unset, it defaults to the shortest scope url for a particular method. --config-dir <folder> A directory into which we will store our persistent data. Defaults to a user-writable directory that we will create during the first invocation. [default: ~/.google-service-cli]","title":"Usage"},{"location":"#configuration","text":"The program will store all persistent data in the ~/.google-service-cli directory in JSON files prefixed with ml1- . You can change the directory used to store configuration with the --config-dir flag on a per-invocation basis. More information about the various kinds of persistent data are given in the following paragraphs.","title":"Configuration"},{"location":"#authentication","text":"Most APIs require a user to authenticate any request. If this is the case, the scope determines the set of permissions granted. The granularity of these is usually no more than read-only or full-access . If not set, the system will automatically select the smallest feasible scope, e.g. when invoking a method that is read-only, it will ask only for a read-only scope. You may use the --scope flag to specify a scope directly. All applicable scopes are documented in the respective method's CLI documentation. The first time a scope is used, the user is asked for permission. Follow the instructions given by the CLI to grant permissions, or to decline. If a scope was authenticated by the user, the respective information will be stored as JSON in the configuration directory, e.g. ~/.google-service-cli/ml1-token-<scope-hash>.json . No manual management of these tokens is necessary. To revoke granted authentication, please refer to the official documentation .","title":"Authentication"},{"location":"#application-secrets","text":"In order to allow any application to use Google services, it will need to be registered using the Google Developer Console . APIs the application may use are then enabled for it one by one. Most APIs can be used for free and have a daily quota. To allow more comfortable usage of the CLI without forcing anyone to register an own application, the CLI comes with a default application secret that is configured accordingly. This also means that heavy usage all around the world may deplete the daily quota. You can workaround this limitation by putting your own secrets file at this location: ~/.google-service-cli/ml1-secret.json , assuming that the required ml API was enabled for it. Such a secret file can be downloaded in the Google Developer Console at APIs & auth -> Credentials -> Download JSON and used as is. Learn more about how to setup Google projects and enable APIs using the official documentation .","title":"Application Secrets"},{"location":"#debugging","text":"Even though the CLI does its best to provide usable error messages, sometimes it might be desirable to know what exactly led to a particular issue. This is done by allowing all client-server communication to be output to standard error as-is . The --debug flag will print errors using the Debug representation to standard error. You may consider redirecting standard error into a file for ease of use, e.g. ml1 --debug <resource> <method> [options] 2>debug.txt .","title":"Debugging"},{"location":"projects_explain/","text":"Performs explanation on the data in the request. {% dynamic include \"/ai-platform/includes/___explain-request\" %} Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects explain ... Required Scalar Argument <name> (string) Required. The resource name of a model or a version. Authorization: requires the predict permission on the specified resource. Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__ExplainRequest: http-body: content-type: string data: string can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r .http-body content-type=et The HTTP Content-Type header value specifying the content type of the body. data=magna The HTTP request/response body as raw binary. About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Explain"},{"location":"projects_explain/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects explain ...","title":"Scopes"},{"location":"projects_explain/#required-scalar-argument","text":"<name> (string) Required. The resource name of a model or a version. Authorization: requires the predict permission on the specified resource.","title":"Required Scalar Argument"},{"location":"projects_explain/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__ExplainRequest: http-body: content-type: string data: string can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r .http-body content-type=et The HTTP Content-Type header value specifying the content type of the body. data=magna The HTTP request/response body as raw binary.","title":"Required Request Value"},{"location":"projects_explain/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"projects_explain/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_explain/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_get-config/","text":"Get the service account information associated with your project. You need this information in order to grant the service account permissions for the Google Cloud Storage location where you put your model training code for training the model with Google Cloud Machine Learning. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects get-config ... Required Scalar Argument <name> (string) Required. The project name. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Get Config"},{"location":"projects_get-config/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects get-config ...","title":"Scopes"},{"location":"projects_get-config/#required-scalar-argument","text":"<name> (string) Required. The project name.","title":"Required Scalar Argument"},{"location":"projects_get-config/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_get-config/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_jobs-cancel/","text":"Cancels a running job. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects jobs-cancel ... Required Scalar Argument <name> (string) Required. The name of the job to cancel. Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__CancelJobRequest: can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Jobs Cancel"},{"location":"projects_jobs-cancel/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects jobs-cancel ...","title":"Scopes"},{"location":"projects_jobs-cancel/#required-scalar-argument","text":"<name> (string) Required. The name of the job to cancel.","title":"Required Scalar Argument"},{"location":"projects_jobs-cancel/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__CancelJobRequest: can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.","title":"Required Request Value"},{"location":"projects_jobs-cancel/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"projects_jobs-cancel/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_jobs-cancel/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_jobs-create/","text":"Creates a training or a batch prediction job. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects jobs-create ... Required Scalar Argument <parent> (string) Required. The project name. Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__Job: create-time: string end-time: string error-message: string etag: string job-id: string job-position: string labels: { string: string } prediction-input: batch-size: string data-format: string input-paths: [string] max-worker-count: int64 model-name: string output-data-format: string output-path: string region: string runtime-version: string signature-name: string uri: string version-name: string prediction-output: error-count: int64 node-hours: number output-path: string prediction-count: int64 start-time: string state: string training-input: args: [string] enable-web-access: boolean encryption-config: kms-key-name: string evaluator-config: accelerator-config: count: string type: string container-args: [string] container-command: [string] disk-config: boot-disk-size-gb: integer boot-disk-type: string image-uri: string tpu-tf-version: string evaluator-count: int64 evaluator-type: string hyperparameters: algorithm: string enable-trial-early-stopping: boolean goal: string hyperparameter-metric-tag: string max-failed-trials: integer max-parallel-trials: integer max-trials: integer resume-previous-job-id: string job-dir: string master-config: accelerator-config: count: string type: string container-args: [string] container-command: [string] disk-config: boot-disk-size-gb: integer boot-disk-type: string image-uri: string tpu-tf-version: string master-type: string network: string package-uris: [string] parameter-server-config: accelerator-config: count: string type: string container-args: [string] container-command: [string] disk-config: boot-disk-size-gb: integer boot-disk-type: string image-uri: string tpu-tf-version: string parameter-server-count: int64 parameter-server-type: string python-module: string python-version: string region: string runtime-version: string scale-tier: string scheduling: max-running-time: string max-wait-time: string priority: integer service-account: string use-chief-in-tf-config: boolean worker-config: accelerator-config: count: string type: string container-args: [string] container-command: [string] disk-config: boot-disk-size-gb: integer boot-disk-type: string image-uri: string tpu-tf-version: string worker-count: int64 worker-type: string training-output: built-in-algorithm-output: framework: string model-path: string python-version: string runtime-version: string completed-trial-count: int64 consumed-ml-units: number hyperparameter-metric-tag: string is-built-in-algorithm-job: boolean is-hyperparameter-tuning-job: boolean web-access-uris: { string: string } can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r . create-time=no Output only. When the job was created. end-time=ipsum Output only. When the job processing was completed. error-message=voluptua. Output only. The details of a failure or a cancellation. etag=at etag is used for optimistic concurrency control as a way to help prevent simultaneous updates of a job from overwriting each other. It is strongly suggested that systems make use of the etag in the read-modify-write cycle to perform job updates in order to avoid race conditions: An etag is returned in the response to GetJob , and systems are expected to put that etag in the request to UpdateJob to ensure that their change will be applied to the same version of the job. job-id=sanctus Required. The user-specified id of the job. job-position=sed Output only. It's only effect when the job is in QUEUED state. If it's positive, it indicates the job's position in the job scheduler. It's 0 when the job is already scheduled. labels=key=amet. Optional. One or more labels that you can add, to organize your jobs. Each label is a key-value pair, where both the key and the value are arbitrary strings that you supply. For more information, see the documentation on using labels. the value will be associated with the given key prediction-input batch-size=takimata Optional. Number of records per batch, defaults to 64. The service will buffer batch_size number of records in memory before invoking one Tensorflow prediction call internally. So take the record size and memory available into consideration when setting this parameter. data-format=amet. Required. The format of the input data files. input-paths=duo Required. The Cloud Storage location of the input data files. May contain wildcards. Each invocation of this argument appends the given value to the array. max-worker-count=-55 Optional. The maximum number of workers to be used for parallel processing. Defaults to 10 if not specified. model-name=gubergren Use this field if you want to use the default version for the specified model. The string must use the following format: &#34;projects/YOUR_PROJECT/models/YOUR_MODEL&#34; output-data-format=lorem Optional. Format of the output data files, defaults to JSON. output-path=gubergren Required. The output Google Cloud Storage location. region=eos Required. The Google Compute Engine region to run the prediction job in. See the available regions for AI Platform services. runtime-version=dolor Optional. The AI Platform runtime version to use for this batch prediction. If not set, AI Platform will pick the runtime version used during the CreateVersion request for this model version, or choose the latest stable version when model version information is not available such as when the model is specified by uri. signature-name=ea Optional. The name of the signature defined in the SavedModel to use for this job. Please refer to SavedModel for information about how to use signatures. Defaults to DEFAULT_SERVING_SIGNATURE_DEF_KEY , which is \"serving_default\". uri=ipsum Use this field if you want to specify a Google Cloud Storage path for the model to use. version-name=invidunt Use this field if you want to specify a version of the model to use. The string is formatted the same way as model_version , with the addition of the version information: &#34;projects/YOUR_PROJECT/models/YOUR_MODEL/versions/YOUR_VERSION&#34; ..prediction-output error-count=-47 The number of data instances which resulted in errors. node-hours=0.8204376297831348 Node hours used by the batch prediction job. output-path=ipsum The output Google Cloud Storage location provided at the job creation time. prediction-count=-93 The number of generated predictions. .. start-time=ut Output only. When the job processing was started. state=gubergren Output only. The detailed state of a job. training-input args=rebum. Optional. Command-line arguments passed to the training application when it starts. If your job uses a custom container, then the arguments are passed to the container's ENTRYPOINT command. Each invocation of this argument appends the given value to the array. enable-web-access=true Optional. Whether you want AI Platform Training to enable interactive shell access to training containers. If set to true , you can access interactive shells at the URIs given by TrainingOutput.web_access_uris or HyperparameterOutput.web_access_uris (within TrainingOutput.trials). encryption-config kms-key-name=ipsum The Cloud KMS resource identifier of the customer-managed encryption key used to protect a resource, such as a training job. It has the following format: projects/{PROJECT_ID}/locations/{REGION}/keyRings/{KEY_RING_NAME}/cryptoKeys/{KEY_NAME} ..evaluator-config.accelerator-config count=ipsum The number of accelerators to attach to each machine running the job. type=est The type of accelerator to use. .. container-args=gubergren Arguments to the entrypoint command. The following rules apply for container_command and container_args: - If you do not supply command or args: The defaults defined in the Docker image are used. - If you supply a command but no args: The default EntryPoint and the default Cmd defined in the Docker image are ignored. Your command is run without any arguments. - If you supply only args: The default Entrypoint defined in the Docker image is run with the args that you supplied. - If you supply a command and args: The default Entrypoint and the default Cmd defined in the Docker image are ignored. Your command is run with your args. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. container-command=ea The command with which the replica's custom container is run. If provided, it will override default ENTRYPOINT of the docker image. If not provided, the docker image's ENTRYPOINT is used. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. disk-config boot-disk-size-gb=2 Size in GB of the boot disk (default is 100GB). boot-disk-type=lorem Type of the boot disk (default is \"pd-ssd\"). Valid values: \"pd-ssd\" (Persistent Disk Solid State Drive) or \"pd-standard\" (Persistent Disk Hard Disk Drive). .. image-uri=eos The Docker image to run on the replica. This image must be in Container Registry. Learn more about configuring custom containers . tpu-tf-version=labore The AI Platform runtime version that includes a TensorFlow version matching the one used in the custom container. This field is required if the replica is a TPU worker that uses a custom container. Otherwise, do not specify this field. This must be a runtime version that currently supports training with TPUs . Note that the version of TensorFlow included in a runtime version may differ from the numbering of the runtime version itself, because it may have a different patch version . In this field, you must specify the runtime version (TensorFlow minor version). For example, if your custom container runs TensorFlow 1.x.y , specify 1.x . .. evaluator-count=-43 Optional. The number of evaluator replicas to use for the training job. Each replica in the cluster will be of the type specified in evaluator_type . This value can only be used when scale_tier is set to CUSTOM . If you set this value, you must also set evaluator_type . The default value is zero. evaluator-type=duo Optional. Specifies the type of virtual machine to use for your training job's evaluator nodes. The supported values are the same as those described in the entry for masterType . This value must be consistent with the category of machine type that masterType uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. This value must be present when scaleTier is set to CUSTOM and evaluatorCount is greater than zero. hyperparameters algorithm=sed Optional. The search algorithm specified for the hyperparameter tuning job. Uses the default AI Platform hyperparameter tuning algorithm if unspecified. enable-trial-early-stopping=true Optional. Indicates if the hyperparameter tuning job enables auto trial early stopping. goal=stet Required. The type of goal to use for tuning. Available types are MAXIMIZE and MINIMIZE . Defaults to MAXIMIZE . hyperparameter-metric-tag=kasd Optional. The TensorFlow summary tag name to use for optimizing trials. For current versions of TensorFlow, this tag name should exactly match what is shown in TensorBoard, including all scopes. For versions of TensorFlow prior to 0.12, this should be only the tag passed to tf.Summary. By default, \"training/hptuning/metric\" will be used. max-failed-trials=77 Optional. The number of failed trials that need to be seen before failing the hyperparameter tuning job. You can specify this field to override the default failing criteria for AI Platform hyperparameter tuning jobs. Defaults to zero, which means the service decides when a hyperparameter job should fail. max-parallel-trials=58 Optional. The number of training trials to run concurrently. You can reduce the time it takes to perform hyperparameter tuning by adding trials in parallel. However, each trail only benefits from the information gained in completed trials. That means that a trial does not get access to the results of trials running at the same time, which could reduce the quality of the overall optimization. Each trial will use the same scale tier and machine types. Defaults to one. max-trials=77 Optional. How many training trials should be attempted to optimize the specified hyperparameters. Defaults to one. resume-previous-job-id=et Optional. The prior hyperparameter tuning job id that users hope to continue with. The job id will be used to find the corresponding vizier study guid and resume the study. .. job-dir=vero Optional. A Google Cloud Storage path in which to store training outputs and other data needed for training. This path is passed to your TensorFlow program as the '--job-dir' command-line argument. The benefit of specifying this field is that Cloud ML validates the path for use in training. master-config.accelerator-config count=erat The number of accelerators to attach to each machine running the job. type=sed The type of accelerator to use. .. container-args=duo Arguments to the entrypoint command. The following rules apply for container_command and container_args: - If you do not supply command or args: The defaults defined in the Docker image are used. - If you supply a command but no args: The default EntryPoint and the default Cmd defined in the Docker image are ignored. Your command is run without any arguments. - If you supply only args: The default Entrypoint defined in the Docker image is run with the args that you supplied. - If you supply a command and args: The default Entrypoint and the default Cmd defined in the Docker image are ignored. Your command is run with your args. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. container-command=dolore The command with which the replica's custom container is run. If provided, it will override default ENTRYPOINT of the docker image. If not provided, the docker image's ENTRYPOINT is used. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. disk-config boot-disk-size-gb=79 Size in GB of the boot disk (default is 100GB). boot-disk-type=voluptua. Type of the boot disk (default is \"pd-ssd\"). Valid values: \"pd-ssd\" (Persistent Disk Solid State Drive) or \"pd-standard\" (Persistent Disk Hard Disk Drive). .. image-uri=amet. The Docker image to run on the replica. This image must be in Container Registry. Learn more about configuring custom containers . tpu-tf-version=consetetur The AI Platform runtime version that includes a TensorFlow version matching the one used in the custom container. This field is required if the replica is a TPU worker that uses a custom container. Otherwise, do not specify this field. This must be a runtime version that currently supports training with TPUs . Note that the version of TensorFlow included in a runtime version may differ from the numbering of the runtime version itself, because it may have a different patch version . In this field, you must specify the runtime version (TensorFlow minor version). For example, if your custom container runs TensorFlow 1.x.y , specify 1.x . .. master-type=diam Optional. Specifies the type of virtual machine to use for your training job's master worker. You must specify this field when scaleTier is set to CUSTOM . You can use certain Compute Engine machine types directly in this field. See the list of compatible Compute Engine machine types . Alternatively, you can use the certain legacy machine types in this field. See the list of legacy machine types . Finally, if you want to use a TPU for training, specify cloud_tpu in this field. Learn more about the special configuration options for training with TPUs . network=dolor Optional. The full name of the Compute Engine network to which the Job is peered. For example, projects/12345/global/networks/myVPC . The format of this field is projects/{project}/global/networks/{network} , where {project} is a project number (like 12345 ) and {network} is network name. Private services access must already be configured for the network. If left unspecified, the Job is not peered with any network. Learn about using VPC Network Peering. . package-uris=et Required. The Google Cloud Storage location of the packages with the training program and any additional dependencies. The maximum number of package URIs is 100. Each invocation of this argument appends the given value to the array. parameter-server-config.accelerator-config count=et The number of accelerators to attach to each machine running the job. type=sadipscing The type of accelerator to use. .. container-args=stet Arguments to the entrypoint command. The following rules apply for container_command and container_args: - If you do not supply command or args: The defaults defined in the Docker image are used. - If you supply a command but no args: The default EntryPoint and the default Cmd defined in the Docker image are ignored. Your command is run without any arguments. - If you supply only args: The default Entrypoint defined in the Docker image is run with the args that you supplied. - If you supply a command and args: The default Entrypoint and the default Cmd defined in the Docker image are ignored. Your command is run with your args. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. container-command=dolor The command with which the replica's custom container is run. If provided, it will override default ENTRYPOINT of the docker image. If not provided, the docker image's ENTRYPOINT is used. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. disk-config boot-disk-size-gb=81 Size in GB of the boot disk (default is 100GB). boot-disk-type=vero Type of the boot disk (default is \"pd-ssd\"). Valid values: \"pd-ssd\" (Persistent Disk Solid State Drive) or \"pd-standard\" (Persistent Disk Hard Disk Drive). .. image-uri=vero The Docker image to run on the replica. This image must be in Container Registry. Learn more about configuring custom containers . tpu-tf-version=invidunt The AI Platform runtime version that includes a TensorFlow version matching the one used in the custom container. This field is required if the replica is a TPU worker that uses a custom container. Otherwise, do not specify this field. This must be a runtime version that currently supports training with TPUs . Note that the version of TensorFlow included in a runtime version may differ from the numbering of the runtime version itself, because it may have a different patch version . In this field, you must specify the runtime version (TensorFlow minor version). For example, if your custom container runs TensorFlow 1.x.y , specify 1.x . .. parameter-server-count=-65 Optional. The number of parameter server replicas to use for the training job. Each replica in the cluster will be of the type specified in parameter_server_type . This value can only be used when scale_tier is set to CUSTOM . If you set this value, you must also set parameter_server_type . The default value is zero. parameter-server-type=vero Optional. Specifies the type of virtual machine to use for your training job's parameter server. The supported values are the same as those described in the entry for master_type . This value must be consistent with the category of machine type that masterType uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. This value must be present when scaleTier is set to CUSTOM and parameter_server_count is greater than zero. python-module=elitr Required. The Python module name to run after installing the packages. python-version=lorem Optional. The version of Python used in training. You must either specify this field or specify masterConfig.imageUri . The following Python versions are available: * Python '3.7' is available when runtime_version is set to '1.15' or later. * Python '3.5' is available when runtime_version is set to a version from '1.4' to '1.14'. * Python '2.7' is available when runtime_version is set to '1.15' or earlier. Read more about the Python versions available for each runtime version . region=diam Required. The region to run the training job in. See the available regions for AI Platform Training. runtime-version=no Optional. The AI Platform runtime version to use for training. You must either specify this field or specify masterConfig.imageUri . For more information, see the runtime version list and learn how to manage runtime versions . scale-tier=ipsum Required. Specifies the machine types, the number of replicas for workers and parameter servers. scheduling max-running-time=accusam Optional. The maximum job running time, expressed in seconds. The field can contain up to nine fractional digits, terminated by s . If not specified, this field defaults to 604800s (seven days). If the training job is still running after this duration, AI Platform Training cancels it. The duration is measured from when the job enters the RUNNING state; therefore it does not overlap with the duration limited by Scheduling.max_wait_time. For example, if you want to ensure your job runs for no more than 2 hours, set this field to 7200s (2 hours * 60 minutes / hour * 60 seconds / minute). If you submit your training job using the gcloud tool, you can specify this field in a config.yaml file . For example: yaml trainingInput: scheduling: maxRunningTime: 7200s max-wait-time=takimata Optional. The maximum job wait time, expressed in seconds. The field can contain up to nine fractional digits, terminated by s . If not specified, there is no limit to the wait time. The minimum for this field is 1800s (30 minutes). If the training job has not entered the RUNNING state after this duration, AI Platform Training cancels it. After the job begins running, it can no longer be cancelled due to the maximum wait time. Therefore the duration limited by this field does not overlap with the duration limited by Scheduling.max_running_time. For example, if the job temporarily stops running and retries due to a VM restart , this cannot lead to a maximum wait time cancellation. However, independently of this constraint, AI Platform Training might stop a job if there are too many retries due to exhausted resources in a region. The following example describes how you might use this field: To cancel your job if it doesn't start running within 1 hour, set this field to 3600s (1 hour * 60 minutes / hour * 60 seconds / minute). If the job is still in the QUEUED or PREPARING state after an hour of waiting, AI Platform Training cancels the job. If you submit your training job using the gcloud tool, you can specify this field in a config.yaml file . For example: yaml trainingInput: scheduling: maxWaitTime: 3600s priority=55 Optional. Job scheduling will be based on this priority, which in the range [0, 1000]. The bigger the number, the higher the priority. Default to 0 if not set. If there are multiple jobs requesting same type of accelerators, the high priority job will be scheduled prior to ones with low priority. .. service-account=voluptua. Optional. The email address of a service account to use when running the training appplication. You must have the iam.serviceAccounts.actAs permission for the specified service account. In addition, the AI Platform Training Google-managed service account must have the roles/iam.serviceAccountAdmin role for the specified service account. Learn more about configuring a service account. If not specified, the AI Platform Training Google-managed service account is used by default. use-chief-in-tf-config=false Optional. Use chief instead of master in the TF_CONFIG environment variable when training with a custom container. Defaults to false . Learn more about this field. This field has no effect for training jobs that don't use a custom container. worker-config.accelerator-config count=erat The number of accelerators to attach to each machine running the job. type=consetetur The type of accelerator to use. .. container-args=amet. Arguments to the entrypoint command. The following rules apply for container_command and container_args: - If you do not supply command or args: The defaults defined in the Docker image are used. - If you supply a command but no args: The default EntryPoint and the default Cmd defined in the Docker image are ignored. Your command is run without any arguments. - If you supply only args: The default Entrypoint defined in the Docker image is run with the args that you supplied. - If you supply a command and args: The default Entrypoint and the default Cmd defined in the Docker image are ignored. Your command is run with your args. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. container-command=sed The command with which the replica's custom container is run. If provided, it will override default ENTRYPOINT of the docker image. If not provided, the docker image's ENTRYPOINT is used. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. disk-config boot-disk-size-gb=92 Size in GB of the boot disk (default is 100GB). boot-disk-type=dolores Type of the boot disk (default is \"pd-ssd\"). Valid values: \"pd-ssd\" (Persistent Disk Solid State Drive) or \"pd-standard\" (Persistent Disk Hard Disk Drive). .. image-uri=gubergren The Docker image to run on the replica. This image must be in Container Registry. Learn more about configuring custom containers . tpu-tf-version=et The AI Platform runtime version that includes a TensorFlow version matching the one used in the custom container. This field is required if the replica is a TPU worker that uses a custom container. Otherwise, do not specify this field. This must be a runtime version that currently supports training with TPUs . Note that the version of TensorFlow included in a runtime version may differ from the numbering of the runtime version itself, because it may have a different patch version . In this field, you must specify the runtime version (TensorFlow minor version). For example, if your custom container runs TensorFlow 1.x.y , specify 1.x . .. worker-count=-23 Optional. The number of worker replicas to use for the training job. Each replica in the cluster will be of the type specified in worker_type . This value can only be used when scale_tier is set to CUSTOM . If you set this value, you must also set worker_type . The default value is zero. worker-type=voluptua. Optional. Specifies the type of virtual machine to use for your training job's worker nodes. The supported values are the same as those described in the entry for masterType . This value must be consistent with the category of machine type that masterType uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. If you use cloud_tpu for this value, see special instructions for configuring a custom TPU machine . This value must be present when scaleTier is set to CUSTOM and workerCount is greater than zero. ..training-output.built-in-algorithm-output framework=dolore Framework on which the built-in algorithm was trained. model-path=dolore The Cloud Storage path to the model/ directory where the training job saves the trained model. Only set for successful jobs that don't use hyperparameter tuning. python-version=dolore Python version on which the built-in algorithm was trained. runtime-version=voluptua. AI Platform runtime version on which the built-in algorithm was trained. .. completed-trial-count=-2 The number of hyperparameter tuning trials that completed successfully. Only set for hyperparameter tuning jobs. consumed-ml-units=0.6626374874296354 The amount of ML units consumed by the job. hyperparameter-metric-tag=lorem The TensorFlow summary tag name used for optimizing hyperparameter tuning trials. See HyperparameterSpec.hyperparameterMetricTag for more information. Only set for hyperparameter tuning jobs. is-built-in-algorithm-job=true Whether this job is a built-in Algorithm job. is-hyperparameter-tuning-job=true Whether this job is a hyperparameter tuning job. web-access-uris=key=sit Output only. URIs for accessing interactive shells (one URI for each training node). Only available if training_input.enable_web_access is true . The keys are names of each node in the training job; for example, master-replica-0 for the master node, worker-replica-0 for the first worker, and ps-replica-0 for the first parameter server. The values are the URIs for each node's interactive shell. the value will be associated with the given key About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Jobs Create"},{"location":"projects_jobs-create/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects jobs-create ...","title":"Scopes"},{"location":"projects_jobs-create/#required-scalar-argument","text":"<parent> (string) Required. The project name.","title":"Required Scalar Argument"},{"location":"projects_jobs-create/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__Job: create-time: string end-time: string error-message: string etag: string job-id: string job-position: string labels: { string: string } prediction-input: batch-size: string data-format: string input-paths: [string] max-worker-count: int64 model-name: string output-data-format: string output-path: string region: string runtime-version: string signature-name: string uri: string version-name: string prediction-output: error-count: int64 node-hours: number output-path: string prediction-count: int64 start-time: string state: string training-input: args: [string] enable-web-access: boolean encryption-config: kms-key-name: string evaluator-config: accelerator-config: count: string type: string container-args: [string] container-command: [string] disk-config: boot-disk-size-gb: integer boot-disk-type: string image-uri: string tpu-tf-version: string evaluator-count: int64 evaluator-type: string hyperparameters: algorithm: string enable-trial-early-stopping: boolean goal: string hyperparameter-metric-tag: string max-failed-trials: integer max-parallel-trials: integer max-trials: integer resume-previous-job-id: string job-dir: string master-config: accelerator-config: count: string type: string container-args: [string] container-command: [string] disk-config: boot-disk-size-gb: integer boot-disk-type: string image-uri: string tpu-tf-version: string master-type: string network: string package-uris: [string] parameter-server-config: accelerator-config: count: string type: string container-args: [string] container-command: [string] disk-config: boot-disk-size-gb: integer boot-disk-type: string image-uri: string tpu-tf-version: string parameter-server-count: int64 parameter-server-type: string python-module: string python-version: string region: string runtime-version: string scale-tier: string scheduling: max-running-time: string max-wait-time: string priority: integer service-account: string use-chief-in-tf-config: boolean worker-config: accelerator-config: count: string type: string container-args: [string] container-command: [string] disk-config: boot-disk-size-gb: integer boot-disk-type: string image-uri: string tpu-tf-version: string worker-count: int64 worker-type: string training-output: built-in-algorithm-output: framework: string model-path: string python-version: string runtime-version: string completed-trial-count: int64 consumed-ml-units: number hyperparameter-metric-tag: string is-built-in-algorithm-job: boolean is-hyperparameter-tuning-job: boolean web-access-uris: { string: string } can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r . create-time=no Output only. When the job was created. end-time=ipsum Output only. When the job processing was completed. error-message=voluptua. Output only. The details of a failure or a cancellation. etag=at etag is used for optimistic concurrency control as a way to help prevent simultaneous updates of a job from overwriting each other. It is strongly suggested that systems make use of the etag in the read-modify-write cycle to perform job updates in order to avoid race conditions: An etag is returned in the response to GetJob , and systems are expected to put that etag in the request to UpdateJob to ensure that their change will be applied to the same version of the job. job-id=sanctus Required. The user-specified id of the job. job-position=sed Output only. It's only effect when the job is in QUEUED state. If it's positive, it indicates the job's position in the job scheduler. It's 0 when the job is already scheduled. labels=key=amet. Optional. One or more labels that you can add, to organize your jobs. Each label is a key-value pair, where both the key and the value are arbitrary strings that you supply. For more information, see the documentation on using labels. the value will be associated with the given key prediction-input batch-size=takimata Optional. Number of records per batch, defaults to 64. The service will buffer batch_size number of records in memory before invoking one Tensorflow prediction call internally. So take the record size and memory available into consideration when setting this parameter. data-format=amet. Required. The format of the input data files. input-paths=duo Required. The Cloud Storage location of the input data files. May contain wildcards. Each invocation of this argument appends the given value to the array. max-worker-count=-55 Optional. The maximum number of workers to be used for parallel processing. Defaults to 10 if not specified. model-name=gubergren Use this field if you want to use the default version for the specified model. The string must use the following format: &#34;projects/YOUR_PROJECT/models/YOUR_MODEL&#34; output-data-format=lorem Optional. Format of the output data files, defaults to JSON. output-path=gubergren Required. The output Google Cloud Storage location. region=eos Required. The Google Compute Engine region to run the prediction job in. See the available regions for AI Platform services. runtime-version=dolor Optional. The AI Platform runtime version to use for this batch prediction. If not set, AI Platform will pick the runtime version used during the CreateVersion request for this model version, or choose the latest stable version when model version information is not available such as when the model is specified by uri. signature-name=ea Optional. The name of the signature defined in the SavedModel to use for this job. Please refer to SavedModel for information about how to use signatures. Defaults to DEFAULT_SERVING_SIGNATURE_DEF_KEY , which is \"serving_default\". uri=ipsum Use this field if you want to specify a Google Cloud Storage path for the model to use. version-name=invidunt Use this field if you want to specify a version of the model to use. The string is formatted the same way as model_version , with the addition of the version information: &#34;projects/YOUR_PROJECT/models/YOUR_MODEL/versions/YOUR_VERSION&#34; ..prediction-output error-count=-47 The number of data instances which resulted in errors. node-hours=0.8204376297831348 Node hours used by the batch prediction job. output-path=ipsum The output Google Cloud Storage location provided at the job creation time. prediction-count=-93 The number of generated predictions. .. start-time=ut Output only. When the job processing was started. state=gubergren Output only. The detailed state of a job. training-input args=rebum. Optional. Command-line arguments passed to the training application when it starts. If your job uses a custom container, then the arguments are passed to the container's ENTRYPOINT command. Each invocation of this argument appends the given value to the array. enable-web-access=true Optional. Whether you want AI Platform Training to enable interactive shell access to training containers. If set to true , you can access interactive shells at the URIs given by TrainingOutput.web_access_uris or HyperparameterOutput.web_access_uris (within TrainingOutput.trials). encryption-config kms-key-name=ipsum The Cloud KMS resource identifier of the customer-managed encryption key used to protect a resource, such as a training job. It has the following format: projects/{PROJECT_ID}/locations/{REGION}/keyRings/{KEY_RING_NAME}/cryptoKeys/{KEY_NAME} ..evaluator-config.accelerator-config count=ipsum The number of accelerators to attach to each machine running the job. type=est The type of accelerator to use. .. container-args=gubergren Arguments to the entrypoint command. The following rules apply for container_command and container_args: - If you do not supply command or args: The defaults defined in the Docker image are used. - If you supply a command but no args: The default EntryPoint and the default Cmd defined in the Docker image are ignored. Your command is run without any arguments. - If you supply only args: The default Entrypoint defined in the Docker image is run with the args that you supplied. - If you supply a command and args: The default Entrypoint and the default Cmd defined in the Docker image are ignored. Your command is run with your args. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. container-command=ea The command with which the replica's custom container is run. If provided, it will override default ENTRYPOINT of the docker image. If not provided, the docker image's ENTRYPOINT is used. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. disk-config boot-disk-size-gb=2 Size in GB of the boot disk (default is 100GB). boot-disk-type=lorem Type of the boot disk (default is \"pd-ssd\"). Valid values: \"pd-ssd\" (Persistent Disk Solid State Drive) or \"pd-standard\" (Persistent Disk Hard Disk Drive). .. image-uri=eos The Docker image to run on the replica. This image must be in Container Registry. Learn more about configuring custom containers . tpu-tf-version=labore The AI Platform runtime version that includes a TensorFlow version matching the one used in the custom container. This field is required if the replica is a TPU worker that uses a custom container. Otherwise, do not specify this field. This must be a runtime version that currently supports training with TPUs . Note that the version of TensorFlow included in a runtime version may differ from the numbering of the runtime version itself, because it may have a different patch version . In this field, you must specify the runtime version (TensorFlow minor version). For example, if your custom container runs TensorFlow 1.x.y , specify 1.x . .. evaluator-count=-43 Optional. The number of evaluator replicas to use for the training job. Each replica in the cluster will be of the type specified in evaluator_type . This value can only be used when scale_tier is set to CUSTOM . If you set this value, you must also set evaluator_type . The default value is zero. evaluator-type=duo Optional. Specifies the type of virtual machine to use for your training job's evaluator nodes. The supported values are the same as those described in the entry for masterType . This value must be consistent with the category of machine type that masterType uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. This value must be present when scaleTier is set to CUSTOM and evaluatorCount is greater than zero. hyperparameters algorithm=sed Optional. The search algorithm specified for the hyperparameter tuning job. Uses the default AI Platform hyperparameter tuning algorithm if unspecified. enable-trial-early-stopping=true Optional. Indicates if the hyperparameter tuning job enables auto trial early stopping. goal=stet Required. The type of goal to use for tuning. Available types are MAXIMIZE and MINIMIZE . Defaults to MAXIMIZE . hyperparameter-metric-tag=kasd Optional. The TensorFlow summary tag name to use for optimizing trials. For current versions of TensorFlow, this tag name should exactly match what is shown in TensorBoard, including all scopes. For versions of TensorFlow prior to 0.12, this should be only the tag passed to tf.Summary. By default, \"training/hptuning/metric\" will be used. max-failed-trials=77 Optional. The number of failed trials that need to be seen before failing the hyperparameter tuning job. You can specify this field to override the default failing criteria for AI Platform hyperparameter tuning jobs. Defaults to zero, which means the service decides when a hyperparameter job should fail. max-parallel-trials=58 Optional. The number of training trials to run concurrently. You can reduce the time it takes to perform hyperparameter tuning by adding trials in parallel. However, each trail only benefits from the information gained in completed trials. That means that a trial does not get access to the results of trials running at the same time, which could reduce the quality of the overall optimization. Each trial will use the same scale tier and machine types. Defaults to one. max-trials=77 Optional. How many training trials should be attempted to optimize the specified hyperparameters. Defaults to one. resume-previous-job-id=et Optional. The prior hyperparameter tuning job id that users hope to continue with. The job id will be used to find the corresponding vizier study guid and resume the study. .. job-dir=vero Optional. A Google Cloud Storage path in which to store training outputs and other data needed for training. This path is passed to your TensorFlow program as the '--job-dir' command-line argument. The benefit of specifying this field is that Cloud ML validates the path for use in training. master-config.accelerator-config count=erat The number of accelerators to attach to each machine running the job. type=sed The type of accelerator to use. .. container-args=duo Arguments to the entrypoint command. The following rules apply for container_command and container_args: - If you do not supply command or args: The defaults defined in the Docker image are used. - If you supply a command but no args: The default EntryPoint and the default Cmd defined in the Docker image are ignored. Your command is run without any arguments. - If you supply only args: The default Entrypoint defined in the Docker image is run with the args that you supplied. - If you supply a command and args: The default Entrypoint and the default Cmd defined in the Docker image are ignored. Your command is run with your args. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. container-command=dolore The command with which the replica's custom container is run. If provided, it will override default ENTRYPOINT of the docker image. If not provided, the docker image's ENTRYPOINT is used. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. disk-config boot-disk-size-gb=79 Size in GB of the boot disk (default is 100GB). boot-disk-type=voluptua. Type of the boot disk (default is \"pd-ssd\"). Valid values: \"pd-ssd\" (Persistent Disk Solid State Drive) or \"pd-standard\" (Persistent Disk Hard Disk Drive). .. image-uri=amet. The Docker image to run on the replica. This image must be in Container Registry. Learn more about configuring custom containers . tpu-tf-version=consetetur The AI Platform runtime version that includes a TensorFlow version matching the one used in the custom container. This field is required if the replica is a TPU worker that uses a custom container. Otherwise, do not specify this field. This must be a runtime version that currently supports training with TPUs . Note that the version of TensorFlow included in a runtime version may differ from the numbering of the runtime version itself, because it may have a different patch version . In this field, you must specify the runtime version (TensorFlow minor version). For example, if your custom container runs TensorFlow 1.x.y , specify 1.x . .. master-type=diam Optional. Specifies the type of virtual machine to use for your training job's master worker. You must specify this field when scaleTier is set to CUSTOM . You can use certain Compute Engine machine types directly in this field. See the list of compatible Compute Engine machine types . Alternatively, you can use the certain legacy machine types in this field. See the list of legacy machine types . Finally, if you want to use a TPU for training, specify cloud_tpu in this field. Learn more about the special configuration options for training with TPUs . network=dolor Optional. The full name of the Compute Engine network to which the Job is peered. For example, projects/12345/global/networks/myVPC . The format of this field is projects/{project}/global/networks/{network} , where {project} is a project number (like 12345 ) and {network} is network name. Private services access must already be configured for the network. If left unspecified, the Job is not peered with any network. Learn about using VPC Network Peering. . package-uris=et Required. The Google Cloud Storage location of the packages with the training program and any additional dependencies. The maximum number of package URIs is 100. Each invocation of this argument appends the given value to the array. parameter-server-config.accelerator-config count=et The number of accelerators to attach to each machine running the job. type=sadipscing The type of accelerator to use. .. container-args=stet Arguments to the entrypoint command. The following rules apply for container_command and container_args: - If you do not supply command or args: The defaults defined in the Docker image are used. - If you supply a command but no args: The default EntryPoint and the default Cmd defined in the Docker image are ignored. Your command is run without any arguments. - If you supply only args: The default Entrypoint defined in the Docker image is run with the args that you supplied. - If you supply a command and args: The default Entrypoint and the default Cmd defined in the Docker image are ignored. Your command is run with your args. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. container-command=dolor The command with which the replica's custom container is run. If provided, it will override default ENTRYPOINT of the docker image. If not provided, the docker image's ENTRYPOINT is used. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. disk-config boot-disk-size-gb=81 Size in GB of the boot disk (default is 100GB). boot-disk-type=vero Type of the boot disk (default is \"pd-ssd\"). Valid values: \"pd-ssd\" (Persistent Disk Solid State Drive) or \"pd-standard\" (Persistent Disk Hard Disk Drive). .. image-uri=vero The Docker image to run on the replica. This image must be in Container Registry. Learn more about configuring custom containers . tpu-tf-version=invidunt The AI Platform runtime version that includes a TensorFlow version matching the one used in the custom container. This field is required if the replica is a TPU worker that uses a custom container. Otherwise, do not specify this field. This must be a runtime version that currently supports training with TPUs . Note that the version of TensorFlow included in a runtime version may differ from the numbering of the runtime version itself, because it may have a different patch version . In this field, you must specify the runtime version (TensorFlow minor version). For example, if your custom container runs TensorFlow 1.x.y , specify 1.x . .. parameter-server-count=-65 Optional. The number of parameter server replicas to use for the training job. Each replica in the cluster will be of the type specified in parameter_server_type . This value can only be used when scale_tier is set to CUSTOM . If you set this value, you must also set parameter_server_type . The default value is zero. parameter-server-type=vero Optional. Specifies the type of virtual machine to use for your training job's parameter server. The supported values are the same as those described in the entry for master_type . This value must be consistent with the category of machine type that masterType uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. This value must be present when scaleTier is set to CUSTOM and parameter_server_count is greater than zero. python-module=elitr Required. The Python module name to run after installing the packages. python-version=lorem Optional. The version of Python used in training. You must either specify this field or specify masterConfig.imageUri . The following Python versions are available: * Python '3.7' is available when runtime_version is set to '1.15' or later. * Python '3.5' is available when runtime_version is set to a version from '1.4' to '1.14'. * Python '2.7' is available when runtime_version is set to '1.15' or earlier. Read more about the Python versions available for each runtime version . region=diam Required. The region to run the training job in. See the available regions for AI Platform Training. runtime-version=no Optional. The AI Platform runtime version to use for training. You must either specify this field or specify masterConfig.imageUri . For more information, see the runtime version list and learn how to manage runtime versions . scale-tier=ipsum Required. Specifies the machine types, the number of replicas for workers and parameter servers. scheduling max-running-time=accusam Optional. The maximum job running time, expressed in seconds. The field can contain up to nine fractional digits, terminated by s . If not specified, this field defaults to 604800s (seven days). If the training job is still running after this duration, AI Platform Training cancels it. The duration is measured from when the job enters the RUNNING state; therefore it does not overlap with the duration limited by Scheduling.max_wait_time. For example, if you want to ensure your job runs for no more than 2 hours, set this field to 7200s (2 hours * 60 minutes / hour * 60 seconds / minute). If you submit your training job using the gcloud tool, you can specify this field in a config.yaml file . For example: yaml trainingInput: scheduling: maxRunningTime: 7200s max-wait-time=takimata Optional. The maximum job wait time, expressed in seconds. The field can contain up to nine fractional digits, terminated by s . If not specified, there is no limit to the wait time. The minimum for this field is 1800s (30 minutes). If the training job has not entered the RUNNING state after this duration, AI Platform Training cancels it. After the job begins running, it can no longer be cancelled due to the maximum wait time. Therefore the duration limited by this field does not overlap with the duration limited by Scheduling.max_running_time. For example, if the job temporarily stops running and retries due to a VM restart , this cannot lead to a maximum wait time cancellation. However, independently of this constraint, AI Platform Training might stop a job if there are too many retries due to exhausted resources in a region. The following example describes how you might use this field: To cancel your job if it doesn't start running within 1 hour, set this field to 3600s (1 hour * 60 minutes / hour * 60 seconds / minute). If the job is still in the QUEUED or PREPARING state after an hour of waiting, AI Platform Training cancels the job. If you submit your training job using the gcloud tool, you can specify this field in a config.yaml file . For example: yaml trainingInput: scheduling: maxWaitTime: 3600s priority=55 Optional. Job scheduling will be based on this priority, which in the range [0, 1000]. The bigger the number, the higher the priority. Default to 0 if not set. If there are multiple jobs requesting same type of accelerators, the high priority job will be scheduled prior to ones with low priority. .. service-account=voluptua. Optional. The email address of a service account to use when running the training appplication. You must have the iam.serviceAccounts.actAs permission for the specified service account. In addition, the AI Platform Training Google-managed service account must have the roles/iam.serviceAccountAdmin role for the specified service account. Learn more about configuring a service account. If not specified, the AI Platform Training Google-managed service account is used by default. use-chief-in-tf-config=false Optional. Use chief instead of master in the TF_CONFIG environment variable when training with a custom container. Defaults to false . Learn more about this field. This field has no effect for training jobs that don't use a custom container. worker-config.accelerator-config count=erat The number of accelerators to attach to each machine running the job. type=consetetur The type of accelerator to use. .. container-args=amet. Arguments to the entrypoint command. The following rules apply for container_command and container_args: - If you do not supply command or args: The defaults defined in the Docker image are used. - If you supply a command but no args: The default EntryPoint and the default Cmd defined in the Docker image are ignored. Your command is run without any arguments. - If you supply only args: The default Entrypoint defined in the Docker image is run with the args that you supplied. - If you supply a command and args: The default Entrypoint and the default Cmd defined in the Docker image are ignored. Your command is run with your args. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. container-command=sed The command with which the replica's custom container is run. If provided, it will override default ENTRYPOINT of the docker image. If not provided, the docker image's ENTRYPOINT is used. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. disk-config boot-disk-size-gb=92 Size in GB of the boot disk (default is 100GB). boot-disk-type=dolores Type of the boot disk (default is \"pd-ssd\"). Valid values: \"pd-ssd\" (Persistent Disk Solid State Drive) or \"pd-standard\" (Persistent Disk Hard Disk Drive). .. image-uri=gubergren The Docker image to run on the replica. This image must be in Container Registry. Learn more about configuring custom containers . tpu-tf-version=et The AI Platform runtime version that includes a TensorFlow version matching the one used in the custom container. This field is required if the replica is a TPU worker that uses a custom container. Otherwise, do not specify this field. This must be a runtime version that currently supports training with TPUs . Note that the version of TensorFlow included in a runtime version may differ from the numbering of the runtime version itself, because it may have a different patch version . In this field, you must specify the runtime version (TensorFlow minor version). For example, if your custom container runs TensorFlow 1.x.y , specify 1.x . .. worker-count=-23 Optional. The number of worker replicas to use for the training job. Each replica in the cluster will be of the type specified in worker_type . This value can only be used when scale_tier is set to CUSTOM . If you set this value, you must also set worker_type . The default value is zero. worker-type=voluptua. Optional. Specifies the type of virtual machine to use for your training job's worker nodes. The supported values are the same as those described in the entry for masterType . This value must be consistent with the category of machine type that masterType uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. If you use cloud_tpu for this value, see special instructions for configuring a custom TPU machine . This value must be present when scaleTier is set to CUSTOM and workerCount is greater than zero. ..training-output.built-in-algorithm-output framework=dolore Framework on which the built-in algorithm was trained. model-path=dolore The Cloud Storage path to the model/ directory where the training job saves the trained model. Only set for successful jobs that don't use hyperparameter tuning. python-version=dolore Python version on which the built-in algorithm was trained. runtime-version=voluptua. AI Platform runtime version on which the built-in algorithm was trained. .. completed-trial-count=-2 The number of hyperparameter tuning trials that completed successfully. Only set for hyperparameter tuning jobs. consumed-ml-units=0.6626374874296354 The amount of ML units consumed by the job. hyperparameter-metric-tag=lorem The TensorFlow summary tag name used for optimizing hyperparameter tuning trials. See HyperparameterSpec.hyperparameterMetricTag for more information. Only set for hyperparameter tuning jobs. is-built-in-algorithm-job=true Whether this job is a built-in Algorithm job. is-hyperparameter-tuning-job=true Whether this job is a hyperparameter tuning job. web-access-uris=key=sit Output only. URIs for accessing interactive shells (one URI for each training node). Only available if training_input.enable_web_access is true . The keys are names of each node in the training job; for example, master-replica-0 for the master node, worker-replica-0 for the first worker, and ps-replica-0 for the first parameter server. The values are the URIs for each node's interactive shell. the value will be associated with the given key","title":"Required Request Value"},{"location":"projects_jobs-create/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"projects_jobs-create/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_jobs-create/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_jobs-get-iam-policy/","text":"Gets the access control policy for a resource. Returns an empty policy if the resource exists and does not have a policy set. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects jobs-get-iam-policy ... Required Scalar Argument <resource> (string) REQUIRED: The resource for which the policy is being requested. See Resource names for the appropriate value for this field. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional Method Properties You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p options-requested-policy-version=integer Optional. The maximum policy version that will be used to format the policy. Valid values are 0, 1, and 3. Requests specifying an invalid value will be rejected. Requests for policies with any conditional role bindings must specify version 3. Policies with no conditional role bindings may specify any valid value or leave the field unset. The policy in the response might use the policy version that you specified, or it might use a lower policy version. For example, if you specify version 3, but the policy has no conditional role bindings, the response uses version 1. To learn which resources support conditions in their IAM policies, see the IAM documentation . Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Jobs Get Iam Policy"},{"location":"projects_jobs-get-iam-policy/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects jobs-get-iam-policy ...","title":"Scopes"},{"location":"projects_jobs-get-iam-policy/#required-scalar-argument","text":"<resource> (string) REQUIRED: The resource for which the policy is being requested. See Resource names for the appropriate value for this field.","title":"Required Scalar Argument"},{"location":"projects_jobs-get-iam-policy/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_jobs-get-iam-policy/#optional-method-properties","text":"You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p options-requested-policy-version=integer Optional. The maximum policy version that will be used to format the policy. Valid values are 0, 1, and 3. Requests specifying an invalid value will be rejected. Requests for policies with any conditional role bindings must specify version 3. Policies with no conditional role bindings may specify any valid value or leave the field unset. The policy in the response might use the policy version that you specified, or it might use a lower policy version. For example, if you specify version 3, but the policy has no conditional role bindings, the response uses version 1. To learn which resources support conditions in their IAM policies, see the IAM documentation .","title":"Optional Method Properties"},{"location":"projects_jobs-get-iam-policy/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_jobs-get/","text":"Describes a job. Scopes You will need authorization for at least one of the following scopes to make a valid call: https://www.googleapis.com/auth/cloud-platform https://www.googleapis.com/auth/cloud-platform.read-only If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects jobs-get ... Required Scalar Argument <name> (string) Required. The name of the job to get the description of. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Jobs Get"},{"location":"projects_jobs-get/#scopes","text":"You will need authorization for at least one of the following scopes to make a valid call: https://www.googleapis.com/auth/cloud-platform https://www.googleapis.com/auth/cloud-platform.read-only If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects jobs-get ...","title":"Scopes"},{"location":"projects_jobs-get/#required-scalar-argument","text":"<name> (string) Required. The name of the job to get the description of.","title":"Required Scalar Argument"},{"location":"projects_jobs-get/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_jobs-get/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_jobs-list/","text":"Lists the jobs in the project. If there are no jobs that match the request parameters, the list request returns an empty response body: {}. Scopes You will need authorization for at least one of the following scopes to make a valid call: https://www.googleapis.com/auth/cloud-platform https://www.googleapis.com/auth/cloud-platform.read-only If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects jobs-list ... Required Scalar Argument <parent> (string) Required. The name of the project for which to list jobs. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional Method Properties You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p filter=string Optional. Specifies the subset of jobs to retrieve. You can filter on the value of one or more attributes of the job object. For example, retrieve jobs with a job identifier that starts with 'census': gcloud ai-platform jobs list --filter='jobId:census ' List all failed jobs with names that start with 'rnn': gcloud ai-platform jobs list --filter='jobId:rnn AND state:FAILED' For more examples, see the guide to monitoring jobs. -p page-size=integer Optional. The number of jobs to retrieve per \"page\" of results. If there are more remaining results than this number, the response message will contain a valid value in the next_page_token field. The default value is 20, and the maximum page size is 100. -p page-token=string Optional. A page token to request the next page of results. You get the token from the next_page_token field of the response from the previous call. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Jobs List"},{"location":"projects_jobs-list/#scopes","text":"You will need authorization for at least one of the following scopes to make a valid call: https://www.googleapis.com/auth/cloud-platform https://www.googleapis.com/auth/cloud-platform.read-only If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects jobs-list ...","title":"Scopes"},{"location":"projects_jobs-list/#required-scalar-argument","text":"<parent> (string) Required. The name of the project for which to list jobs.","title":"Required Scalar Argument"},{"location":"projects_jobs-list/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_jobs-list/#optional-method-properties","text":"You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p filter=string Optional. Specifies the subset of jobs to retrieve. You can filter on the value of one or more attributes of the job object. For example, retrieve jobs with a job identifier that starts with 'census': gcloud ai-platform jobs list --filter='jobId:census ' List all failed jobs with names that start with 'rnn': gcloud ai-platform jobs list --filter='jobId:rnn AND state:FAILED' For more examples, see the guide to monitoring jobs. -p page-size=integer Optional. The number of jobs to retrieve per \"page\" of results. If there are more remaining results than this number, the response message will contain a valid value in the next_page_token field. The default value is 20, and the maximum page size is 100. -p page-token=string Optional. A page token to request the next page of results. You get the token from the next_page_token field of the response from the previous call.","title":"Optional Method Properties"},{"location":"projects_jobs-list/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_jobs-patch/","text":"Updates a specific job resource. Currently the only supported fields to update are labels . Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects jobs-patch ... Required Scalar Argument <name> (string) Required. The job name. Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__Job: create-time: string end-time: string error-message: string etag: string job-id: string job-position: string labels: { string: string } prediction-input: batch-size: string data-format: string input-paths: [string] max-worker-count: int64 model-name: string output-data-format: string output-path: string region: string runtime-version: string signature-name: string uri: string version-name: string prediction-output: error-count: int64 node-hours: number output-path: string prediction-count: int64 start-time: string state: string training-input: args: [string] enable-web-access: boolean encryption-config: kms-key-name: string evaluator-config: accelerator-config: count: string type: string container-args: [string] container-command: [string] disk-config: boot-disk-size-gb: integer boot-disk-type: string image-uri: string tpu-tf-version: string evaluator-count: int64 evaluator-type: string hyperparameters: algorithm: string enable-trial-early-stopping: boolean goal: string hyperparameter-metric-tag: string max-failed-trials: integer max-parallel-trials: integer max-trials: integer resume-previous-job-id: string job-dir: string master-config: accelerator-config: count: string type: string container-args: [string] container-command: [string] disk-config: boot-disk-size-gb: integer boot-disk-type: string image-uri: string tpu-tf-version: string master-type: string network: string package-uris: [string] parameter-server-config: accelerator-config: count: string type: string container-args: [string] container-command: [string] disk-config: boot-disk-size-gb: integer boot-disk-type: string image-uri: string tpu-tf-version: string parameter-server-count: int64 parameter-server-type: string python-module: string python-version: string region: string runtime-version: string scale-tier: string scheduling: max-running-time: string max-wait-time: string priority: integer service-account: string use-chief-in-tf-config: boolean worker-config: accelerator-config: count: string type: string container-args: [string] container-command: [string] disk-config: boot-disk-size-gb: integer boot-disk-type: string image-uri: string tpu-tf-version: string worker-count: int64 worker-type: string training-output: built-in-algorithm-output: framework: string model-path: string python-version: string runtime-version: string completed-trial-count: int64 consumed-ml-units: number hyperparameter-metric-tag: string is-built-in-algorithm-job: boolean is-hyperparameter-tuning-job: boolean web-access-uris: { string: string } can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r . create-time=et Output only. When the job was created. end-time=tempor Output only. When the job processing was completed. error-message=aliquyam Output only. The details of a failure or a cancellation. etag=ipsum etag is used for optimistic concurrency control as a way to help prevent simultaneous updates of a job from overwriting each other. It is strongly suggested that systems make use of the etag in the read-modify-write cycle to perform job updates in order to avoid race conditions: An etag is returned in the response to GetJob , and systems are expected to put that etag in the request to UpdateJob to ensure that their change will be applied to the same version of the job. job-id=et Required. The user-specified id of the job. job-position=sanctus Output only. It's only effect when the job is in QUEUED state. If it's positive, it indicates the job's position in the job scheduler. It's 0 when the job is already scheduled. labels=key=lorem Optional. One or more labels that you can add, to organize your jobs. Each label is a key-value pair, where both the key and the value are arbitrary strings that you supply. For more information, see the documentation on using labels. the value will be associated with the given key prediction-input batch-size=est Optional. Number of records per batch, defaults to 64. The service will buffer batch_size number of records in memory before invoking one Tensorflow prediction call internally. So take the record size and memory available into consideration when setting this parameter. data-format=sed Required. The format of the input data files. input-paths=diam Required. The Cloud Storage location of the input data files. May contain wildcards. Each invocation of this argument appends the given value to the array. max-worker-count=-19 Optional. The maximum number of workers to be used for parallel processing. Defaults to 10 if not specified. model-name=dolores Use this field if you want to use the default version for the specified model. The string must use the following format: &#34;projects/YOUR_PROJECT/models/YOUR_MODEL&#34; output-data-format=et Optional. Format of the output data files, defaults to JSON. output-path=sed Required. The output Google Cloud Storage location. region=no Required. The Google Compute Engine region to run the prediction job in. See the available regions for AI Platform services. runtime-version=et Optional. The AI Platform runtime version to use for this batch prediction. If not set, AI Platform will pick the runtime version used during the CreateVersion request for this model version, or choose the latest stable version when model version information is not available such as when the model is specified by uri. signature-name=elitr Optional. The name of the signature defined in the SavedModel to use for this job. Please refer to SavedModel for information about how to use signatures. Defaults to DEFAULT_SERVING_SIGNATURE_DEF_KEY , which is \"serving_default\". uri=sed Use this field if you want to specify a Google Cloud Storage path for the model to use. version-name=no Use this field if you want to specify a version of the model to use. The string is formatted the same way as model_version , with the addition of the version information: &#34;projects/YOUR_PROJECT/models/YOUR_MODEL/versions/YOUR_VERSION&#34; ..prediction-output error-count=-91 The number of data instances which resulted in errors. node-hours=0.1918654921610582 Node hours used by the batch prediction job. output-path=aliquyam The output Google Cloud Storage location provided at the job creation time. prediction-count=-69 The number of generated predictions. .. start-time=sadipscing Output only. When the job processing was started. state=erat Output only. The detailed state of a job. training-input args=aliquyam Optional. Command-line arguments passed to the training application when it starts. If your job uses a custom container, then the arguments are passed to the container's ENTRYPOINT command. Each invocation of this argument appends the given value to the array. enable-web-access=true Optional. Whether you want AI Platform Training to enable interactive shell access to training containers. If set to true , you can access interactive shells at the URIs given by TrainingOutput.web_access_uris or HyperparameterOutput.web_access_uris (within TrainingOutput.trials). encryption-config kms-key-name=est The Cloud KMS resource identifier of the customer-managed encryption key used to protect a resource, such as a training job. It has the following format: projects/{PROJECT_ID}/locations/{REGION}/keyRings/{KEY_RING_NAME}/cryptoKeys/{KEY_NAME} ..evaluator-config.accelerator-config count=et The number of accelerators to attach to each machine running the job. type=sea The type of accelerator to use. .. container-args=consetetur Arguments to the entrypoint command. The following rules apply for container_command and container_args: - If you do not supply command or args: The defaults defined in the Docker image are used. - If you supply a command but no args: The default EntryPoint and the default Cmd defined in the Docker image are ignored. Your command is run without any arguments. - If you supply only args: The default Entrypoint defined in the Docker image is run with the args that you supplied. - If you supply a command and args: The default Entrypoint and the default Cmd defined in the Docker image are ignored. Your command is run with your args. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. container-command=consetetur The command with which the replica's custom container is run. If provided, it will override default ENTRYPOINT of the docker image. If not provided, the docker image's ENTRYPOINT is used. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. disk-config boot-disk-size-gb=36 Size in GB of the boot disk (default is 100GB). boot-disk-type=est Type of the boot disk (default is \"pd-ssd\"). Valid values: \"pd-ssd\" (Persistent Disk Solid State Drive) or \"pd-standard\" (Persistent Disk Hard Disk Drive). .. image-uri=aliquyam The Docker image to run on the replica. This image must be in Container Registry. Learn more about configuring custom containers . tpu-tf-version=elitr The AI Platform runtime version that includes a TensorFlow version matching the one used in the custom container. This field is required if the replica is a TPU worker that uses a custom container. Otherwise, do not specify this field. This must be a runtime version that currently supports training with TPUs . Note that the version of TensorFlow included in a runtime version may differ from the numbering of the runtime version itself, because it may have a different patch version . In this field, you must specify the runtime version (TensorFlow minor version). For example, if your custom container runs TensorFlow 1.x.y , specify 1.x . .. evaluator-count=-20 Optional. The number of evaluator replicas to use for the training job. Each replica in the cluster will be of the type specified in evaluator_type . This value can only be used when scale_tier is set to CUSTOM . If you set this value, you must also set evaluator_type . The default value is zero. evaluator-type=diam Optional. Specifies the type of virtual machine to use for your training job's evaluator nodes. The supported values are the same as those described in the entry for masterType . This value must be consistent with the category of machine type that masterType uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. This value must be present when scaleTier is set to CUSTOM and evaluatorCount is greater than zero. hyperparameters algorithm=est Optional. The search algorithm specified for the hyperparameter tuning job. Uses the default AI Platform hyperparameter tuning algorithm if unspecified. enable-trial-early-stopping=true Optional. Indicates if the hyperparameter tuning job enables auto trial early stopping. goal=sed Required. The type of goal to use for tuning. Available types are MAXIMIZE and MINIMIZE . Defaults to MAXIMIZE . hyperparameter-metric-tag=eos Optional. The TensorFlow summary tag name to use for optimizing trials. For current versions of TensorFlow, this tag name should exactly match what is shown in TensorBoard, including all scopes. For versions of TensorFlow prior to 0.12, this should be only the tag passed to tf.Summary. By default, \"training/hptuning/metric\" will be used. max-failed-trials=45 Optional. The number of failed trials that need to be seen before failing the hyperparameter tuning job. You can specify this field to override the default failing criteria for AI Platform hyperparameter tuning jobs. Defaults to zero, which means the service decides when a hyperparameter job should fail. max-parallel-trials=84 Optional. The number of training trials to run concurrently. You can reduce the time it takes to perform hyperparameter tuning by adding trials in parallel. However, each trail only benefits from the information gained in completed trials. That means that a trial does not get access to the results of trials running at the same time, which could reduce the quality of the overall optimization. Each trial will use the same scale tier and machine types. Defaults to one. max-trials=86 Optional. How many training trials should be attempted to optimize the specified hyperparameters. Defaults to one. resume-previous-job-id=dolores Optional. The prior hyperparameter tuning job id that users hope to continue with. The job id will be used to find the corresponding vizier study guid and resume the study. .. job-dir=eos Optional. A Google Cloud Storage path in which to store training outputs and other data needed for training. This path is passed to your TensorFlow program as the '--job-dir' command-line argument. The benefit of specifying this field is that Cloud ML validates the path for use in training. master-config.accelerator-config count=et The number of accelerators to attach to each machine running the job. type=sea The type of accelerator to use. .. container-args=et Arguments to the entrypoint command. The following rules apply for container_command and container_args: - If you do not supply command or args: The defaults defined in the Docker image are used. - If you supply a command but no args: The default EntryPoint and the default Cmd defined in the Docker image are ignored. Your command is run without any arguments. - If you supply only args: The default Entrypoint defined in the Docker image is run with the args that you supplied. - If you supply a command and args: The default Entrypoint and the default Cmd defined in the Docker image are ignored. Your command is run with your args. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. container-command=at The command with which the replica's custom container is run. If provided, it will override default ENTRYPOINT of the docker image. If not provided, the docker image's ENTRYPOINT is used. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. disk-config boot-disk-size-gb=17 Size in GB of the boot disk (default is 100GB). boot-disk-type=eirmod Type of the boot disk (default is \"pd-ssd\"). Valid values: \"pd-ssd\" (Persistent Disk Solid State Drive) or \"pd-standard\" (Persistent Disk Hard Disk Drive). .. image-uri=lorem The Docker image to run on the replica. This image must be in Container Registry. Learn more about configuring custom containers . tpu-tf-version=accusam The AI Platform runtime version that includes a TensorFlow version matching the one used in the custom container. This field is required if the replica is a TPU worker that uses a custom container. Otherwise, do not specify this field. This must be a runtime version that currently supports training with TPUs . Note that the version of TensorFlow included in a runtime version may differ from the numbering of the runtime version itself, because it may have a different patch version . In this field, you must specify the runtime version (TensorFlow minor version). For example, if your custom container runs TensorFlow 1.x.y , specify 1.x . .. master-type=amet Optional. Specifies the type of virtual machine to use for your training job's master worker. You must specify this field when scaleTier is set to CUSTOM . You can use certain Compute Engine machine types directly in this field. See the list of compatible Compute Engine machine types . Alternatively, you can use the certain legacy machine types in this field. See the list of legacy machine types . Finally, if you want to use a TPU for training, specify cloud_tpu in this field. Learn more about the special configuration options for training with TPUs . network=erat Optional. The full name of the Compute Engine network to which the Job is peered. For example, projects/12345/global/networks/myVPC . The format of this field is projects/{project}/global/networks/{network} , where {project} is a project number (like 12345 ) and {network} is network name. Private services access must already be configured for the network. If left unspecified, the Job is not peered with any network. Learn about using VPC Network Peering. . package-uris=dolores Required. The Google Cloud Storage location of the packages with the training program and any additional dependencies. The maximum number of package URIs is 100. Each invocation of this argument appends the given value to the array. parameter-server-config.accelerator-config count=erat The number of accelerators to attach to each machine running the job. type=accusam The type of accelerator to use. .. container-args=sea Arguments to the entrypoint command. The following rules apply for container_command and container_args: - If you do not supply command or args: The defaults defined in the Docker image are used. - If you supply a command but no args: The default EntryPoint and the default Cmd defined in the Docker image are ignored. Your command is run without any arguments. - If you supply only args: The default Entrypoint defined in the Docker image is run with the args that you supplied. - If you supply a command and args: The default Entrypoint and the default Cmd defined in the Docker image are ignored. Your command is run with your args. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. container-command=takimata The command with which the replica's custom container is run. If provided, it will override default ENTRYPOINT of the docker image. If not provided, the docker image's ENTRYPOINT is used. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. disk-config boot-disk-size-gb=50 Size in GB of the boot disk (default is 100GB). boot-disk-type=et Type of the boot disk (default is \"pd-ssd\"). Valid values: \"pd-ssd\" (Persistent Disk Solid State Drive) or \"pd-standard\" (Persistent Disk Hard Disk Drive). .. image-uri=at The Docker image to run on the replica. This image must be in Container Registry. Learn more about configuring custom containers . tpu-tf-version=dolor The AI Platform runtime version that includes a TensorFlow version matching the one used in the custom container. This field is required if the replica is a TPU worker that uses a custom container. Otherwise, do not specify this field. This must be a runtime version that currently supports training with TPUs . Note that the version of TensorFlow included in a runtime version may differ from the numbering of the runtime version itself, because it may have a different patch version . In this field, you must specify the runtime version (TensorFlow minor version). For example, if your custom container runs TensorFlow 1.x.y , specify 1.x . .. parameter-server-count=-22 Optional. The number of parameter server replicas to use for the training job. Each replica in the cluster will be of the type specified in parameter_server_type . This value can only be used when scale_tier is set to CUSTOM . If you set this value, you must also set parameter_server_type . The default value is zero. parameter-server-type=sit Optional. Specifies the type of virtual machine to use for your training job's parameter server. The supported values are the same as those described in the entry for master_type . This value must be consistent with the category of machine type that masterType uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. This value must be present when scaleTier is set to CUSTOM and parameter_server_count is greater than zero. python-module=erat Required. The Python module name to run after installing the packages. python-version=sea Optional. The version of Python used in training. You must either specify this field or specify masterConfig.imageUri . The following Python versions are available: * Python '3.7' is available when runtime_version is set to '1.15' or later. * Python '3.5' is available when runtime_version is set to a version from '1.4' to '1.14'. * Python '2.7' is available when runtime_version is set to '1.15' or earlier. Read more about the Python versions available for each runtime version . region=nonumy Required. The region to run the training job in. See the available regions for AI Platform Training. runtime-version=et Optional. The AI Platform runtime version to use for training. You must either specify this field or specify masterConfig.imageUri . For more information, see the runtime version list and learn how to manage runtime versions . scale-tier=gubergren Required. Specifies the machine types, the number of replicas for workers and parameter servers. scheduling max-running-time=justo Optional. The maximum job running time, expressed in seconds. The field can contain up to nine fractional digits, terminated by s . If not specified, this field defaults to 604800s (seven days). If the training job is still running after this duration, AI Platform Training cancels it. The duration is measured from when the job enters the RUNNING state; therefore it does not overlap with the duration limited by Scheduling.max_wait_time. For example, if you want to ensure your job runs for no more than 2 hours, set this field to 7200s (2 hours * 60 minutes / hour * 60 seconds / minute). If you submit your training job using the gcloud tool, you can specify this field in a config.yaml file . For example: yaml trainingInput: scheduling: maxRunningTime: 7200s max-wait-time=sea Optional. The maximum job wait time, expressed in seconds. The field can contain up to nine fractional digits, terminated by s . If not specified, there is no limit to the wait time. The minimum for this field is 1800s (30 minutes). If the training job has not entered the RUNNING state after this duration, AI Platform Training cancels it. After the job begins running, it can no longer be cancelled due to the maximum wait time. Therefore the duration limited by this field does not overlap with the duration limited by Scheduling.max_running_time. For example, if the job temporarily stops running and retries due to a VM restart , this cannot lead to a maximum wait time cancellation. However, independently of this constraint, AI Platform Training might stop a job if there are too many retries due to exhausted resources in a region. The following example describes how you might use this field: To cancel your job if it doesn't start running within 1 hour, set this field to 3600s (1 hour * 60 minutes / hour * 60 seconds / minute). If the job is still in the QUEUED or PREPARING state after an hour of waiting, AI Platform Training cancels the job. If you submit your training job using the gcloud tool, you can specify this field in a config.yaml file . For example: yaml trainingInput: scheduling: maxWaitTime: 3600s priority=5 Optional. Job scheduling will be based on this priority, which in the range [0, 1000]. The bigger the number, the higher the priority. Default to 0 if not set. If there are multiple jobs requesting same type of accelerators, the high priority job will be scheduled prior to ones with low priority. .. service-account=sit Optional. The email address of a service account to use when running the training appplication. You must have the iam.serviceAccounts.actAs permission for the specified service account. In addition, the AI Platform Training Google-managed service account must have the roles/iam.serviceAccountAdmin role for the specified service account. Learn more about configuring a service account. If not specified, the AI Platform Training Google-managed service account is used by default. use-chief-in-tf-config=false Optional. Use chief instead of master in the TF_CONFIG environment variable when training with a custom container. Defaults to false . Learn more about this field. This field has no effect for training jobs that don't use a custom container. worker-config.accelerator-config count=dolores The number of accelerators to attach to each machine running the job. type=consetetur The type of accelerator to use. .. container-args=gubergren Arguments to the entrypoint command. The following rules apply for container_command and container_args: - If you do not supply command or args: The defaults defined in the Docker image are used. - If you supply a command but no args: The default EntryPoint and the default Cmd defined in the Docker image are ignored. Your command is run without any arguments. - If you supply only args: The default Entrypoint defined in the Docker image is run with the args that you supplied. - If you supply a command and args: The default Entrypoint and the default Cmd defined in the Docker image are ignored. Your command is run with your args. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. container-command=dolor The command with which the replica's custom container is run. If provided, it will override default ENTRYPOINT of the docker image. If not provided, the docker image's ENTRYPOINT is used. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. disk-config boot-disk-size-gb=69 Size in GB of the boot disk (default is 100GB). boot-disk-type=no Type of the boot disk (default is \"pd-ssd\"). Valid values: \"pd-ssd\" (Persistent Disk Solid State Drive) or \"pd-standard\" (Persistent Disk Hard Disk Drive). .. image-uri=amet. The Docker image to run on the replica. This image must be in Container Registry. Learn more about configuring custom containers . tpu-tf-version=ipsum The AI Platform runtime version that includes a TensorFlow version matching the one used in the custom container. This field is required if the replica is a TPU worker that uses a custom container. Otherwise, do not specify this field. This must be a runtime version that currently supports training with TPUs . Note that the version of TensorFlow included in a runtime version may differ from the numbering of the runtime version itself, because it may have a different patch version . In this field, you must specify the runtime version (TensorFlow minor version). For example, if your custom container runs TensorFlow 1.x.y , specify 1.x . .. worker-count=-56 Optional. The number of worker replicas to use for the training job. Each replica in the cluster will be of the type specified in worker_type . This value can only be used when scale_tier is set to CUSTOM . If you set this value, you must also set worker_type . The default value is zero. worker-type=accusam Optional. Specifies the type of virtual machine to use for your training job's worker nodes. The supported values are the same as those described in the entry for masterType . This value must be consistent with the category of machine type that masterType uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. If you use cloud_tpu for this value, see special instructions for configuring a custom TPU machine . This value must be present when scaleTier is set to CUSTOM and workerCount is greater than zero. ..training-output.built-in-algorithm-output framework=gubergren Framework on which the built-in algorithm was trained. model-path=sadipscing The Cloud Storage path to the model/ directory where the training job saves the trained model. Only set for successful jobs that don't use hyperparameter tuning. python-version=at Python version on which the built-in algorithm was trained. runtime-version=sit AI Platform runtime version on which the built-in algorithm was trained. .. completed-trial-count=-20 The number of hyperparameter tuning trials that completed successfully. Only set for hyperparameter tuning jobs. consumed-ml-units=0.38020685422472145 The amount of ML units consumed by the job. hyperparameter-metric-tag=et The TensorFlow summary tag name used for optimizing hyperparameter tuning trials. See HyperparameterSpec.hyperparameterMetricTag for more information. Only set for hyperparameter tuning jobs. is-built-in-algorithm-job=true Whether this job is a built-in Algorithm job. is-hyperparameter-tuning-job=false Whether this job is a hyperparameter tuning job. web-access-uris=key=amet. Output only. URIs for accessing interactive shells (one URI for each training node). Only available if training_input.enable_web_access is true . The keys are names of each node in the training job; for example, master-replica-0 for the master node, worker-replica-0 for the first worker, and ps-replica-0 for the first parameter server. The values are the URIs for each node's interactive shell. the value will be associated with the given key About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional Method Properties You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p update-mask=string Required. Specifies the path, relative to Job , of the field to update. To adopt etag mechanism, include etag field in the mask, and include the etag value in your job resource. For example, to change the labels of a job, the update_mask parameter would be specified as labels , etag , and the PATCH request body would specify the new value, as follows: { \"labels\": { \"owner\": \"Google\", \"color\": \"Blue\" } \"etag\": \"33a64df551425fcc55e4d42a148795d9f25f89d4\" } If etag matches the one on the server, the labels of the job will be replaced with the given ones, and the server end etag will be recalculated. Currently the only supported update masks are labels and etag . Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Jobs Patch"},{"location":"projects_jobs-patch/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects jobs-patch ...","title":"Scopes"},{"location":"projects_jobs-patch/#required-scalar-argument","text":"<name> (string) Required. The job name.","title":"Required Scalar Argument"},{"location":"projects_jobs-patch/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__Job: create-time: string end-time: string error-message: string etag: string job-id: string job-position: string labels: { string: string } prediction-input: batch-size: string data-format: string input-paths: [string] max-worker-count: int64 model-name: string output-data-format: string output-path: string region: string runtime-version: string signature-name: string uri: string version-name: string prediction-output: error-count: int64 node-hours: number output-path: string prediction-count: int64 start-time: string state: string training-input: args: [string] enable-web-access: boolean encryption-config: kms-key-name: string evaluator-config: accelerator-config: count: string type: string container-args: [string] container-command: [string] disk-config: boot-disk-size-gb: integer boot-disk-type: string image-uri: string tpu-tf-version: string evaluator-count: int64 evaluator-type: string hyperparameters: algorithm: string enable-trial-early-stopping: boolean goal: string hyperparameter-metric-tag: string max-failed-trials: integer max-parallel-trials: integer max-trials: integer resume-previous-job-id: string job-dir: string master-config: accelerator-config: count: string type: string container-args: [string] container-command: [string] disk-config: boot-disk-size-gb: integer boot-disk-type: string image-uri: string tpu-tf-version: string master-type: string network: string package-uris: [string] parameter-server-config: accelerator-config: count: string type: string container-args: [string] container-command: [string] disk-config: boot-disk-size-gb: integer boot-disk-type: string image-uri: string tpu-tf-version: string parameter-server-count: int64 parameter-server-type: string python-module: string python-version: string region: string runtime-version: string scale-tier: string scheduling: max-running-time: string max-wait-time: string priority: integer service-account: string use-chief-in-tf-config: boolean worker-config: accelerator-config: count: string type: string container-args: [string] container-command: [string] disk-config: boot-disk-size-gb: integer boot-disk-type: string image-uri: string tpu-tf-version: string worker-count: int64 worker-type: string training-output: built-in-algorithm-output: framework: string model-path: string python-version: string runtime-version: string completed-trial-count: int64 consumed-ml-units: number hyperparameter-metric-tag: string is-built-in-algorithm-job: boolean is-hyperparameter-tuning-job: boolean web-access-uris: { string: string } can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r . create-time=et Output only. When the job was created. end-time=tempor Output only. When the job processing was completed. error-message=aliquyam Output only. The details of a failure or a cancellation. etag=ipsum etag is used for optimistic concurrency control as a way to help prevent simultaneous updates of a job from overwriting each other. It is strongly suggested that systems make use of the etag in the read-modify-write cycle to perform job updates in order to avoid race conditions: An etag is returned in the response to GetJob , and systems are expected to put that etag in the request to UpdateJob to ensure that their change will be applied to the same version of the job. job-id=et Required. The user-specified id of the job. job-position=sanctus Output only. It's only effect when the job is in QUEUED state. If it's positive, it indicates the job's position in the job scheduler. It's 0 when the job is already scheduled. labels=key=lorem Optional. One or more labels that you can add, to organize your jobs. Each label is a key-value pair, where both the key and the value are arbitrary strings that you supply. For more information, see the documentation on using labels. the value will be associated with the given key prediction-input batch-size=est Optional. Number of records per batch, defaults to 64. The service will buffer batch_size number of records in memory before invoking one Tensorflow prediction call internally. So take the record size and memory available into consideration when setting this parameter. data-format=sed Required. The format of the input data files. input-paths=diam Required. The Cloud Storage location of the input data files. May contain wildcards. Each invocation of this argument appends the given value to the array. max-worker-count=-19 Optional. The maximum number of workers to be used for parallel processing. Defaults to 10 if not specified. model-name=dolores Use this field if you want to use the default version for the specified model. The string must use the following format: &#34;projects/YOUR_PROJECT/models/YOUR_MODEL&#34; output-data-format=et Optional. Format of the output data files, defaults to JSON. output-path=sed Required. The output Google Cloud Storage location. region=no Required. The Google Compute Engine region to run the prediction job in. See the available regions for AI Platform services. runtime-version=et Optional. The AI Platform runtime version to use for this batch prediction. If not set, AI Platform will pick the runtime version used during the CreateVersion request for this model version, or choose the latest stable version when model version information is not available such as when the model is specified by uri. signature-name=elitr Optional. The name of the signature defined in the SavedModel to use for this job. Please refer to SavedModel for information about how to use signatures. Defaults to DEFAULT_SERVING_SIGNATURE_DEF_KEY , which is \"serving_default\". uri=sed Use this field if you want to specify a Google Cloud Storage path for the model to use. version-name=no Use this field if you want to specify a version of the model to use. The string is formatted the same way as model_version , with the addition of the version information: &#34;projects/YOUR_PROJECT/models/YOUR_MODEL/versions/YOUR_VERSION&#34; ..prediction-output error-count=-91 The number of data instances which resulted in errors. node-hours=0.1918654921610582 Node hours used by the batch prediction job. output-path=aliquyam The output Google Cloud Storage location provided at the job creation time. prediction-count=-69 The number of generated predictions. .. start-time=sadipscing Output only. When the job processing was started. state=erat Output only. The detailed state of a job. training-input args=aliquyam Optional. Command-line arguments passed to the training application when it starts. If your job uses a custom container, then the arguments are passed to the container's ENTRYPOINT command. Each invocation of this argument appends the given value to the array. enable-web-access=true Optional. Whether you want AI Platform Training to enable interactive shell access to training containers. If set to true , you can access interactive shells at the URIs given by TrainingOutput.web_access_uris or HyperparameterOutput.web_access_uris (within TrainingOutput.trials). encryption-config kms-key-name=est The Cloud KMS resource identifier of the customer-managed encryption key used to protect a resource, such as a training job. It has the following format: projects/{PROJECT_ID}/locations/{REGION}/keyRings/{KEY_RING_NAME}/cryptoKeys/{KEY_NAME} ..evaluator-config.accelerator-config count=et The number of accelerators to attach to each machine running the job. type=sea The type of accelerator to use. .. container-args=consetetur Arguments to the entrypoint command. The following rules apply for container_command and container_args: - If you do not supply command or args: The defaults defined in the Docker image are used. - If you supply a command but no args: The default EntryPoint and the default Cmd defined in the Docker image are ignored. Your command is run without any arguments. - If you supply only args: The default Entrypoint defined in the Docker image is run with the args that you supplied. - If you supply a command and args: The default Entrypoint and the default Cmd defined in the Docker image are ignored. Your command is run with your args. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. container-command=consetetur The command with which the replica's custom container is run. If provided, it will override default ENTRYPOINT of the docker image. If not provided, the docker image's ENTRYPOINT is used. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. disk-config boot-disk-size-gb=36 Size in GB of the boot disk (default is 100GB). boot-disk-type=est Type of the boot disk (default is \"pd-ssd\"). Valid values: \"pd-ssd\" (Persistent Disk Solid State Drive) or \"pd-standard\" (Persistent Disk Hard Disk Drive). .. image-uri=aliquyam The Docker image to run on the replica. This image must be in Container Registry. Learn more about configuring custom containers . tpu-tf-version=elitr The AI Platform runtime version that includes a TensorFlow version matching the one used in the custom container. This field is required if the replica is a TPU worker that uses a custom container. Otherwise, do not specify this field. This must be a runtime version that currently supports training with TPUs . Note that the version of TensorFlow included in a runtime version may differ from the numbering of the runtime version itself, because it may have a different patch version . In this field, you must specify the runtime version (TensorFlow minor version). For example, if your custom container runs TensorFlow 1.x.y , specify 1.x . .. evaluator-count=-20 Optional. The number of evaluator replicas to use for the training job. Each replica in the cluster will be of the type specified in evaluator_type . This value can only be used when scale_tier is set to CUSTOM . If you set this value, you must also set evaluator_type . The default value is zero. evaluator-type=diam Optional. Specifies the type of virtual machine to use for your training job's evaluator nodes. The supported values are the same as those described in the entry for masterType . This value must be consistent with the category of machine type that masterType uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. This value must be present when scaleTier is set to CUSTOM and evaluatorCount is greater than zero. hyperparameters algorithm=est Optional. The search algorithm specified for the hyperparameter tuning job. Uses the default AI Platform hyperparameter tuning algorithm if unspecified. enable-trial-early-stopping=true Optional. Indicates if the hyperparameter tuning job enables auto trial early stopping. goal=sed Required. The type of goal to use for tuning. Available types are MAXIMIZE and MINIMIZE . Defaults to MAXIMIZE . hyperparameter-metric-tag=eos Optional. The TensorFlow summary tag name to use for optimizing trials. For current versions of TensorFlow, this tag name should exactly match what is shown in TensorBoard, including all scopes. For versions of TensorFlow prior to 0.12, this should be only the tag passed to tf.Summary. By default, \"training/hptuning/metric\" will be used. max-failed-trials=45 Optional. The number of failed trials that need to be seen before failing the hyperparameter tuning job. You can specify this field to override the default failing criteria for AI Platform hyperparameter tuning jobs. Defaults to zero, which means the service decides when a hyperparameter job should fail. max-parallel-trials=84 Optional. The number of training trials to run concurrently. You can reduce the time it takes to perform hyperparameter tuning by adding trials in parallel. However, each trail only benefits from the information gained in completed trials. That means that a trial does not get access to the results of trials running at the same time, which could reduce the quality of the overall optimization. Each trial will use the same scale tier and machine types. Defaults to one. max-trials=86 Optional. How many training trials should be attempted to optimize the specified hyperparameters. Defaults to one. resume-previous-job-id=dolores Optional. The prior hyperparameter tuning job id that users hope to continue with. The job id will be used to find the corresponding vizier study guid and resume the study. .. job-dir=eos Optional. A Google Cloud Storage path in which to store training outputs and other data needed for training. This path is passed to your TensorFlow program as the '--job-dir' command-line argument. The benefit of specifying this field is that Cloud ML validates the path for use in training. master-config.accelerator-config count=et The number of accelerators to attach to each machine running the job. type=sea The type of accelerator to use. .. container-args=et Arguments to the entrypoint command. The following rules apply for container_command and container_args: - If you do not supply command or args: The defaults defined in the Docker image are used. - If you supply a command but no args: The default EntryPoint and the default Cmd defined in the Docker image are ignored. Your command is run without any arguments. - If you supply only args: The default Entrypoint defined in the Docker image is run with the args that you supplied. - If you supply a command and args: The default Entrypoint and the default Cmd defined in the Docker image are ignored. Your command is run with your args. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. container-command=at The command with which the replica's custom container is run. If provided, it will override default ENTRYPOINT of the docker image. If not provided, the docker image's ENTRYPOINT is used. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. disk-config boot-disk-size-gb=17 Size in GB of the boot disk (default is 100GB). boot-disk-type=eirmod Type of the boot disk (default is \"pd-ssd\"). Valid values: \"pd-ssd\" (Persistent Disk Solid State Drive) or \"pd-standard\" (Persistent Disk Hard Disk Drive). .. image-uri=lorem The Docker image to run on the replica. This image must be in Container Registry. Learn more about configuring custom containers . tpu-tf-version=accusam The AI Platform runtime version that includes a TensorFlow version matching the one used in the custom container. This field is required if the replica is a TPU worker that uses a custom container. Otherwise, do not specify this field. This must be a runtime version that currently supports training with TPUs . Note that the version of TensorFlow included in a runtime version may differ from the numbering of the runtime version itself, because it may have a different patch version . In this field, you must specify the runtime version (TensorFlow minor version). For example, if your custom container runs TensorFlow 1.x.y , specify 1.x . .. master-type=amet Optional. Specifies the type of virtual machine to use for your training job's master worker. You must specify this field when scaleTier is set to CUSTOM . You can use certain Compute Engine machine types directly in this field. See the list of compatible Compute Engine machine types . Alternatively, you can use the certain legacy machine types in this field. See the list of legacy machine types . Finally, if you want to use a TPU for training, specify cloud_tpu in this field. Learn more about the special configuration options for training with TPUs . network=erat Optional. The full name of the Compute Engine network to which the Job is peered. For example, projects/12345/global/networks/myVPC . The format of this field is projects/{project}/global/networks/{network} , where {project} is a project number (like 12345 ) and {network} is network name. Private services access must already be configured for the network. If left unspecified, the Job is not peered with any network. Learn about using VPC Network Peering. . package-uris=dolores Required. The Google Cloud Storage location of the packages with the training program and any additional dependencies. The maximum number of package URIs is 100. Each invocation of this argument appends the given value to the array. parameter-server-config.accelerator-config count=erat The number of accelerators to attach to each machine running the job. type=accusam The type of accelerator to use. .. container-args=sea Arguments to the entrypoint command. The following rules apply for container_command and container_args: - If you do not supply command or args: The defaults defined in the Docker image are used. - If you supply a command but no args: The default EntryPoint and the default Cmd defined in the Docker image are ignored. Your command is run without any arguments. - If you supply only args: The default Entrypoint defined in the Docker image is run with the args that you supplied. - If you supply a command and args: The default Entrypoint and the default Cmd defined in the Docker image are ignored. Your command is run with your args. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. container-command=takimata The command with which the replica's custom container is run. If provided, it will override default ENTRYPOINT of the docker image. If not provided, the docker image's ENTRYPOINT is used. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. disk-config boot-disk-size-gb=50 Size in GB of the boot disk (default is 100GB). boot-disk-type=et Type of the boot disk (default is \"pd-ssd\"). Valid values: \"pd-ssd\" (Persistent Disk Solid State Drive) or \"pd-standard\" (Persistent Disk Hard Disk Drive). .. image-uri=at The Docker image to run on the replica. This image must be in Container Registry. Learn more about configuring custom containers . tpu-tf-version=dolor The AI Platform runtime version that includes a TensorFlow version matching the one used in the custom container. This field is required if the replica is a TPU worker that uses a custom container. Otherwise, do not specify this field. This must be a runtime version that currently supports training with TPUs . Note that the version of TensorFlow included in a runtime version may differ from the numbering of the runtime version itself, because it may have a different patch version . In this field, you must specify the runtime version (TensorFlow minor version). For example, if your custom container runs TensorFlow 1.x.y , specify 1.x . .. parameter-server-count=-22 Optional. The number of parameter server replicas to use for the training job. Each replica in the cluster will be of the type specified in parameter_server_type . This value can only be used when scale_tier is set to CUSTOM . If you set this value, you must also set parameter_server_type . The default value is zero. parameter-server-type=sit Optional. Specifies the type of virtual machine to use for your training job's parameter server. The supported values are the same as those described in the entry for master_type . This value must be consistent with the category of machine type that masterType uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. This value must be present when scaleTier is set to CUSTOM and parameter_server_count is greater than zero. python-module=erat Required. The Python module name to run after installing the packages. python-version=sea Optional. The version of Python used in training. You must either specify this field or specify masterConfig.imageUri . The following Python versions are available: * Python '3.7' is available when runtime_version is set to '1.15' or later. * Python '3.5' is available when runtime_version is set to a version from '1.4' to '1.14'. * Python '2.7' is available when runtime_version is set to '1.15' or earlier. Read more about the Python versions available for each runtime version . region=nonumy Required. The region to run the training job in. See the available regions for AI Platform Training. runtime-version=et Optional. The AI Platform runtime version to use for training. You must either specify this field or specify masterConfig.imageUri . For more information, see the runtime version list and learn how to manage runtime versions . scale-tier=gubergren Required. Specifies the machine types, the number of replicas for workers and parameter servers. scheduling max-running-time=justo Optional. The maximum job running time, expressed in seconds. The field can contain up to nine fractional digits, terminated by s . If not specified, this field defaults to 604800s (seven days). If the training job is still running after this duration, AI Platform Training cancels it. The duration is measured from when the job enters the RUNNING state; therefore it does not overlap with the duration limited by Scheduling.max_wait_time. For example, if you want to ensure your job runs for no more than 2 hours, set this field to 7200s (2 hours * 60 minutes / hour * 60 seconds / minute). If you submit your training job using the gcloud tool, you can specify this field in a config.yaml file . For example: yaml trainingInput: scheduling: maxRunningTime: 7200s max-wait-time=sea Optional. The maximum job wait time, expressed in seconds. The field can contain up to nine fractional digits, terminated by s . If not specified, there is no limit to the wait time. The minimum for this field is 1800s (30 minutes). If the training job has not entered the RUNNING state after this duration, AI Platform Training cancels it. After the job begins running, it can no longer be cancelled due to the maximum wait time. Therefore the duration limited by this field does not overlap with the duration limited by Scheduling.max_running_time. For example, if the job temporarily stops running and retries due to a VM restart , this cannot lead to a maximum wait time cancellation. However, independently of this constraint, AI Platform Training might stop a job if there are too many retries due to exhausted resources in a region. The following example describes how you might use this field: To cancel your job if it doesn't start running within 1 hour, set this field to 3600s (1 hour * 60 minutes / hour * 60 seconds / minute). If the job is still in the QUEUED or PREPARING state after an hour of waiting, AI Platform Training cancels the job. If you submit your training job using the gcloud tool, you can specify this field in a config.yaml file . For example: yaml trainingInput: scheduling: maxWaitTime: 3600s priority=5 Optional. Job scheduling will be based on this priority, which in the range [0, 1000]. The bigger the number, the higher the priority. Default to 0 if not set. If there are multiple jobs requesting same type of accelerators, the high priority job will be scheduled prior to ones with low priority. .. service-account=sit Optional. The email address of a service account to use when running the training appplication. You must have the iam.serviceAccounts.actAs permission for the specified service account. In addition, the AI Platform Training Google-managed service account must have the roles/iam.serviceAccountAdmin role for the specified service account. Learn more about configuring a service account. If not specified, the AI Platform Training Google-managed service account is used by default. use-chief-in-tf-config=false Optional. Use chief instead of master in the TF_CONFIG environment variable when training with a custom container. Defaults to false . Learn more about this field. This field has no effect for training jobs that don't use a custom container. worker-config.accelerator-config count=dolores The number of accelerators to attach to each machine running the job. type=consetetur The type of accelerator to use. .. container-args=gubergren Arguments to the entrypoint command. The following rules apply for container_command and container_args: - If you do not supply command or args: The defaults defined in the Docker image are used. - If you supply a command but no args: The default EntryPoint and the default Cmd defined in the Docker image are ignored. Your command is run without any arguments. - If you supply only args: The default Entrypoint defined in the Docker image is run with the args that you supplied. - If you supply a command and args: The default Entrypoint and the default Cmd defined in the Docker image are ignored. Your command is run with your args. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. container-command=dolor The command with which the replica's custom container is run. If provided, it will override default ENTRYPOINT of the docker image. If not provided, the docker image's ENTRYPOINT is used. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time. Each invocation of this argument appends the given value to the array. disk-config boot-disk-size-gb=69 Size in GB of the boot disk (default is 100GB). boot-disk-type=no Type of the boot disk (default is \"pd-ssd\"). Valid values: \"pd-ssd\" (Persistent Disk Solid State Drive) or \"pd-standard\" (Persistent Disk Hard Disk Drive). .. image-uri=amet. The Docker image to run on the replica. This image must be in Container Registry. Learn more about configuring custom containers . tpu-tf-version=ipsum The AI Platform runtime version that includes a TensorFlow version matching the one used in the custom container. This field is required if the replica is a TPU worker that uses a custom container. Otherwise, do not specify this field. This must be a runtime version that currently supports training with TPUs . Note that the version of TensorFlow included in a runtime version may differ from the numbering of the runtime version itself, because it may have a different patch version . In this field, you must specify the runtime version (TensorFlow minor version). For example, if your custom container runs TensorFlow 1.x.y , specify 1.x . .. worker-count=-56 Optional. The number of worker replicas to use for the training job. Each replica in the cluster will be of the type specified in worker_type . This value can only be used when scale_tier is set to CUSTOM . If you set this value, you must also set worker_type . The default value is zero. worker-type=accusam Optional. Specifies the type of virtual machine to use for your training job's worker nodes. The supported values are the same as those described in the entry for masterType . This value must be consistent with the category of machine type that masterType uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. If you use cloud_tpu for this value, see special instructions for configuring a custom TPU machine . This value must be present when scaleTier is set to CUSTOM and workerCount is greater than zero. ..training-output.built-in-algorithm-output framework=gubergren Framework on which the built-in algorithm was trained. model-path=sadipscing The Cloud Storage path to the model/ directory where the training job saves the trained model. Only set for successful jobs that don't use hyperparameter tuning. python-version=at Python version on which the built-in algorithm was trained. runtime-version=sit AI Platform runtime version on which the built-in algorithm was trained. .. completed-trial-count=-20 The number of hyperparameter tuning trials that completed successfully. Only set for hyperparameter tuning jobs. consumed-ml-units=0.38020685422472145 The amount of ML units consumed by the job. hyperparameter-metric-tag=et The TensorFlow summary tag name used for optimizing hyperparameter tuning trials. See HyperparameterSpec.hyperparameterMetricTag for more information. Only set for hyperparameter tuning jobs. is-built-in-algorithm-job=true Whether this job is a built-in Algorithm job. is-hyperparameter-tuning-job=false Whether this job is a hyperparameter tuning job. web-access-uris=key=amet. Output only. URIs for accessing interactive shells (one URI for each training node). Only available if training_input.enable_web_access is true . The keys are names of each node in the training job; for example, master-replica-0 for the master node, worker-replica-0 for the first worker, and ps-replica-0 for the first parameter server. The values are the URIs for each node's interactive shell. the value will be associated with the given key","title":"Required Request Value"},{"location":"projects_jobs-patch/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"projects_jobs-patch/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_jobs-patch/#optional-method-properties","text":"You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p update-mask=string Required. Specifies the path, relative to Job , of the field to update. To adopt etag mechanism, include etag field in the mask, and include the etag value in your job resource. For example, to change the labels of a job, the update_mask parameter would be specified as labels , etag , and the PATCH request body would specify the new value, as follows: { \"labels\": { \"owner\": \"Google\", \"color\": \"Blue\" } \"etag\": \"33a64df551425fcc55e4d42a148795d9f25f89d4\" } If etag matches the one on the server, the labels of the job will be replaced with the given ones, and the server end etag will be recalculated. Currently the only supported update masks are labels and etag .","title":"Optional Method Properties"},{"location":"projects_jobs-patch/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_jobs-set-iam-policy/","text":"Sets the access control policy on the specified resource. Replaces any existing policy. Can return NOT_FOUND , INVALID_ARGUMENT , and PERMISSION_DENIED errors. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects jobs-set-iam-policy ... Required Scalar Argument <resource> (string) REQUIRED: The resource for which the policy is being specified. See Resource names for the appropriate value for this field. Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleIamV1__SetIamPolicyRequest: policy: etag: string version: integer update-mask: string can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r .policy etag=no etag is used for optimistic concurrency control as a way to help prevent simultaneous updates of a policy from overwriting each other. It is strongly suggested that systems make use of the etag in the read-modify-write cycle to perform policy updates in order to avoid race conditions: An etag is returned in the response to getIamPolicy , and systems are expected to put that etag in the request to setIamPolicy to ensure that their change will be applied to the same version of the policy. Important: If you use IAM Conditions, you must include the etag field whenever you call setIamPolicy . If you omit this field, then IAM allows you to overwrite a version 3 policy with a version 1 policy, and all of the conditions in the version 3 policy are lost. version=10 Specifies the format of the policy. Valid values are 0 , 1 , and 3 . Requests that specify an invalid value are rejected. Any operation that affects conditional role bindings must specify version 3 . This requirement applies to the following operations: * Getting a policy that includes a conditional role binding * Adding a conditional role binding to a policy * Changing a conditional role binding in a policy * Removing any role binding, with or without a condition, from a policy that includes conditions Important: If you use IAM Conditions, you must include the etag field whenever you call setIamPolicy . If you omit this field, then IAM allows you to overwrite a version 3 policy with a version 1 policy, and all of the conditions in the version 3 policy are lost. If a policy does not include any conditions, operations on that policy may specify any valid version or leave the field unset. To learn which resources support conditions in their IAM policies, see the IAM documentation . .. update-mask=sed OPTIONAL: A FieldMask specifying which fields of the policy to modify. Only the fields in the mask will be modified. If no mask is provided, the following default mask is used: paths: &#34;bindings, etag&#34; About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Jobs Set Iam Policy"},{"location":"projects_jobs-set-iam-policy/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects jobs-set-iam-policy ...","title":"Scopes"},{"location":"projects_jobs-set-iam-policy/#required-scalar-argument","text":"<resource> (string) REQUIRED: The resource for which the policy is being specified. See Resource names for the appropriate value for this field.","title":"Required Scalar Argument"},{"location":"projects_jobs-set-iam-policy/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleIamV1__SetIamPolicyRequest: policy: etag: string version: integer update-mask: string can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r .policy etag=no etag is used for optimistic concurrency control as a way to help prevent simultaneous updates of a policy from overwriting each other. It is strongly suggested that systems make use of the etag in the read-modify-write cycle to perform policy updates in order to avoid race conditions: An etag is returned in the response to getIamPolicy , and systems are expected to put that etag in the request to setIamPolicy to ensure that their change will be applied to the same version of the policy. Important: If you use IAM Conditions, you must include the etag field whenever you call setIamPolicy . If you omit this field, then IAM allows you to overwrite a version 3 policy with a version 1 policy, and all of the conditions in the version 3 policy are lost. version=10 Specifies the format of the policy. Valid values are 0 , 1 , and 3 . Requests that specify an invalid value are rejected. Any operation that affects conditional role bindings must specify version 3 . This requirement applies to the following operations: * Getting a policy that includes a conditional role binding * Adding a conditional role binding to a policy * Changing a conditional role binding in a policy * Removing any role binding, with or without a condition, from a policy that includes conditions Important: If you use IAM Conditions, you must include the etag field whenever you call setIamPolicy . If you omit this field, then IAM allows you to overwrite a version 3 policy with a version 1 policy, and all of the conditions in the version 3 policy are lost. If a policy does not include any conditions, operations on that policy may specify any valid version or leave the field unset. To learn which resources support conditions in their IAM policies, see the IAM documentation . .. update-mask=sed OPTIONAL: A FieldMask specifying which fields of the policy to modify. Only the fields in the mask will be modified. If no mask is provided, the following default mask is used: paths: &#34;bindings, etag&#34;","title":"Required Request Value"},{"location":"projects_jobs-set-iam-policy/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"projects_jobs-set-iam-policy/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_jobs-set-iam-policy/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_jobs-test-iam-permissions/","text":"Returns permissions that a caller has on the specified resource. If the resource does not exist, this will return an empty set of permissions, not a NOT_FOUND error. Note: This operation is designed to be used for building permission-aware UIs and command-line tools, not for authorization checking. This operation may \"fail open\" without warning. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects jobs-test-iam-permissions ... Required Scalar Argument <resource> (string) REQUIRED: The resource for which the policy detail is being requested. See Resource names for the appropriate value for this field. Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleIamV1__TestIamPermissionsRequest: permissions: [string] can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r . permissions=kasd The set of permissions to check for the resource . Permissions with wildcards (such as * or storage.* ) are not allowed. For more information see IAM Overview . Each invocation of this argument appends the given value to the array. About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Jobs Test Iam Permissions"},{"location":"projects_jobs-test-iam-permissions/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects jobs-test-iam-permissions ...","title":"Scopes"},{"location":"projects_jobs-test-iam-permissions/#required-scalar-argument","text":"<resource> (string) REQUIRED: The resource for which the policy detail is being requested. See Resource names for the appropriate value for this field.","title":"Required Scalar Argument"},{"location":"projects_jobs-test-iam-permissions/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleIamV1__TestIamPermissionsRequest: permissions: [string] can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r . permissions=kasd The set of permissions to check for the resource . Permissions with wildcards (such as * or storage.* ) are not allowed. For more information see IAM Overview . Each invocation of this argument appends the given value to the array.","title":"Required Request Value"},{"location":"projects_jobs-test-iam-permissions/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"projects_jobs-test-iam-permissions/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_jobs-test-iam-permissions/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_locations-get/","text":"Get the complete list of CMLE capabilities in a location, along with their location-specific properties. Scopes You will need authorization for at least one of the following scopes to make a valid call: https://www.googleapis.com/auth/cloud-platform https://www.googleapis.com/auth/cloud-platform.read-only If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-get ... Required Scalar Argument <name> (string) Required. The name of the location. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Locations Get"},{"location":"projects_locations-get/#scopes","text":"You will need authorization for at least one of the following scopes to make a valid call: https://www.googleapis.com/auth/cloud-platform https://www.googleapis.com/auth/cloud-platform.read-only If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-get ...","title":"Scopes"},{"location":"projects_locations-get/#required-scalar-argument","text":"<name> (string) Required. The name of the location.","title":"Required Scalar Argument"},{"location":"projects_locations-get/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_locations-get/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_locations-list/","text":"List all locations that provides at least one type of CMLE capability. Scopes You will need authorization for at least one of the following scopes to make a valid call: https://www.googleapis.com/auth/cloud-platform https://www.googleapis.com/auth/cloud-platform.read-only If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-list ... Required Scalar Argument <parent> (string) Required. The name of the project for which available locations are to be listed (since some locations might be whitelisted for specific projects). Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional Method Properties You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p page-size=integer Optional. The number of locations to retrieve per \"page\" of results. If there are more remaining results than this number, the response message will contain a valid value in the next_page_token field. The default value is 20, and the maximum page size is 100. -p page-token=string Optional. A page token to request the next page of results. You get the token from the next_page_token field of the response from the previous call. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Locations List"},{"location":"projects_locations-list/#scopes","text":"You will need authorization for at least one of the following scopes to make a valid call: https://www.googleapis.com/auth/cloud-platform https://www.googleapis.com/auth/cloud-platform.read-only If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-list ...","title":"Scopes"},{"location":"projects_locations-list/#required-scalar-argument","text":"<parent> (string) Required. The name of the project for which available locations are to be listed (since some locations might be whitelisted for specific projects).","title":"Required Scalar Argument"},{"location":"projects_locations-list/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_locations-list/#optional-method-properties","text":"You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p page-size=integer Optional. The number of locations to retrieve per \"page\" of results. If there are more remaining results than this number, the response message will contain a valid value in the next_page_token field. The default value is 20, and the maximum page size is 100. -p page-token=string Optional. A page token to request the next page of results. You get the token from the next_page_token field of the response from the previous call.","title":"Optional Method Properties"},{"location":"projects_locations-list/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_locations-operations-cancel/","text":"Starts asynchronous cancellation on a long-running operation. The server makes a best effort to cancel the operation, but success is not guaranteed. If the server doesn't support this method, it returns google.rpc.Code.UNIMPLEMENTED . Clients can use Operations.GetOperation or other methods to check whether the cancellation succeeded or whether the operation completed despite cancellation. On successful cancellation, the operation is not deleted; instead, it becomes an operation with an Operation.error value with a google.rpc.Status.code of 1, corresponding to Code.CANCELLED . Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-operations-cancel ... Required Scalar Argument <name> (string) The name of the operation resource to be cancelled. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Locations Operations Cancel"},{"location":"projects_locations-operations-cancel/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-operations-cancel ...","title":"Scopes"},{"location":"projects_locations-operations-cancel/#required-scalar-argument","text":"<name> (string) The name of the operation resource to be cancelled.","title":"Required Scalar Argument"},{"location":"projects_locations-operations-cancel/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_locations-operations-cancel/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_locations-operations-get/","text":"Gets the latest state of a long-running operation. Clients can use this method to poll the operation result at intervals as recommended by the API service. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-operations-get ... Required Scalar Argument <name> (string) The name of the operation resource. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Locations Operations Get"},{"location":"projects_locations-operations-get/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-operations-get ...","title":"Scopes"},{"location":"projects_locations-operations-get/#required-scalar-argument","text":"<name> (string) The name of the operation resource.","title":"Required Scalar Argument"},{"location":"projects_locations-operations-get/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_locations-operations-get/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_locations-studies-create/","text":"Creates a study. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-create ... Required Scalar Argument <parent> (string) Required. The project and location that the study belongs to. Format: projects/{project}/locations/{location} Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__Study: create-time: string inactive-reason: string name: string state: string study-config: algorithm: string automated-stopping-config: decay-curve-stopping-config: use-elapsed-time: boolean median-automated-stopping-config: use-elapsed-time: boolean can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r . create-time=lorem Output only. Time at which the study was created. inactive-reason=sanctus Output only. A human readable reason why the Study is inactive. This should be empty if a study is ACTIVE or COMPLETED. name=nonumy Output only. The name of a study. state=rebum. Output only. The detailed state of a study. study-config algorithm=tempor The search algorithm specified for the study. automated-stopping-config.decay-curve-stopping-config use-elapsed-time=true If true, measurement.elapsed_time is used as the x-axis of each Trials Decay Curve. Otherwise, Measurement.steps will be used as the x-axis. ..median-automated-stopping-config use-elapsed-time=false If true, the median automated stopping rule applies to measurement.use_elapsed_time, which means the elapsed_time field of the current trial's latest measurement is used to compute the median objective value for each completed trial. About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional Method Properties You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p study-id=string Required. The ID to use for the study, which will become the final component of the study's resource name. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Locations Studies Create"},{"location":"projects_locations-studies-create/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-create ...","title":"Scopes"},{"location":"projects_locations-studies-create/#required-scalar-argument","text":"<parent> (string) Required. The project and location that the study belongs to. Format: projects/{project}/locations/{location}","title":"Required Scalar Argument"},{"location":"projects_locations-studies-create/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__Study: create-time: string inactive-reason: string name: string state: string study-config: algorithm: string automated-stopping-config: decay-curve-stopping-config: use-elapsed-time: boolean median-automated-stopping-config: use-elapsed-time: boolean can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r . create-time=lorem Output only. Time at which the study was created. inactive-reason=sanctus Output only. A human readable reason why the Study is inactive. This should be empty if a study is ACTIVE or COMPLETED. name=nonumy Output only. The name of a study. state=rebum. Output only. The detailed state of a study. study-config algorithm=tempor The search algorithm specified for the study. automated-stopping-config.decay-curve-stopping-config use-elapsed-time=true If true, measurement.elapsed_time is used as the x-axis of each Trials Decay Curve. Otherwise, Measurement.steps will be used as the x-axis. ..median-automated-stopping-config use-elapsed-time=false If true, the median automated stopping rule applies to measurement.use_elapsed_time, which means the elapsed_time field of the current trial's latest measurement is used to compute the median objective value for each completed trial.","title":"Required Request Value"},{"location":"projects_locations-studies-create/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"projects_locations-studies-create/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_locations-studies-create/#optional-method-properties","text":"You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p study-id=string Required. The ID to use for the study, which will become the final component of the study's resource name.","title":"Optional Method Properties"},{"location":"projects_locations-studies-create/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_locations-studies-delete/","text":"Deletes a study. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-delete ... Required Scalar Argument <name> (string) Required. The study name. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Locations Studies Delete"},{"location":"projects_locations-studies-delete/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-delete ...","title":"Scopes"},{"location":"projects_locations-studies-delete/#required-scalar-argument","text":"<name> (string) Required. The study name.","title":"Required Scalar Argument"},{"location":"projects_locations-studies-delete/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_locations-studies-delete/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_locations-studies-get/","text":"Gets a study. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-get ... Required Scalar Argument <name> (string) Required. The study name. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Locations Studies Get"},{"location":"projects_locations-studies-get/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-get ...","title":"Scopes"},{"location":"projects_locations-studies-get/#required-scalar-argument","text":"<name> (string) Required. The study name.","title":"Required Scalar Argument"},{"location":"projects_locations-studies-get/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_locations-studies-get/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_locations-studies-list/","text":"Lists all the studies in a region for an associated project. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-list ... Required Scalar Argument <parent> (string) Required. The project and location that the study belongs to. Format: projects/{project}/locations/{location} Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Locations Studies List"},{"location":"projects_locations-studies-list/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-list ...","title":"Scopes"},{"location":"projects_locations-studies-list/#required-scalar-argument","text":"<parent> (string) Required. The project and location that the study belongs to. Format: projects/{project}/locations/{location}","title":"Required Scalar Argument"},{"location":"projects_locations-studies-list/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_locations-studies-list/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_locations-studies-trials-add-measurement/","text":"Adds a measurement of the objective metrics to a trial. This measurement is assumed to have been taken before the trial is complete. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-trials-add-measurement ... Required Scalar Argument <name> (string) Required. The trial name. Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__AddTrialMeasurementRequest: measurement: elapsed-time: string step-count: int64 can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r .measurement elapsed-time=amet Output only. Time that the trial has been running at the point of this measurement. step-count=-37 The number of steps a machine learning model has been trained for. Must be non-negative. About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Locations Studies Trials Add Measurement"},{"location":"projects_locations-studies-trials-add-measurement/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-trials-add-measurement ...","title":"Scopes"},{"location":"projects_locations-studies-trials-add-measurement/#required-scalar-argument","text":"<name> (string) Required. The trial name.","title":"Required Scalar Argument"},{"location":"projects_locations-studies-trials-add-measurement/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__AddTrialMeasurementRequest: measurement: elapsed-time: string step-count: int64 can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r .measurement elapsed-time=amet Output only. Time that the trial has been running at the point of this measurement. step-count=-37 The number of steps a machine learning model has been trained for. Must be non-negative.","title":"Required Request Value"},{"location":"projects_locations-studies-trials-add-measurement/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"projects_locations-studies-trials-add-measurement/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_locations-studies-trials-add-measurement/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_locations-studies-trials-check-early-stopping-state/","text":"Checks whether a trial should stop or not. Returns a long-running operation. When the operation is successful, it will contain a CheckTrialEarlyStoppingStateResponse. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-trials-check-early-stopping-state ... Required Scalar Argument <name> (string) Required. The trial name. Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__CheckTrialEarlyStoppingStateRequest: can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Locations Studies Trials Check Early Stopping State"},{"location":"projects_locations-studies-trials-check-early-stopping-state/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-trials-check-early-stopping-state ...","title":"Scopes"},{"location":"projects_locations-studies-trials-check-early-stopping-state/#required-scalar-argument","text":"<name> (string) Required. The trial name.","title":"Required Scalar Argument"},{"location":"projects_locations-studies-trials-check-early-stopping-state/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__CheckTrialEarlyStoppingStateRequest: can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.","title":"Required Request Value"},{"location":"projects_locations-studies-trials-check-early-stopping-state/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"projects_locations-studies-trials-check-early-stopping-state/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_locations-studies-trials-check-early-stopping-state/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_locations-studies-trials-complete/","text":"Marks a trial as complete. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-trials-complete ... Required Scalar Argument <name> (string) Required. The trial name.metat Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__CompleteTrialRequest: final-measurement: elapsed-time: string step-count: int64 infeasible-reason: string trial-infeasible: boolean can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r .final-measurement elapsed-time=at Output only. Time that the trial has been running at the point of this measurement. step-count=-53 The number of steps a machine learning model has been trained for. Must be non-negative. .. infeasible-reason=vero Optional. A human readable reason why the trial was infeasible. This should only be provided if trial_infeasible is true. trial-infeasible=true Optional. True if the trial cannot be run with the given Parameter, and final_measurement will be ignored. About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Locations Studies Trials Complete"},{"location":"projects_locations-studies-trials-complete/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-trials-complete ...","title":"Scopes"},{"location":"projects_locations-studies-trials-complete/#required-scalar-argument","text":"<name> (string) Required. The trial name.metat","title":"Required Scalar Argument"},{"location":"projects_locations-studies-trials-complete/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__CompleteTrialRequest: final-measurement: elapsed-time: string step-count: int64 infeasible-reason: string trial-infeasible: boolean can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r .final-measurement elapsed-time=at Output only. Time that the trial has been running at the point of this measurement. step-count=-53 The number of steps a machine learning model has been trained for. Must be non-negative. .. infeasible-reason=vero Optional. A human readable reason why the trial was infeasible. This should only be provided if trial_infeasible is true. trial-infeasible=true Optional. True if the trial cannot be run with the given Parameter, and final_measurement will be ignored.","title":"Required Request Value"},{"location":"projects_locations-studies-trials-complete/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"projects_locations-studies-trials-complete/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_locations-studies-trials-complete/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_locations-studies-trials-create/","text":"Adds a user provided trial to a study. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-trials-create ... Required Scalar Argument <parent> (string) Required. The name of the study that the trial belongs to. Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__Trial: client-id: string end-time: string final-measurement: elapsed-time: string step-count: int64 infeasible-reason: string name: string start-time: string state: string trial-infeasible: boolean can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r . client-id=ut Output only. The identifier of the client that originally requested this trial. end-time=rebum. Output only. Time at which the trial's status changed to COMPLETED. final-measurement elapsed-time=duo Output only. Time that the trial has been running at the point of this measurement. step-count=-63 The number of steps a machine learning model has been trained for. Must be non-negative. .. infeasible-reason=sadipscing Output only. A human readable string describing why the trial is infeasible. This should only be set if trial_infeasible is true. name=tempor Output only. Name of the trial assigned by the service. start-time=sea Output only. Time at which the trial was started. state=et The detailed state of a trial. trial-infeasible=true Output only. If true, the parameters in this trial are not attempted again. About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Locations Studies Trials Create"},{"location":"projects_locations-studies-trials-create/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-trials-create ...","title":"Scopes"},{"location":"projects_locations-studies-trials-create/#required-scalar-argument","text":"<parent> (string) Required. The name of the study that the trial belongs to.","title":"Required Scalar Argument"},{"location":"projects_locations-studies-trials-create/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__Trial: client-id: string end-time: string final-measurement: elapsed-time: string step-count: int64 infeasible-reason: string name: string start-time: string state: string trial-infeasible: boolean can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r . client-id=ut Output only. The identifier of the client that originally requested this trial. end-time=rebum. Output only. Time at which the trial's status changed to COMPLETED. final-measurement elapsed-time=duo Output only. Time that the trial has been running at the point of this measurement. step-count=-63 The number of steps a machine learning model has been trained for. Must be non-negative. .. infeasible-reason=sadipscing Output only. A human readable string describing why the trial is infeasible. This should only be set if trial_infeasible is true. name=tempor Output only. Name of the trial assigned by the service. start-time=sea Output only. Time at which the trial was started. state=et The detailed state of a trial. trial-infeasible=true Output only. If true, the parameters in this trial are not attempted again.","title":"Required Request Value"},{"location":"projects_locations-studies-trials-create/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"projects_locations-studies-trials-create/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_locations-studies-trials-create/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_locations-studies-trials-delete/","text":"Deletes a trial. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-trials-delete ... Required Scalar Argument <name> (string) Required. The trial name. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Locations Studies Trials Delete"},{"location":"projects_locations-studies-trials-delete/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-trials-delete ...","title":"Scopes"},{"location":"projects_locations-studies-trials-delete/#required-scalar-argument","text":"<name> (string) Required. The trial name.","title":"Required Scalar Argument"},{"location":"projects_locations-studies-trials-delete/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_locations-studies-trials-delete/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_locations-studies-trials-get/","text":"Gets a trial. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-trials-get ... Required Scalar Argument <name> (string) Required. The trial name. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Locations Studies Trials Get"},{"location":"projects_locations-studies-trials-get/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-trials-get ...","title":"Scopes"},{"location":"projects_locations-studies-trials-get/#required-scalar-argument","text":"<name> (string) Required. The trial name.","title":"Required Scalar Argument"},{"location":"projects_locations-studies-trials-get/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_locations-studies-trials-get/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_locations-studies-trials-list-optimal-trials/","text":"Lists the pareto-optimal trials for multi-objective study or the optimal trials for single-objective study. The definition of pareto-optimal can be checked in wiki page. https://en.wikipedia.org/wiki/Pareto_efficiency Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-trials-list-optimal-trials ... Required Scalar Argument <parent> (string) Required. The name of the study that the pareto-optimal trial belongs to. Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__ListOptimalTrialsRequest: can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Locations Studies Trials List Optimal Trials"},{"location":"projects_locations-studies-trials-list-optimal-trials/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-trials-list-optimal-trials ...","title":"Scopes"},{"location":"projects_locations-studies-trials-list-optimal-trials/#required-scalar-argument","text":"<parent> (string) Required. The name of the study that the pareto-optimal trial belongs to.","title":"Required Scalar Argument"},{"location":"projects_locations-studies-trials-list-optimal-trials/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__ListOptimalTrialsRequest: can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.","title":"Required Request Value"},{"location":"projects_locations-studies-trials-list-optimal-trials/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"projects_locations-studies-trials-list-optimal-trials/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_locations-studies-trials-list-optimal-trials/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_locations-studies-trials-list/","text":"Lists the trials associated with a study. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-trials-list ... Required Scalar Argument <parent> (string) Required. The name of the study that the trial belongs to. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Locations Studies Trials List"},{"location":"projects_locations-studies-trials-list/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-trials-list ...","title":"Scopes"},{"location":"projects_locations-studies-trials-list/#required-scalar-argument","text":"<parent> (string) Required. The name of the study that the trial belongs to.","title":"Required Scalar Argument"},{"location":"projects_locations-studies-trials-list/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_locations-studies-trials-list/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_locations-studies-trials-stop/","text":"Stops a trial. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-trials-stop ... Required Scalar Argument <name> (string) Required. The trial name. Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__StopTrialRequest: can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Locations Studies Trials Stop"},{"location":"projects_locations-studies-trials-stop/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-trials-stop ...","title":"Scopes"},{"location":"projects_locations-studies-trials-stop/#required-scalar-argument","text":"<name> (string) Required. The trial name.","title":"Required Scalar Argument"},{"location":"projects_locations-studies-trials-stop/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__StopTrialRequest: can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.","title":"Required Request Value"},{"location":"projects_locations-studies-trials-stop/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"projects_locations-studies-trials-stop/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_locations-studies-trials-stop/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_locations-studies-trials-suggest/","text":"Adds one or more trials to a study, with parameter values suggested by AI Platform Vizier. Returns a long-running operation associated with the generation of trial suggestions. When this long-running operation succeeds, it will contain a SuggestTrialsResponse. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-trials-suggest ... Required Scalar Argument <parent> (string) Required. The name of the study that the trial belongs to. Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__SuggestTrialsRequest: client-id: string suggestion-count: integer can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r . client-id=magna Required. The identifier of the client that is requesting the suggestion. If multiple SuggestTrialsRequests have the same client_id , the service will return the identical suggested trial if the trial is pending, and provide a new trial if the last suggested trial was completed. suggestion-count=42 Required. The number of suggestions requested. About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Locations Studies Trials Suggest"},{"location":"projects_locations-studies-trials-suggest/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects locations-studies-trials-suggest ...","title":"Scopes"},{"location":"projects_locations-studies-trials-suggest/#required-scalar-argument","text":"<parent> (string) Required. The name of the study that the trial belongs to.","title":"Required Scalar Argument"},{"location":"projects_locations-studies-trials-suggest/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__SuggestTrialsRequest: client-id: string suggestion-count: integer can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r . client-id=magna Required. The identifier of the client that is requesting the suggestion. If multiple SuggestTrialsRequests have the same client_id , the service will return the identical suggested trial if the trial is pending, and provide a new trial if the last suggested trial was completed. suggestion-count=42 Required. The number of suggestions requested.","title":"Required Request Value"},{"location":"projects_locations-studies-trials-suggest/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"projects_locations-studies-trials-suggest/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_locations-studies-trials-suggest/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_models-create/","text":"Creates a model which will later contain one or more versions. You must add at least one version before you can request predictions from the model. Add versions by calling projects.models.versions.create. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-create ... Required Scalar Argument <parent> (string) Required. The project name. Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__Model: default-version: accelerator-config: count: string type: string auto-scaling: max-nodes: integer min-nodes: integer container: args: [string] command: [string] image: string create-time: string deployment-uri: string description: string error-message: string etag: string explanation-config: integrated-gradients-attribution: num-integral-steps: integer sampled-shapley-attribution: num-paths: integer xrai-attribution: num-integral-steps: integer framework: string is-default: boolean labels: { string: string } last-migration-model-id: string last-migration-time: string last-use-time: string machine-type: string manual-scaling: nodes: integer name: string package-uris: [string] prediction-class: string python-version: string request-logging-config: bigquery-table-name: string sampling-percentage: number routes: health: string predict: string runtime-version: string service-account: string state: string description: string etag: string labels: { string: string } name: string online-prediction-console-logging: boolean online-prediction-logging: boolean regions: [string] can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r .default-version.accelerator-config count=rebum. The number of accelerators to attach to each machine running the job. type=at The type of accelerator to use. ..auto-scaling max-nodes=13 The maximum number of nodes to scale this model under load. The actual value will depend on resource quota and availability. min-nodes=87 Optional. The minimum number of nodes to allocate for this model. These nodes are always up, starting from the time the model is deployed. Therefore, the cost of operating this model will be at least rate * min_nodes * number of hours since last billing cycle, where rate is the cost per node-hour as documented in the pricing guide , even if no predictions are performed. There is additional cost for each prediction performed. Unlike manual scaling, if the load gets too heavy for the nodes that are up, the service will automatically add nodes to handle the increased load as well as scale back as traffic drops, always maintaining at least min_nodes . You will be charged for the time in which additional nodes are used. If min_nodes is not specified and AutoScaling is used with a legacy (MLS1) machine type , min_nodes defaults to 0, in which case, when traffic to a model stops (and after a cool-down period), nodes will be shut down and no charges will be incurred until traffic to the model resumes. If min_nodes is not specified and AutoScaling is used with a Compute Engine (N1) machine type , min_nodes defaults to 1. min_nodes must be at least 1 for use with a Compute Engine machine type. You can set min_nodes when creating the model version, and you can also update min_nodes for an existing version: update_body.json: { 'autoScaling': { 'minNodes': 5 } } HTTP request: PATCH https://ml.googleapis.com/v1/{name=projects/ /models/ /versions/*}?update_mask=autoScaling.minNodes -d @./update_body.json ..container args=stet Immutable. Specifies arguments for the command that runs when the container starts. This overrides the container's CMD . Specify this field as an array of executable and arguments, similar to a Docker CMD 's \"default parameters\" form. If you don't specify this field but do specify the command field, then the command from the command field runs without any additional arguments. See the Kubernetes documentation about how the command and args fields interact with a container's ENTRYPOINT and CMD . If you don't specify this field and don't specify the commmand field, then the container's ENTRYPOINT and CMD determine what runs based on their default behavior. See the Docker documentation about how CMD and ENTRYPOINT interact . In this field, you can reference environment variables set by AI Platform Prediction and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with $$ ; for example: $$(VARIABLE_NAME) This field corresponds to the args field of the Kubernetes Containers v1 core API . Each invocation of this argument appends the given value to the array. command=aliquyam Immutable. Specifies the command that runs when the container starts. This overrides the container's ENTRYPOINT . Specify this field as an array of executable and arguments, similar to a Docker ENTRYPOINT 's \"exec\" form, not its \"shell\" form. If you do not specify this field, then the container's ENTRYPOINT runs, in conjunction with the args field or the container's CMD , if either exists. If this field is not specified and the container does not have an ENTRYPOINT , then refer to the Docker documentation about how CMD and ENTRYPOINT interact . If you specify this field, then you can also specify the args field to provide additional arguments for this command. However, if you specify this field, then the container's CMD is ignored. See the Kubernetes documentation about how the command and args fields interact with a container's ENTRYPOINT and CMD . In this field, you can reference environment variables set by AI Platform Prediction and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with $$ ; for example: $$(VARIABLE_NAME) This field corresponds to the command field of the Kubernetes Containers v1 core API . Each invocation of this argument appends the given value to the array. image=ut URI of the Docker image to be used as the custom container for serving predictions. This URI must identify an image in Artifact Registry and begin with the hostname {REGION}-docker.pkg.dev , where {REGION} is replaced by the region that matches AI Platform Prediction regional endpoint that you are using. For example, if you are using the us-central1-ml.googleapis.com endpoint, then this URI must begin with us-central1-docker.pkg.dev . To use a custom container, the AI Platform Google-managed service account must have permission to pull (read) the Docker image at this URI. The AI Platform Google-managed service account has the following format: service-{PROJECT_NUMBER}@cloud-ml.google.com.iam.gserviceaccount.com {PROJECT_NUMBER} is replaced by your Google Cloud project number. By default, this service account has necessary permissions to pull an Artifact Registry image in the same Google Cloud project where you are using AI Platform Prediction. In this case, no configuration is necessary. If you want to use an image from a different Google Cloud project, learn how to grant the Artifact Registry Reader (roles/artifactregistry.reader) role for a repository to your projet's AI Platform Google-managed service account. To learn about the requirements for the Docker image itself, read Custom container requirements . .. create-time=sit Output only. The time the version was created. deployment-uri=vero The Cloud Storage URI of a directory containing trained model artifacts to be used to create the model version. See the guide to deploying models for more information. The total number of files under this directory must not exceed 1000. During projects.models.versions.create, AI Platform Prediction copies all files from the specified directory to a location managed by the service. From then on, AI Platform Prediction uses these copies of the model artifacts to serve predictions, not the original files in Cloud Storage, so this location is useful only as a historical record. If you specify container, then this field is optional. Otherwise, it is required. Learn how to use this field with a custom container . description=rebum. Optional. The description specified for the version when it was created. error-message=dolores Output only. The details of a failure or a cancellation. etag=consetetur etag is used for optimistic concurrency control as a way to help prevent simultaneous updates of a model from overwriting each other. It is strongly suggested that systems make use of the etag in the read-modify-write cycle to perform model updates in order to avoid race conditions: An etag is returned in the response to GetVersion , and systems are expected to put that etag in the request to UpdateVersion to ensure that their change will be applied to the model as intended. explanation-config.integrated-gradients-attribution num-integral-steps=82 Number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. ..sampled-shapley-attribution num-paths=71 The number of feature permutations to consider when approximating the Shapley values. ..xrai-attribution num-integral-steps=63 Number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. ... framework=clita Optional. The machine learning framework AI Platform uses to train this version of the model. Valid values are TENSORFLOW , SCIKIT_LEARN , XGBOOST . If you do not specify a framework, AI Platform will analyze files in the deployment_uri to determine a framework. If you choose SCIKIT_LEARN or XGBOOST , you must also set the runtime version of the model to 1.4 or greater. Do not specify a framework if you're deploying a custom prediction routine or if you're using a custom container . is-default=false Output only. If true, this version will be used to handle prediction requests that do not specify a version. You can change the default version by calling projects.methods.versions.setDefault. labels=key=aliquyam Optional. One or more labels that you can add, to organize your model versions. Each label is a key-value pair, where both the key and the value are arbitrary strings that you supply. For more information, see the documentation on using labels. Note that this field is not updatable for mls1* models. the value will be associated with the given key last-migration-model-id=magna Output only. The AI Platform (Unified) Model ID for the last model migration . last-migration-time=diam Output only. The last time this version was successfully migrated to AI Platform (Unified) . last-use-time=nonumy Output only. The time the version was last used for prediction. machine-type=et Optional. The type of machine on which to serve the model. Currently only applies to online prediction service. To learn about valid values for this field, read Choosing a machine type for online prediction . If this field is not specified and you are using a regional endpoint , then the machine type defaults to n1-standard-2 . If this field is not specified and you are using the global endpoint ( ml.googleapis.com ), then the machine type defaults to mls1-c1-m2 . manual-scaling nodes=93 The number of nodes to allocate for this model. These nodes are always up, starting from the time the model is deployed, so the cost of operating this model will be proportional to nodes * number of hours since last billing cycle plus the cost for each prediction performed. .. name=accusam Required. The name specified for the version when it was created. The version name must be unique within the model it is created in. package-uris=tempor Optional. Cloud Storage paths ( gs://\u2026 ) of packages for custom prediction routines or scikit-learn pipelines with custom code . For a custom prediction routine, one of these packages must contain your Predictor class (see predictionClass ). Additionally, include any dependencies used by your Predictor or scikit-learn pipeline uses that are not already included in your selected runtime version . If you specify this field, you must also set runtimeVersion to 1.4 or greater. Each invocation of this argument appends the given value to the array. prediction-class=sed Optional. The fully qualified name (module_name.class_name) of a class that implements the Predictor interface described in this reference field. The module containing this class should be included in a package provided to the packageUris field . Specify this field if and only if you are deploying a custom prediction routine (beta) . If you specify this field, you must set runtimeVersion to 1.4 or greater and you must set machineType to a legacy (MLS1) machine type . The following code sample provides the Predictor interface: class Predictor(object): \"\"\"Interface for constructing custom predictors.\"\"\" def predict(self, instances, kwargs): \"\"\"Performs custom prediction. Instances are the decoded values from the request. They have already been deserialized from JSON. Args: instances: A list of prediction input instances. kwargs: A dictionary of keyword args provided as additional fields on the predict request body. Returns: A list of outputs containing the prediction results. This list must be JSON serializable. \"\"\" raise NotImplementedError() @classmethod def from_path(cls, model_dir): \"\"\"Creates an instance of Predictor using the given path. Loading of the predictor should be done in this method. Args: model_dir: The local directory that contains the exported model file along with any additional files uploaded when creating the version resource. Returns: An instance implementing this Predictor class. \"\"\" raise NotImplementedError() Learn more about the Predictor interface and custom prediction routines . python-version=est Required. The version of Python used in prediction. The following Python versions are available: * Python '3.7' is available when runtime_version is set to '1.15' or later. * Python '3.5' is available when runtime_version is set to a version from '1.4' to '1.14'. * Python '2.7' is available when runtime_version is set to '1.15' or earlier. Read more about the Python versions available for each runtime version . request-logging-config bigquery-table-name=takimata Required. Fully qualified BigQuery table name in the following format: \" project_id.dataset_name.table_name\" The specified table must already exist, and the \"Cloud ML Service Agent\" for your project must have permission to write to it. The table must have the following schema : Field nameType Mode model STRING REQUIRED model_version STRING REQUIRED time TIMESTAMP REQUIRED raw_data STRING REQUIRED raw_prediction STRING NULLABLE groundtruth STRING NULLABLE sampling-percentage=0.02085600923949349 Percentage of requests to be logged, expressed as a fraction from 0 to 1. For example, if you want to log 10% of requests, enter 0.1 . The sampling window is the lifetime of the model version. Defaults to 0. ..routes health=at HTTP path on the container to send health checkss to. AI Platform Prediction intermittently sends GET requests to this path on the container's IP address and port to check that the container is healthy. Read more about health checks . For example, if you set this field to /bar , then AI Platform Prediction intermittently sends a GET request to the /bar path on the port of your container specified by the first value of Version.container.ports. If you don't specify this field, it defaults to the following value: /v1/models/ MODEL/versions/VERSION The placeholders in this value are replaced as follows: * MODEL: The name of the parent Model. This does not include the \"projects/PROJECT_ID/models/\" prefix that the API returns in output; it is the bare model name, as provided to projects.models.create. * VERSION: The name of the model version. This does not include the \"projects/PROJECT_ID /models/MODEL/versions/\" prefix that the API returns in output; it is the bare version name, as provided to projects.models.versions.create. predict=erat HTTP path on the container to send prediction requests to. AI Platform Prediction forwards requests sent using projects.predict to this path on the container's IP address and port. AI Platform Prediction then returns the container's response in the API response. For example, if you set this field to /foo , then when AI Platform Prediction receives a prediction request, it forwards the request body in a POST request to the /foo path on the port of your container specified by the first value of Version.container.ports. If you don't specify this field, it defaults to the following value: /v1/models/MODEL/versions/VERSION:predict The placeholders in this value are replaced as follows: * MODEL: The name of the parent Model. This does not include the \"projects/PROJECT_ID/models/\" prefix that the API returns in output; it is the bare model name, as provided to projects.models.create. * VERSION: The name of the model version. This does not include the \"projects/PROJECT_ID/models/MODEL/versions/\" prefix that the API returns in output; it is the bare version name, as provided to projects.models.versions.create. .. runtime-version=justo Required. The AI Platform runtime version to use for this deployment. For more information, see the runtime version list and how to manage runtime versions . service-account=ipsum Optional. Specifies the service account for resource access control. If you specify this field, then you must also specify either the containerSpec or the predictionClass field. Learn more about using a custom service account . state=accusam Output only. The state of a version. .. description=dolores Optional. The description specified for the model when it was created. etag=consetetur etag is used for optimistic concurrency control as a way to help prevent simultaneous updates of a model from overwriting each other. It is strongly suggested that systems make use of the etag in the read-modify-write cycle to perform model updates in order to avoid race conditions: An etag is returned in the response to GetModel , and systems are expected to put that etag in the request to UpdateModel to ensure that their change will be applied to the model as intended. labels=key=no Optional. One or more labels that you can add, to organize your models. Each label is a key-value pair, where both the key and the value are arbitrary strings that you supply. For more information, see the documentation on using labels. Note that this field is not updatable for mls1* models. the value will be associated with the given key name=justo Required. The name specified for the model when it was created. The model name must be unique within the project it is created in. online-prediction-console-logging=true Optional. If true, online prediction nodes send stderr and stdout streams to Cloud Logging. These can be more verbose than the standard access logs (see onlinePredictionLogging ) and can incur higher cost. However, they are helpful for debugging. Note that logs may incur a cost , especially if your project receives prediction requests at a high QPS. Estimate your costs before enabling this option. Default is false. online-prediction-logging=true Optional. If true, online prediction access logs are sent to Cloud Logging. These logs are like standard server access logs, containing information like timestamp and latency for each request. Note that logs may incur a cost , especially if your project receives prediction requests at a high queries per second rate (QPS). Estimate your costs before enabling this option. Default is false. regions=sea Optional. The list of regions where the model is going to be deployed. Only one region per model is supported. Defaults to 'us-central1' if nothing is set. See the available regions for AI Platform services. Note: * No matter where a model is deployed, it can always be accessed by users from anywhere, both for online and batch prediction. * The region for a batch prediction job is set by the region field when submitting the batch prediction job and does not take its value from this field. Each invocation of this argument appends the given value to the array. About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Models Create"},{"location":"projects_models-create/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-create ...","title":"Scopes"},{"location":"projects_models-create/#required-scalar-argument","text":"<parent> (string) Required. The project name.","title":"Required Scalar Argument"},{"location":"projects_models-create/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__Model: default-version: accelerator-config: count: string type: string auto-scaling: max-nodes: integer min-nodes: integer container: args: [string] command: [string] image: string create-time: string deployment-uri: string description: string error-message: string etag: string explanation-config: integrated-gradients-attribution: num-integral-steps: integer sampled-shapley-attribution: num-paths: integer xrai-attribution: num-integral-steps: integer framework: string is-default: boolean labels: { string: string } last-migration-model-id: string last-migration-time: string last-use-time: string machine-type: string manual-scaling: nodes: integer name: string package-uris: [string] prediction-class: string python-version: string request-logging-config: bigquery-table-name: string sampling-percentage: number routes: health: string predict: string runtime-version: string service-account: string state: string description: string etag: string labels: { string: string } name: string online-prediction-console-logging: boolean online-prediction-logging: boolean regions: [string] can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r .default-version.accelerator-config count=rebum. The number of accelerators to attach to each machine running the job. type=at The type of accelerator to use. ..auto-scaling max-nodes=13 The maximum number of nodes to scale this model under load. The actual value will depend on resource quota and availability. min-nodes=87 Optional. The minimum number of nodes to allocate for this model. These nodes are always up, starting from the time the model is deployed. Therefore, the cost of operating this model will be at least rate * min_nodes * number of hours since last billing cycle, where rate is the cost per node-hour as documented in the pricing guide , even if no predictions are performed. There is additional cost for each prediction performed. Unlike manual scaling, if the load gets too heavy for the nodes that are up, the service will automatically add nodes to handle the increased load as well as scale back as traffic drops, always maintaining at least min_nodes . You will be charged for the time in which additional nodes are used. If min_nodes is not specified and AutoScaling is used with a legacy (MLS1) machine type , min_nodes defaults to 0, in which case, when traffic to a model stops (and after a cool-down period), nodes will be shut down and no charges will be incurred until traffic to the model resumes. If min_nodes is not specified and AutoScaling is used with a Compute Engine (N1) machine type , min_nodes defaults to 1. min_nodes must be at least 1 for use with a Compute Engine machine type. You can set min_nodes when creating the model version, and you can also update min_nodes for an existing version: update_body.json: { 'autoScaling': { 'minNodes': 5 } } HTTP request: PATCH https://ml.googleapis.com/v1/{name=projects/ /models/ /versions/*}?update_mask=autoScaling.minNodes -d @./update_body.json ..container args=stet Immutable. Specifies arguments for the command that runs when the container starts. This overrides the container's CMD . Specify this field as an array of executable and arguments, similar to a Docker CMD 's \"default parameters\" form. If you don't specify this field but do specify the command field, then the command from the command field runs without any additional arguments. See the Kubernetes documentation about how the command and args fields interact with a container's ENTRYPOINT and CMD . If you don't specify this field and don't specify the commmand field, then the container's ENTRYPOINT and CMD determine what runs based on their default behavior. See the Docker documentation about how CMD and ENTRYPOINT interact . In this field, you can reference environment variables set by AI Platform Prediction and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with $$ ; for example: $$(VARIABLE_NAME) This field corresponds to the args field of the Kubernetes Containers v1 core API . Each invocation of this argument appends the given value to the array. command=aliquyam Immutable. Specifies the command that runs when the container starts. This overrides the container's ENTRYPOINT . Specify this field as an array of executable and arguments, similar to a Docker ENTRYPOINT 's \"exec\" form, not its \"shell\" form. If you do not specify this field, then the container's ENTRYPOINT runs, in conjunction with the args field or the container's CMD , if either exists. If this field is not specified and the container does not have an ENTRYPOINT , then refer to the Docker documentation about how CMD and ENTRYPOINT interact . If you specify this field, then you can also specify the args field to provide additional arguments for this command. However, if you specify this field, then the container's CMD is ignored. See the Kubernetes documentation about how the command and args fields interact with a container's ENTRYPOINT and CMD . In this field, you can reference environment variables set by AI Platform Prediction and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with $$ ; for example: $$(VARIABLE_NAME) This field corresponds to the command field of the Kubernetes Containers v1 core API . Each invocation of this argument appends the given value to the array. image=ut URI of the Docker image to be used as the custom container for serving predictions. This URI must identify an image in Artifact Registry and begin with the hostname {REGION}-docker.pkg.dev , where {REGION} is replaced by the region that matches AI Platform Prediction regional endpoint that you are using. For example, if you are using the us-central1-ml.googleapis.com endpoint, then this URI must begin with us-central1-docker.pkg.dev . To use a custom container, the AI Platform Google-managed service account must have permission to pull (read) the Docker image at this URI. The AI Platform Google-managed service account has the following format: service-{PROJECT_NUMBER}@cloud-ml.google.com.iam.gserviceaccount.com {PROJECT_NUMBER} is replaced by your Google Cloud project number. By default, this service account has necessary permissions to pull an Artifact Registry image in the same Google Cloud project where you are using AI Platform Prediction. In this case, no configuration is necessary. If you want to use an image from a different Google Cloud project, learn how to grant the Artifact Registry Reader (roles/artifactregistry.reader) role for a repository to your projet's AI Platform Google-managed service account. To learn about the requirements for the Docker image itself, read Custom container requirements . .. create-time=sit Output only. The time the version was created. deployment-uri=vero The Cloud Storage URI of a directory containing trained model artifacts to be used to create the model version. See the guide to deploying models for more information. The total number of files under this directory must not exceed 1000. During projects.models.versions.create, AI Platform Prediction copies all files from the specified directory to a location managed by the service. From then on, AI Platform Prediction uses these copies of the model artifacts to serve predictions, not the original files in Cloud Storage, so this location is useful only as a historical record. If you specify container, then this field is optional. Otherwise, it is required. Learn how to use this field with a custom container . description=rebum. Optional. The description specified for the version when it was created. error-message=dolores Output only. The details of a failure or a cancellation. etag=consetetur etag is used for optimistic concurrency control as a way to help prevent simultaneous updates of a model from overwriting each other. It is strongly suggested that systems make use of the etag in the read-modify-write cycle to perform model updates in order to avoid race conditions: An etag is returned in the response to GetVersion , and systems are expected to put that etag in the request to UpdateVersion to ensure that their change will be applied to the model as intended. explanation-config.integrated-gradients-attribution num-integral-steps=82 Number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. ..sampled-shapley-attribution num-paths=71 The number of feature permutations to consider when approximating the Shapley values. ..xrai-attribution num-integral-steps=63 Number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. ... framework=clita Optional. The machine learning framework AI Platform uses to train this version of the model. Valid values are TENSORFLOW , SCIKIT_LEARN , XGBOOST . If you do not specify a framework, AI Platform will analyze files in the deployment_uri to determine a framework. If you choose SCIKIT_LEARN or XGBOOST , you must also set the runtime version of the model to 1.4 or greater. Do not specify a framework if you're deploying a custom prediction routine or if you're using a custom container . is-default=false Output only. If true, this version will be used to handle prediction requests that do not specify a version. You can change the default version by calling projects.methods.versions.setDefault. labels=key=aliquyam Optional. One or more labels that you can add, to organize your model versions. Each label is a key-value pair, where both the key and the value are arbitrary strings that you supply. For more information, see the documentation on using labels. Note that this field is not updatable for mls1* models. the value will be associated with the given key last-migration-model-id=magna Output only. The AI Platform (Unified) Model ID for the last model migration . last-migration-time=diam Output only. The last time this version was successfully migrated to AI Platform (Unified) . last-use-time=nonumy Output only. The time the version was last used for prediction. machine-type=et Optional. The type of machine on which to serve the model. Currently only applies to online prediction service. To learn about valid values for this field, read Choosing a machine type for online prediction . If this field is not specified and you are using a regional endpoint , then the machine type defaults to n1-standard-2 . If this field is not specified and you are using the global endpoint ( ml.googleapis.com ), then the machine type defaults to mls1-c1-m2 . manual-scaling nodes=93 The number of nodes to allocate for this model. These nodes are always up, starting from the time the model is deployed, so the cost of operating this model will be proportional to nodes * number of hours since last billing cycle plus the cost for each prediction performed. .. name=accusam Required. The name specified for the version when it was created. The version name must be unique within the model it is created in. package-uris=tempor Optional. Cloud Storage paths ( gs://\u2026 ) of packages for custom prediction routines or scikit-learn pipelines with custom code . For a custom prediction routine, one of these packages must contain your Predictor class (see predictionClass ). Additionally, include any dependencies used by your Predictor or scikit-learn pipeline uses that are not already included in your selected runtime version . If you specify this field, you must also set runtimeVersion to 1.4 or greater. Each invocation of this argument appends the given value to the array. prediction-class=sed Optional. The fully qualified name (module_name.class_name) of a class that implements the Predictor interface described in this reference field. The module containing this class should be included in a package provided to the packageUris field . Specify this field if and only if you are deploying a custom prediction routine (beta) . If you specify this field, you must set runtimeVersion to 1.4 or greater and you must set machineType to a legacy (MLS1) machine type . The following code sample provides the Predictor interface: class Predictor(object): \"\"\"Interface for constructing custom predictors.\"\"\" def predict(self, instances, kwargs): \"\"\"Performs custom prediction. Instances are the decoded values from the request. They have already been deserialized from JSON. Args: instances: A list of prediction input instances. kwargs: A dictionary of keyword args provided as additional fields on the predict request body. Returns: A list of outputs containing the prediction results. This list must be JSON serializable. \"\"\" raise NotImplementedError() @classmethod def from_path(cls, model_dir): \"\"\"Creates an instance of Predictor using the given path. Loading of the predictor should be done in this method. Args: model_dir: The local directory that contains the exported model file along with any additional files uploaded when creating the version resource. Returns: An instance implementing this Predictor class. \"\"\" raise NotImplementedError() Learn more about the Predictor interface and custom prediction routines . python-version=est Required. The version of Python used in prediction. The following Python versions are available: * Python '3.7' is available when runtime_version is set to '1.15' or later. * Python '3.5' is available when runtime_version is set to a version from '1.4' to '1.14'. * Python '2.7' is available when runtime_version is set to '1.15' or earlier. Read more about the Python versions available for each runtime version . request-logging-config bigquery-table-name=takimata Required. Fully qualified BigQuery table name in the following format: \" project_id.dataset_name.table_name\" The specified table must already exist, and the \"Cloud ML Service Agent\" for your project must have permission to write to it. The table must have the following schema : Field nameType Mode model STRING REQUIRED model_version STRING REQUIRED time TIMESTAMP REQUIRED raw_data STRING REQUIRED raw_prediction STRING NULLABLE groundtruth STRING NULLABLE sampling-percentage=0.02085600923949349 Percentage of requests to be logged, expressed as a fraction from 0 to 1. For example, if you want to log 10% of requests, enter 0.1 . The sampling window is the lifetime of the model version. Defaults to 0. ..routes health=at HTTP path on the container to send health checkss to. AI Platform Prediction intermittently sends GET requests to this path on the container's IP address and port to check that the container is healthy. Read more about health checks . For example, if you set this field to /bar , then AI Platform Prediction intermittently sends a GET request to the /bar path on the port of your container specified by the first value of Version.container.ports. If you don't specify this field, it defaults to the following value: /v1/models/ MODEL/versions/VERSION The placeholders in this value are replaced as follows: * MODEL: The name of the parent Model. This does not include the \"projects/PROJECT_ID/models/\" prefix that the API returns in output; it is the bare model name, as provided to projects.models.create. * VERSION: The name of the model version. This does not include the \"projects/PROJECT_ID /models/MODEL/versions/\" prefix that the API returns in output; it is the bare version name, as provided to projects.models.versions.create. predict=erat HTTP path on the container to send prediction requests to. AI Platform Prediction forwards requests sent using projects.predict to this path on the container's IP address and port. AI Platform Prediction then returns the container's response in the API response. For example, if you set this field to /foo , then when AI Platform Prediction receives a prediction request, it forwards the request body in a POST request to the /foo path on the port of your container specified by the first value of Version.container.ports. If you don't specify this field, it defaults to the following value: /v1/models/MODEL/versions/VERSION:predict The placeholders in this value are replaced as follows: * MODEL: The name of the parent Model. This does not include the \"projects/PROJECT_ID/models/\" prefix that the API returns in output; it is the bare model name, as provided to projects.models.create. * VERSION: The name of the model version. This does not include the \"projects/PROJECT_ID/models/MODEL/versions/\" prefix that the API returns in output; it is the bare version name, as provided to projects.models.versions.create. .. runtime-version=justo Required. The AI Platform runtime version to use for this deployment. For more information, see the runtime version list and how to manage runtime versions . service-account=ipsum Optional. Specifies the service account for resource access control. If you specify this field, then you must also specify either the containerSpec or the predictionClass field. Learn more about using a custom service account . state=accusam Output only. The state of a version. .. description=dolores Optional. The description specified for the model when it was created. etag=consetetur etag is used for optimistic concurrency control as a way to help prevent simultaneous updates of a model from overwriting each other. It is strongly suggested that systems make use of the etag in the read-modify-write cycle to perform model updates in order to avoid race conditions: An etag is returned in the response to GetModel , and systems are expected to put that etag in the request to UpdateModel to ensure that their change will be applied to the model as intended. labels=key=no Optional. One or more labels that you can add, to organize your models. Each label is a key-value pair, where both the key and the value are arbitrary strings that you supply. For more information, see the documentation on using labels. Note that this field is not updatable for mls1* models. the value will be associated with the given key name=justo Required. The name specified for the model when it was created. The model name must be unique within the project it is created in. online-prediction-console-logging=true Optional. If true, online prediction nodes send stderr and stdout streams to Cloud Logging. These can be more verbose than the standard access logs (see onlinePredictionLogging ) and can incur higher cost. However, they are helpful for debugging. Note that logs may incur a cost , especially if your project receives prediction requests at a high QPS. Estimate your costs before enabling this option. Default is false. online-prediction-logging=true Optional. If true, online prediction access logs are sent to Cloud Logging. These logs are like standard server access logs, containing information like timestamp and latency for each request. Note that logs may incur a cost , especially if your project receives prediction requests at a high queries per second rate (QPS). Estimate your costs before enabling this option. Default is false. regions=sea Optional. The list of regions where the model is going to be deployed. Only one region per model is supported. Defaults to 'us-central1' if nothing is set. See the available regions for AI Platform services. Note: * No matter where a model is deployed, it can always be accessed by users from anywhere, both for online and batch prediction. * The region for a batch prediction job is set by the region field when submitting the batch prediction job and does not take its value from this field. Each invocation of this argument appends the given value to the array.","title":"Required Request Value"},{"location":"projects_models-create/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"projects_models-create/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_models-create/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_models-delete/","text":"Deletes a model. You can only delete a model if there are no versions in it. You can delete versions by calling projects.models.versions.delete. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-delete ... Required Scalar Argument <name> (string) Required. The name of the model. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Models Delete"},{"location":"projects_models-delete/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-delete ...","title":"Scopes"},{"location":"projects_models-delete/#required-scalar-argument","text":"<name> (string) Required. The name of the model.","title":"Required Scalar Argument"},{"location":"projects_models-delete/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_models-delete/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_models-get-iam-policy/","text":"Gets the access control policy for a resource. Returns an empty policy if the resource exists and does not have a policy set. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-get-iam-policy ... Required Scalar Argument <resource> (string) REQUIRED: The resource for which the policy is being requested. See Resource names for the appropriate value for this field. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional Method Properties You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p options-requested-policy-version=integer Optional. The maximum policy version that will be used to format the policy. Valid values are 0, 1, and 3. Requests specifying an invalid value will be rejected. Requests for policies with any conditional role bindings must specify version 3. Policies with no conditional role bindings may specify any valid value or leave the field unset. The policy in the response might use the policy version that you specified, or it might use a lower policy version. For example, if you specify version 3, but the policy has no conditional role bindings, the response uses version 1. To learn which resources support conditions in their IAM policies, see the IAM documentation . Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Models Get Iam Policy"},{"location":"projects_models-get-iam-policy/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-get-iam-policy ...","title":"Scopes"},{"location":"projects_models-get-iam-policy/#required-scalar-argument","text":"<resource> (string) REQUIRED: The resource for which the policy is being requested. See Resource names for the appropriate value for this field.","title":"Required Scalar Argument"},{"location":"projects_models-get-iam-policy/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_models-get-iam-policy/#optional-method-properties","text":"You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p options-requested-policy-version=integer Optional. The maximum policy version that will be used to format the policy. Valid values are 0, 1, and 3. Requests specifying an invalid value will be rejected. Requests for policies with any conditional role bindings must specify version 3. Policies with no conditional role bindings may specify any valid value or leave the field unset. The policy in the response might use the policy version that you specified, or it might use a lower policy version. For example, if you specify version 3, but the policy has no conditional role bindings, the response uses version 1. To learn which resources support conditions in their IAM policies, see the IAM documentation .","title":"Optional Method Properties"},{"location":"projects_models-get-iam-policy/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_models-get/","text":"Gets information about a model, including its name, the description (if set), and the default version (if at least one version of the model has been deployed). Scopes You will need authorization for at least one of the following scopes to make a valid call: https://www.googleapis.com/auth/cloud-platform https://www.googleapis.com/auth/cloud-platform.read-only If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-get ... Required Scalar Argument <name> (string) Required. The name of the model. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Models Get"},{"location":"projects_models-get/#scopes","text":"You will need authorization for at least one of the following scopes to make a valid call: https://www.googleapis.com/auth/cloud-platform https://www.googleapis.com/auth/cloud-platform.read-only If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-get ...","title":"Scopes"},{"location":"projects_models-get/#required-scalar-argument","text":"<name> (string) Required. The name of the model.","title":"Required Scalar Argument"},{"location":"projects_models-get/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_models-get/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_models-list/","text":"Lists the models in a project. Each project can contain multiple models, and each model can have multiple versions. If there are no models that match the request parameters, the list request returns an empty response body: {}. Scopes You will need authorization for at least one of the following scopes to make a valid call: https://www.googleapis.com/auth/cloud-platform https://www.googleapis.com/auth/cloud-platform.read-only If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-list ... Required Scalar Argument <parent> (string) Required. The name of the project whose models are to be listed. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional Method Properties You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p filter=string Optional. Specifies the subset of models to retrieve. -p page-size=integer Optional. The number of models to retrieve per \"page\" of results. If there are more remaining results than this number, the response message will contain a valid value in the next_page_token field. The default value is 20, and the maximum page size is 100. -p page-token=string Optional. A page token to request the next page of results. You get the token from the next_page_token field of the response from the previous call. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Models List"},{"location":"projects_models-list/#scopes","text":"You will need authorization for at least one of the following scopes to make a valid call: https://www.googleapis.com/auth/cloud-platform https://www.googleapis.com/auth/cloud-platform.read-only If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-list ...","title":"Scopes"},{"location":"projects_models-list/#required-scalar-argument","text":"<parent> (string) Required. The name of the project whose models are to be listed.","title":"Required Scalar Argument"},{"location":"projects_models-list/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_models-list/#optional-method-properties","text":"You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p filter=string Optional. Specifies the subset of models to retrieve. -p page-size=integer Optional. The number of models to retrieve per \"page\" of results. If there are more remaining results than this number, the response message will contain a valid value in the next_page_token field. The default value is 20, and the maximum page size is 100. -p page-token=string Optional. A page token to request the next page of results. You get the token from the next_page_token field of the response from the previous call.","title":"Optional Method Properties"},{"location":"projects_models-list/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_models-patch/","text":"Updates a specific model resource. Currently the only supported fields to update are description and default_version.name . Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-patch ... Required Scalar Argument <name> (string) Required. The project name. Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__Model: default-version: accelerator-config: count: string type: string auto-scaling: max-nodes: integer min-nodes: integer container: args: [string] command: [string] image: string create-time: string deployment-uri: string description: string error-message: string etag: string explanation-config: integrated-gradients-attribution: num-integral-steps: integer sampled-shapley-attribution: num-paths: integer xrai-attribution: num-integral-steps: integer framework: string is-default: boolean labels: { string: string } last-migration-model-id: string last-migration-time: string last-use-time: string machine-type: string manual-scaling: nodes: integer name: string package-uris: [string] prediction-class: string python-version: string request-logging-config: bigquery-table-name: string sampling-percentage: number routes: health: string predict: string runtime-version: string service-account: string state: string description: string etag: string labels: { string: string } name: string online-prediction-console-logging: boolean online-prediction-logging: boolean regions: [string] can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r .default-version.accelerator-config count=ipsum The number of accelerators to attach to each machine running the job. type=stet The type of accelerator to use. ..auto-scaling max-nodes=39 The maximum number of nodes to scale this model under load. The actual value will depend on resource quota and availability. min-nodes=96 Optional. The minimum number of nodes to allocate for this model. These nodes are always up, starting from the time the model is deployed. Therefore, the cost of operating this model will be at least rate * min_nodes * number of hours since last billing cycle, where rate is the cost per node-hour as documented in the pricing guide , even if no predictions are performed. There is additional cost for each prediction performed. Unlike manual scaling, if the load gets too heavy for the nodes that are up, the service will automatically add nodes to handle the increased load as well as scale back as traffic drops, always maintaining at least min_nodes . You will be charged for the time in which additional nodes are used. If min_nodes is not specified and AutoScaling is used with a legacy (MLS1) machine type , min_nodes defaults to 0, in which case, when traffic to a model stops (and after a cool-down period), nodes will be shut down and no charges will be incurred until traffic to the model resumes. If min_nodes is not specified and AutoScaling is used with a Compute Engine (N1) machine type , min_nodes defaults to 1. min_nodes must be at least 1 for use with a Compute Engine machine type. You can set min_nodes when creating the model version, and you can also update min_nodes for an existing version: update_body.json: { 'autoScaling': { 'minNodes': 5 } } HTTP request: PATCH https://ml.googleapis.com/v1/{name=projects/ /models/ /versions/*}?update_mask=autoScaling.minNodes -d @./update_body.json ..container args=no Immutable. Specifies arguments for the command that runs when the container starts. This overrides the container's CMD . Specify this field as an array of executable and arguments, similar to a Docker CMD 's \"default parameters\" form. If you don't specify this field but do specify the command field, then the command from the command field runs without any additional arguments. See the Kubernetes documentation about how the command and args fields interact with a container's ENTRYPOINT and CMD . If you don't specify this field and don't specify the commmand field, then the container's ENTRYPOINT and CMD determine what runs based on their default behavior. See the Docker documentation about how CMD and ENTRYPOINT interact . In this field, you can reference environment variables set by AI Platform Prediction and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with $$ ; for example: $$(VARIABLE_NAME) This field corresponds to the args field of the Kubernetes Containers v1 core API . Each invocation of this argument appends the given value to the array. command=sit Immutable. Specifies the command that runs when the container starts. This overrides the container's ENTRYPOINT . Specify this field as an array of executable and arguments, similar to a Docker ENTRYPOINT 's \"exec\" form, not its \"shell\" form. If you do not specify this field, then the container's ENTRYPOINT runs, in conjunction with the args field or the container's CMD , if either exists. If this field is not specified and the container does not have an ENTRYPOINT , then refer to the Docker documentation about how CMD and ENTRYPOINT interact . If you specify this field, then you can also specify the args field to provide additional arguments for this command. However, if you specify this field, then the container's CMD is ignored. See the Kubernetes documentation about how the command and args fields interact with a container's ENTRYPOINT and CMD . In this field, you can reference environment variables set by AI Platform Prediction and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with $$ ; for example: $$(VARIABLE_NAME) This field corresponds to the command field of the Kubernetes Containers v1 core API . Each invocation of this argument appends the given value to the array. image=kasd URI of the Docker image to be used as the custom container for serving predictions. This URI must identify an image in Artifact Registry and begin with the hostname {REGION}-docker.pkg.dev , where {REGION} is replaced by the region that matches AI Platform Prediction regional endpoint that you are using. For example, if you are using the us-central1-ml.googleapis.com endpoint, then this URI must begin with us-central1-docker.pkg.dev . To use a custom container, the AI Platform Google-managed service account must have permission to pull (read) the Docker image at this URI. The AI Platform Google-managed service account has the following format: service-{PROJECT_NUMBER}@cloud-ml.google.com.iam.gserviceaccount.com {PROJECT_NUMBER} is replaced by your Google Cloud project number. By default, this service account has necessary permissions to pull an Artifact Registry image in the same Google Cloud project where you are using AI Platform Prediction. In this case, no configuration is necessary. If you want to use an image from a different Google Cloud project, learn how to grant the Artifact Registry Reader (roles/artifactregistry.reader) role for a repository to your projet's AI Platform Google-managed service account. To learn about the requirements for the Docker image itself, read Custom container requirements . .. create-time=amet Output only. The time the version was created. deployment-uri=lorem The Cloud Storage URI of a directory containing trained model artifacts to be used to create the model version. See the guide to deploying models for more information. The total number of files under this directory must not exceed 1000. During projects.models.versions.create, AI Platform Prediction copies all files from the specified directory to a location managed by the service. From then on, AI Platform Prediction uses these copies of the model artifacts to serve predictions, not the original files in Cloud Storage, so this location is useful only as a historical record. If you specify container, then this field is optional. Otherwise, it is required. Learn how to use this field with a custom container . description=justo Optional. The description specified for the version when it was created. error-message=invidunt Output only. The details of a failure or a cancellation. etag=sed etag is used for optimistic concurrency control as a way to help prevent simultaneous updates of a model from overwriting each other. It is strongly suggested that systems make use of the etag in the read-modify-write cycle to perform model updates in order to avoid race conditions: An etag is returned in the response to GetVersion , and systems are expected to put that etag in the request to UpdateVersion to ensure that their change will be applied to the model as intended. explanation-config.integrated-gradients-attribution num-integral-steps=10 Number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. ..sampled-shapley-attribution num-paths=91 The number of feature permutations to consider when approximating the Shapley values. ..xrai-attribution num-integral-steps=1 Number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. ... framework=kasd Optional. The machine learning framework AI Platform uses to train this version of the model. Valid values are TENSORFLOW , SCIKIT_LEARN , XGBOOST . If you do not specify a framework, AI Platform will analyze files in the deployment_uri to determine a framework. If you choose SCIKIT_LEARN or XGBOOST , you must also set the runtime version of the model to 1.4 or greater. Do not specify a framework if you're deploying a custom prediction routine or if you're using a custom container . is-default=false Output only. If true, this version will be used to handle prediction requests that do not specify a version. You can change the default version by calling projects.methods.versions.setDefault. labels=key=erat Optional. One or more labels that you can add, to organize your model versions. Each label is a key-value pair, where both the key and the value are arbitrary strings that you supply. For more information, see the documentation on using labels. Note that this field is not updatable for mls1* models. the value will be associated with the given key last-migration-model-id=clita Output only. The AI Platform (Unified) Model ID for the last model migration . last-migration-time=vero Output only. The last time this version was successfully migrated to AI Platform (Unified) . last-use-time=invidunt Output only. The time the version was last used for prediction. machine-type=nonumy Optional. The type of machine on which to serve the model. Currently only applies to online prediction service. To learn about valid values for this field, read Choosing a machine type for online prediction . If this field is not specified and you are using a regional endpoint , then the machine type defaults to n1-standard-2 . If this field is not specified and you are using the global endpoint ( ml.googleapis.com ), then the machine type defaults to mls1-c1-m2 . manual-scaling nodes=20 The number of nodes to allocate for this model. These nodes are always up, starting from the time the model is deployed, so the cost of operating this model will be proportional to nodes * number of hours since last billing cycle plus the cost for each prediction performed. .. name=erat Required. The name specified for the version when it was created. The version name must be unique within the model it is created in. package-uris=dolores Optional. Cloud Storage paths ( gs://\u2026 ) of packages for custom prediction routines or scikit-learn pipelines with custom code . For a custom prediction routine, one of these packages must contain your Predictor class (see predictionClass ). Additionally, include any dependencies used by your Predictor or scikit-learn pipeline uses that are not already included in your selected runtime version . If you specify this field, you must also set runtimeVersion to 1.4 or greater. Each invocation of this argument appends the given value to the array. prediction-class=ipsum Optional. The fully qualified name (module_name.class_name) of a class that implements the Predictor interface described in this reference field. The module containing this class should be included in a package provided to the packageUris field . Specify this field if and only if you are deploying a custom prediction routine (beta) . If you specify this field, you must set runtimeVersion to 1.4 or greater and you must set machineType to a legacy (MLS1) machine type . The following code sample provides the Predictor interface: class Predictor(object): \"\"\"Interface for constructing custom predictors.\"\"\" def predict(self, instances, kwargs): \"\"\"Performs custom prediction. Instances are the decoded values from the request. They have already been deserialized from JSON. Args: instances: A list of prediction input instances. kwargs: A dictionary of keyword args provided as additional fields on the predict request body. Returns: A list of outputs containing the prediction results. This list must be JSON serializable. \"\"\" raise NotImplementedError() @classmethod def from_path(cls, model_dir): \"\"\"Creates an instance of Predictor using the given path. Loading of the predictor should be done in this method. Args: model_dir: The local directory that contains the exported model file along with any additional files uploaded when creating the version resource. Returns: An instance implementing this Predictor class. \"\"\" raise NotImplementedError() Learn more about the Predictor interface and custom prediction routines . python-version=voluptua. Required. The version of Python used in prediction. The following Python versions are available: * Python '3.7' is available when runtime_version is set to '1.15' or later. * Python '3.5' is available when runtime_version is set to a version from '1.4' to '1.14'. * Python '2.7' is available when runtime_version is set to '1.15' or earlier. Read more about the Python versions available for each runtime version . request-logging-config bigquery-table-name=eos Required. Fully qualified BigQuery table name in the following format: \" project_id.dataset_name.table_name\" The specified table must already exist, and the \"Cloud ML Service Agent\" for your project must have permission to write to it. The table must have the following schema : Field nameType Mode model STRING REQUIRED model_version STRING REQUIRED time TIMESTAMP REQUIRED raw_data STRING REQUIRED raw_prediction STRING NULLABLE groundtruth STRING NULLABLE sampling-percentage=0.2455307612046853 Percentage of requests to be logged, expressed as a fraction from 0 to 1. For example, if you want to log 10% of requests, enter 0.1 . The sampling window is the lifetime of the model version. Defaults to 0. ..routes health=elitr HTTP path on the container to send health checkss to. AI Platform Prediction intermittently sends GET requests to this path on the container's IP address and port to check that the container is healthy. Read more about health checks . For example, if you set this field to /bar , then AI Platform Prediction intermittently sends a GET request to the /bar path on the port of your container specified by the first value of Version.container.ports. If you don't specify this field, it defaults to the following value: /v1/models/ MODEL/versions/VERSION The placeholders in this value are replaced as follows: * MODEL: The name of the parent Model. This does not include the \"projects/PROJECT_ID/models/\" prefix that the API returns in output; it is the bare model name, as provided to projects.models.create. * VERSION: The name of the model version. This does not include the \"projects/PROJECT_ID /models/MODEL/versions/\" prefix that the API returns in output; it is the bare version name, as provided to projects.models.versions.create. predict=consetetur HTTP path on the container to send prediction requests to. AI Platform Prediction forwards requests sent using projects.predict to this path on the container's IP address and port. AI Platform Prediction then returns the container's response in the API response. For example, if you set this field to /foo , then when AI Platform Prediction receives a prediction request, it forwards the request body in a POST request to the /foo path on the port of your container specified by the first value of Version.container.ports. If you don't specify this field, it defaults to the following value: /v1/models/MODEL/versions/VERSION:predict The placeholders in this value are replaced as follows: * MODEL: The name of the parent Model. This does not include the \"projects/PROJECT_ID/models/\" prefix that the API returns in output; it is the bare model name, as provided to projects.models.create. * VERSION: The name of the model version. This does not include the \"projects/PROJECT_ID/models/MODEL/versions/\" prefix that the API returns in output; it is the bare version name, as provided to projects.models.versions.create. .. runtime-version=et Required. The AI Platform runtime version to use for this deployment. For more information, see the runtime version list and how to manage runtime versions . service-account=clita Optional. Specifies the service account for resource access control. If you specify this field, then you must also specify either the containerSpec or the predictionClass field. Learn more about using a custom service account . state=sit Output only. The state of a version. .. description=takimata Optional. The description specified for the model when it was created. etag=erat etag is used for optimistic concurrency control as a way to help prevent simultaneous updates of a model from overwriting each other. It is strongly suggested that systems make use of the etag in the read-modify-write cycle to perform model updates in order to avoid race conditions: An etag is returned in the response to GetModel , and systems are expected to put that etag in the request to UpdateModel to ensure that their change will be applied to the model as intended. labels=key=diam Optional. One or more labels that you can add, to organize your models. Each label is a key-value pair, where both the key and the value are arbitrary strings that you supply. For more information, see the documentation on using labels. Note that this field is not updatable for mls1* models. the value will be associated with the given key name=nonumy Required. The name specified for the model when it was created. The model name must be unique within the project it is created in. online-prediction-console-logging=false Optional. If true, online prediction nodes send stderr and stdout streams to Cloud Logging. These can be more verbose than the standard access logs (see onlinePredictionLogging ) and can incur higher cost. However, they are helpful for debugging. Note that logs may incur a cost , especially if your project receives prediction requests at a high QPS. Estimate your costs before enabling this option. Default is false. online-prediction-logging=false Optional. If true, online prediction access logs are sent to Cloud Logging. These logs are like standard server access logs, containing information like timestamp and latency for each request. Note that logs may incur a cost , especially if your project receives prediction requests at a high queries per second rate (QPS). Estimate your costs before enabling this option. Default is false. regions=diam Optional. The list of regions where the model is going to be deployed. Only one region per model is supported. Defaults to 'us-central1' if nothing is set. See the available regions for AI Platform services. Note: * No matter where a model is deployed, it can always be accessed by users from anywhere, both for online and batch prediction. * The region for a batch prediction job is set by the region field when submitting the batch prediction job and does not take its value from this field. Each invocation of this argument appends the given value to the array. About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional Method Properties You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p update-mask=string Required. Specifies the path, relative to Model , of the field to update. For example, to change the description of a model to \"foo\" and set its default version to \"version_1\", the update_mask parameter would be specified as description , default_version.name , and the PATCH request body would specify the new value, as follows: { \"description\": \"foo\", \"defaultVersion\": { \"name\":\"version_1\" } } Currently the supported update masks are description and default_version.name . Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Models Patch"},{"location":"projects_models-patch/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-patch ...","title":"Scopes"},{"location":"projects_models-patch/#required-scalar-argument","text":"<name> (string) Required. The project name.","title":"Required Scalar Argument"},{"location":"projects_models-patch/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__Model: default-version: accelerator-config: count: string type: string auto-scaling: max-nodes: integer min-nodes: integer container: args: [string] command: [string] image: string create-time: string deployment-uri: string description: string error-message: string etag: string explanation-config: integrated-gradients-attribution: num-integral-steps: integer sampled-shapley-attribution: num-paths: integer xrai-attribution: num-integral-steps: integer framework: string is-default: boolean labels: { string: string } last-migration-model-id: string last-migration-time: string last-use-time: string machine-type: string manual-scaling: nodes: integer name: string package-uris: [string] prediction-class: string python-version: string request-logging-config: bigquery-table-name: string sampling-percentage: number routes: health: string predict: string runtime-version: string service-account: string state: string description: string etag: string labels: { string: string } name: string online-prediction-console-logging: boolean online-prediction-logging: boolean regions: [string] can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r .default-version.accelerator-config count=ipsum The number of accelerators to attach to each machine running the job. type=stet The type of accelerator to use. ..auto-scaling max-nodes=39 The maximum number of nodes to scale this model under load. The actual value will depend on resource quota and availability. min-nodes=96 Optional. The minimum number of nodes to allocate for this model. These nodes are always up, starting from the time the model is deployed. Therefore, the cost of operating this model will be at least rate * min_nodes * number of hours since last billing cycle, where rate is the cost per node-hour as documented in the pricing guide , even if no predictions are performed. There is additional cost for each prediction performed. Unlike manual scaling, if the load gets too heavy for the nodes that are up, the service will automatically add nodes to handle the increased load as well as scale back as traffic drops, always maintaining at least min_nodes . You will be charged for the time in which additional nodes are used. If min_nodes is not specified and AutoScaling is used with a legacy (MLS1) machine type , min_nodes defaults to 0, in which case, when traffic to a model stops (and after a cool-down period), nodes will be shut down and no charges will be incurred until traffic to the model resumes. If min_nodes is not specified and AutoScaling is used with a Compute Engine (N1) machine type , min_nodes defaults to 1. min_nodes must be at least 1 for use with a Compute Engine machine type. You can set min_nodes when creating the model version, and you can also update min_nodes for an existing version: update_body.json: { 'autoScaling': { 'minNodes': 5 } } HTTP request: PATCH https://ml.googleapis.com/v1/{name=projects/ /models/ /versions/*}?update_mask=autoScaling.minNodes -d @./update_body.json ..container args=no Immutable. Specifies arguments for the command that runs when the container starts. This overrides the container's CMD . Specify this field as an array of executable and arguments, similar to a Docker CMD 's \"default parameters\" form. If you don't specify this field but do specify the command field, then the command from the command field runs without any additional arguments. See the Kubernetes documentation about how the command and args fields interact with a container's ENTRYPOINT and CMD . If you don't specify this field and don't specify the commmand field, then the container's ENTRYPOINT and CMD determine what runs based on their default behavior. See the Docker documentation about how CMD and ENTRYPOINT interact . In this field, you can reference environment variables set by AI Platform Prediction and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with $$ ; for example: $$(VARIABLE_NAME) This field corresponds to the args field of the Kubernetes Containers v1 core API . Each invocation of this argument appends the given value to the array. command=sit Immutable. Specifies the command that runs when the container starts. This overrides the container's ENTRYPOINT . Specify this field as an array of executable and arguments, similar to a Docker ENTRYPOINT 's \"exec\" form, not its \"shell\" form. If you do not specify this field, then the container's ENTRYPOINT runs, in conjunction with the args field or the container's CMD , if either exists. If this field is not specified and the container does not have an ENTRYPOINT , then refer to the Docker documentation about how CMD and ENTRYPOINT interact . If you specify this field, then you can also specify the args field to provide additional arguments for this command. However, if you specify this field, then the container's CMD is ignored. See the Kubernetes documentation about how the command and args fields interact with a container's ENTRYPOINT and CMD . In this field, you can reference environment variables set by AI Platform Prediction and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with $$ ; for example: $$(VARIABLE_NAME) This field corresponds to the command field of the Kubernetes Containers v1 core API . Each invocation of this argument appends the given value to the array. image=kasd URI of the Docker image to be used as the custom container for serving predictions. This URI must identify an image in Artifact Registry and begin with the hostname {REGION}-docker.pkg.dev , where {REGION} is replaced by the region that matches AI Platform Prediction regional endpoint that you are using. For example, if you are using the us-central1-ml.googleapis.com endpoint, then this URI must begin with us-central1-docker.pkg.dev . To use a custom container, the AI Platform Google-managed service account must have permission to pull (read) the Docker image at this URI. The AI Platform Google-managed service account has the following format: service-{PROJECT_NUMBER}@cloud-ml.google.com.iam.gserviceaccount.com {PROJECT_NUMBER} is replaced by your Google Cloud project number. By default, this service account has necessary permissions to pull an Artifact Registry image in the same Google Cloud project where you are using AI Platform Prediction. In this case, no configuration is necessary. If you want to use an image from a different Google Cloud project, learn how to grant the Artifact Registry Reader (roles/artifactregistry.reader) role for a repository to your projet's AI Platform Google-managed service account. To learn about the requirements for the Docker image itself, read Custom container requirements . .. create-time=amet Output only. The time the version was created. deployment-uri=lorem The Cloud Storage URI of a directory containing trained model artifacts to be used to create the model version. See the guide to deploying models for more information. The total number of files under this directory must not exceed 1000. During projects.models.versions.create, AI Platform Prediction copies all files from the specified directory to a location managed by the service. From then on, AI Platform Prediction uses these copies of the model artifacts to serve predictions, not the original files in Cloud Storage, so this location is useful only as a historical record. If you specify container, then this field is optional. Otherwise, it is required. Learn how to use this field with a custom container . description=justo Optional. The description specified for the version when it was created. error-message=invidunt Output only. The details of a failure or a cancellation. etag=sed etag is used for optimistic concurrency control as a way to help prevent simultaneous updates of a model from overwriting each other. It is strongly suggested that systems make use of the etag in the read-modify-write cycle to perform model updates in order to avoid race conditions: An etag is returned in the response to GetVersion , and systems are expected to put that etag in the request to UpdateVersion to ensure that their change will be applied to the model as intended. explanation-config.integrated-gradients-attribution num-integral-steps=10 Number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. ..sampled-shapley-attribution num-paths=91 The number of feature permutations to consider when approximating the Shapley values. ..xrai-attribution num-integral-steps=1 Number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. ... framework=kasd Optional. The machine learning framework AI Platform uses to train this version of the model. Valid values are TENSORFLOW , SCIKIT_LEARN , XGBOOST . If you do not specify a framework, AI Platform will analyze files in the deployment_uri to determine a framework. If you choose SCIKIT_LEARN or XGBOOST , you must also set the runtime version of the model to 1.4 or greater. Do not specify a framework if you're deploying a custom prediction routine or if you're using a custom container . is-default=false Output only. If true, this version will be used to handle prediction requests that do not specify a version. You can change the default version by calling projects.methods.versions.setDefault. labels=key=erat Optional. One or more labels that you can add, to organize your model versions. Each label is a key-value pair, where both the key and the value are arbitrary strings that you supply. For more information, see the documentation on using labels. Note that this field is not updatable for mls1* models. the value will be associated with the given key last-migration-model-id=clita Output only. The AI Platform (Unified) Model ID for the last model migration . last-migration-time=vero Output only. The last time this version was successfully migrated to AI Platform (Unified) . last-use-time=invidunt Output only. The time the version was last used for prediction. machine-type=nonumy Optional. The type of machine on which to serve the model. Currently only applies to online prediction service. To learn about valid values for this field, read Choosing a machine type for online prediction . If this field is not specified and you are using a regional endpoint , then the machine type defaults to n1-standard-2 . If this field is not specified and you are using the global endpoint ( ml.googleapis.com ), then the machine type defaults to mls1-c1-m2 . manual-scaling nodes=20 The number of nodes to allocate for this model. These nodes are always up, starting from the time the model is deployed, so the cost of operating this model will be proportional to nodes * number of hours since last billing cycle plus the cost for each prediction performed. .. name=erat Required. The name specified for the version when it was created. The version name must be unique within the model it is created in. package-uris=dolores Optional. Cloud Storage paths ( gs://\u2026 ) of packages for custom prediction routines or scikit-learn pipelines with custom code . For a custom prediction routine, one of these packages must contain your Predictor class (see predictionClass ). Additionally, include any dependencies used by your Predictor or scikit-learn pipeline uses that are not already included in your selected runtime version . If you specify this field, you must also set runtimeVersion to 1.4 or greater. Each invocation of this argument appends the given value to the array. prediction-class=ipsum Optional. The fully qualified name (module_name.class_name) of a class that implements the Predictor interface described in this reference field. The module containing this class should be included in a package provided to the packageUris field . Specify this field if and only if you are deploying a custom prediction routine (beta) . If you specify this field, you must set runtimeVersion to 1.4 or greater and you must set machineType to a legacy (MLS1) machine type . The following code sample provides the Predictor interface: class Predictor(object): \"\"\"Interface for constructing custom predictors.\"\"\" def predict(self, instances, kwargs): \"\"\"Performs custom prediction. Instances are the decoded values from the request. They have already been deserialized from JSON. Args: instances: A list of prediction input instances. kwargs: A dictionary of keyword args provided as additional fields on the predict request body. Returns: A list of outputs containing the prediction results. This list must be JSON serializable. \"\"\" raise NotImplementedError() @classmethod def from_path(cls, model_dir): \"\"\"Creates an instance of Predictor using the given path. Loading of the predictor should be done in this method. Args: model_dir: The local directory that contains the exported model file along with any additional files uploaded when creating the version resource. Returns: An instance implementing this Predictor class. \"\"\" raise NotImplementedError() Learn more about the Predictor interface and custom prediction routines . python-version=voluptua. Required. The version of Python used in prediction. The following Python versions are available: * Python '3.7' is available when runtime_version is set to '1.15' or later. * Python '3.5' is available when runtime_version is set to a version from '1.4' to '1.14'. * Python '2.7' is available when runtime_version is set to '1.15' or earlier. Read more about the Python versions available for each runtime version . request-logging-config bigquery-table-name=eos Required. Fully qualified BigQuery table name in the following format: \" project_id.dataset_name.table_name\" The specified table must already exist, and the \"Cloud ML Service Agent\" for your project must have permission to write to it. The table must have the following schema : Field nameType Mode model STRING REQUIRED model_version STRING REQUIRED time TIMESTAMP REQUIRED raw_data STRING REQUIRED raw_prediction STRING NULLABLE groundtruth STRING NULLABLE sampling-percentage=0.2455307612046853 Percentage of requests to be logged, expressed as a fraction from 0 to 1. For example, if you want to log 10% of requests, enter 0.1 . The sampling window is the lifetime of the model version. Defaults to 0. ..routes health=elitr HTTP path on the container to send health checkss to. AI Platform Prediction intermittently sends GET requests to this path on the container's IP address and port to check that the container is healthy. Read more about health checks . For example, if you set this field to /bar , then AI Platform Prediction intermittently sends a GET request to the /bar path on the port of your container specified by the first value of Version.container.ports. If you don't specify this field, it defaults to the following value: /v1/models/ MODEL/versions/VERSION The placeholders in this value are replaced as follows: * MODEL: The name of the parent Model. This does not include the \"projects/PROJECT_ID/models/\" prefix that the API returns in output; it is the bare model name, as provided to projects.models.create. * VERSION: The name of the model version. This does not include the \"projects/PROJECT_ID /models/MODEL/versions/\" prefix that the API returns in output; it is the bare version name, as provided to projects.models.versions.create. predict=consetetur HTTP path on the container to send prediction requests to. AI Platform Prediction forwards requests sent using projects.predict to this path on the container's IP address and port. AI Platform Prediction then returns the container's response in the API response. For example, if you set this field to /foo , then when AI Platform Prediction receives a prediction request, it forwards the request body in a POST request to the /foo path on the port of your container specified by the first value of Version.container.ports. If you don't specify this field, it defaults to the following value: /v1/models/MODEL/versions/VERSION:predict The placeholders in this value are replaced as follows: * MODEL: The name of the parent Model. This does not include the \"projects/PROJECT_ID/models/\" prefix that the API returns in output; it is the bare model name, as provided to projects.models.create. * VERSION: The name of the model version. This does not include the \"projects/PROJECT_ID/models/MODEL/versions/\" prefix that the API returns in output; it is the bare version name, as provided to projects.models.versions.create. .. runtime-version=et Required. The AI Platform runtime version to use for this deployment. For more information, see the runtime version list and how to manage runtime versions . service-account=clita Optional. Specifies the service account for resource access control. If you specify this field, then you must also specify either the containerSpec or the predictionClass field. Learn more about using a custom service account . state=sit Output only. The state of a version. .. description=takimata Optional. The description specified for the model when it was created. etag=erat etag is used for optimistic concurrency control as a way to help prevent simultaneous updates of a model from overwriting each other. It is strongly suggested that systems make use of the etag in the read-modify-write cycle to perform model updates in order to avoid race conditions: An etag is returned in the response to GetModel , and systems are expected to put that etag in the request to UpdateModel to ensure that their change will be applied to the model as intended. labels=key=diam Optional. One or more labels that you can add, to organize your models. Each label is a key-value pair, where both the key and the value are arbitrary strings that you supply. For more information, see the documentation on using labels. Note that this field is not updatable for mls1* models. the value will be associated with the given key name=nonumy Required. The name specified for the model when it was created. The model name must be unique within the project it is created in. online-prediction-console-logging=false Optional. If true, online prediction nodes send stderr and stdout streams to Cloud Logging. These can be more verbose than the standard access logs (see onlinePredictionLogging ) and can incur higher cost. However, they are helpful for debugging. Note that logs may incur a cost , especially if your project receives prediction requests at a high QPS. Estimate your costs before enabling this option. Default is false. online-prediction-logging=false Optional. If true, online prediction access logs are sent to Cloud Logging. These logs are like standard server access logs, containing information like timestamp and latency for each request. Note that logs may incur a cost , especially if your project receives prediction requests at a high queries per second rate (QPS). Estimate your costs before enabling this option. Default is false. regions=diam Optional. The list of regions where the model is going to be deployed. Only one region per model is supported. Defaults to 'us-central1' if nothing is set. See the available regions for AI Platform services. Note: * No matter where a model is deployed, it can always be accessed by users from anywhere, both for online and batch prediction. * The region for a batch prediction job is set by the region field when submitting the batch prediction job and does not take its value from this field. Each invocation of this argument appends the given value to the array.","title":"Required Request Value"},{"location":"projects_models-patch/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"projects_models-patch/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_models-patch/#optional-method-properties","text":"You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p update-mask=string Required. Specifies the path, relative to Model , of the field to update. For example, to change the description of a model to \"foo\" and set its default version to \"version_1\", the update_mask parameter would be specified as description , default_version.name , and the PATCH request body would specify the new value, as follows: { \"description\": \"foo\", \"defaultVersion\": { \"name\":\"version_1\" } } Currently the supported update masks are description and default_version.name .","title":"Optional Method Properties"},{"location":"projects_models-patch/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_models-set-iam-policy/","text":"Sets the access control policy on the specified resource. Replaces any existing policy. Can return NOT_FOUND , INVALID_ARGUMENT , and PERMISSION_DENIED errors. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-set-iam-policy ... Required Scalar Argument <resource> (string) REQUIRED: The resource for which the policy is being specified. See Resource names for the appropriate value for this field. Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleIamV1__SetIamPolicyRequest: policy: etag: string version: integer update-mask: string can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r .policy etag=sed etag is used for optimistic concurrency control as a way to help prevent simultaneous updates of a policy from overwriting each other. It is strongly suggested that systems make use of the etag in the read-modify-write cycle to perform policy updates in order to avoid race conditions: An etag is returned in the response to getIamPolicy , and systems are expected to put that etag in the request to setIamPolicy to ensure that their change will be applied to the same version of the policy. Important: If you use IAM Conditions, you must include the etag field whenever you call setIamPolicy . If you omit this field, then IAM allows you to overwrite a version 3 policy with a version 1 policy, and all of the conditions in the version 3 policy are lost. version=83 Specifies the format of the policy. Valid values are 0 , 1 , and 3 . Requests that specify an invalid value are rejected. Any operation that affects conditional role bindings must specify version 3 . This requirement applies to the following operations: * Getting a policy that includes a conditional role binding * Adding a conditional role binding to a policy * Changing a conditional role binding in a policy * Removing any role binding, with or without a condition, from a policy that includes conditions Important: If you use IAM Conditions, you must include the etag field whenever you call setIamPolicy . If you omit this field, then IAM allows you to overwrite a version 3 policy with a version 1 policy, and all of the conditions in the version 3 policy are lost. If a policy does not include any conditions, operations on that policy may specify any valid version or leave the field unset. To learn which resources support conditions in their IAM policies, see the IAM documentation . .. update-mask=ea OPTIONAL: A FieldMask specifying which fields of the policy to modify. Only the fields in the mask will be modified. If no mask is provided, the following default mask is used: paths: &#34;bindings, etag&#34; About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Models Set Iam Policy"},{"location":"projects_models-set-iam-policy/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-set-iam-policy ...","title":"Scopes"},{"location":"projects_models-set-iam-policy/#required-scalar-argument","text":"<resource> (string) REQUIRED: The resource for which the policy is being specified. See Resource names for the appropriate value for this field.","title":"Required Scalar Argument"},{"location":"projects_models-set-iam-policy/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleIamV1__SetIamPolicyRequest: policy: etag: string version: integer update-mask: string can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r .policy etag=sed etag is used for optimistic concurrency control as a way to help prevent simultaneous updates of a policy from overwriting each other. It is strongly suggested that systems make use of the etag in the read-modify-write cycle to perform policy updates in order to avoid race conditions: An etag is returned in the response to getIamPolicy , and systems are expected to put that etag in the request to setIamPolicy to ensure that their change will be applied to the same version of the policy. Important: If you use IAM Conditions, you must include the etag field whenever you call setIamPolicy . If you omit this field, then IAM allows you to overwrite a version 3 policy with a version 1 policy, and all of the conditions in the version 3 policy are lost. version=83 Specifies the format of the policy. Valid values are 0 , 1 , and 3 . Requests that specify an invalid value are rejected. Any operation that affects conditional role bindings must specify version 3 . This requirement applies to the following operations: * Getting a policy that includes a conditional role binding * Adding a conditional role binding to a policy * Changing a conditional role binding in a policy * Removing any role binding, with or without a condition, from a policy that includes conditions Important: If you use IAM Conditions, you must include the etag field whenever you call setIamPolicy . If you omit this field, then IAM allows you to overwrite a version 3 policy with a version 1 policy, and all of the conditions in the version 3 policy are lost. If a policy does not include any conditions, operations on that policy may specify any valid version or leave the field unset. To learn which resources support conditions in their IAM policies, see the IAM documentation . .. update-mask=ea OPTIONAL: A FieldMask specifying which fields of the policy to modify. Only the fields in the mask will be modified. If no mask is provided, the following default mask is used: paths: &#34;bindings, etag&#34;","title":"Required Request Value"},{"location":"projects_models-set-iam-policy/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"projects_models-set-iam-policy/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_models-set-iam-policy/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_models-test-iam-permissions/","text":"Returns permissions that a caller has on the specified resource. If the resource does not exist, this will return an empty set of permissions, not a NOT_FOUND error. Note: This operation is designed to be used for building permission-aware UIs and command-line tools, not for authorization checking. This operation may \"fail open\" without warning. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-test-iam-permissions ... Required Scalar Argument <resource> (string) REQUIRED: The resource for which the policy detail is being requested. See Resource names for the appropriate value for this field. Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleIamV1__TestIamPermissionsRequest: permissions: [string] can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r . permissions=dolore The set of permissions to check for the resource . Permissions with wildcards (such as * or storage.* ) are not allowed. For more information see IAM Overview . Each invocation of this argument appends the given value to the array. About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Models Test Iam Permissions"},{"location":"projects_models-test-iam-permissions/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-test-iam-permissions ...","title":"Scopes"},{"location":"projects_models-test-iam-permissions/#required-scalar-argument","text":"<resource> (string) REQUIRED: The resource for which the policy detail is being requested. See Resource names for the appropriate value for this field.","title":"Required Scalar Argument"},{"location":"projects_models-test-iam-permissions/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleIamV1__TestIamPermissionsRequest: permissions: [string] can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r . permissions=dolore The set of permissions to check for the resource . Permissions with wildcards (such as * or storage.* ) are not allowed. For more information see IAM Overview . Each invocation of this argument appends the given value to the array.","title":"Required Request Value"},{"location":"projects_models-test-iam-permissions/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"projects_models-test-iam-permissions/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_models-test-iam-permissions/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_models-versions-create/","text":"Creates a new version of a model from a trained TensorFlow model. If the version created in the cloud by this call is the first deployed version of the specified model, it will be made the default version of the model. When you add a version to a model that already has one or more versions, the default version does not automatically change. If you want a new version to be the default, you must call projects.models.versions.setDefault. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-versions-create ... Required Scalar Argument <parent> (string) Required. The name of the model. Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__Version: accelerator-config: count: string type: string auto-scaling: max-nodes: integer min-nodes: integer container: args: [string] command: [string] image: string create-time: string deployment-uri: string description: string error-message: string etag: string explanation-config: integrated-gradients-attribution: num-integral-steps: integer sampled-shapley-attribution: num-paths: integer xrai-attribution: num-integral-steps: integer framework: string is-default: boolean labels: { string: string } last-migration-model-id: string last-migration-time: string last-use-time: string machine-type: string manual-scaling: nodes: integer name: string package-uris: [string] prediction-class: string python-version: string request-logging-config: bigquery-table-name: string sampling-percentage: number routes: health: string predict: string runtime-version: string service-account: string state: string can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r .accelerator-config count=ipsum The number of accelerators to attach to each machine running the job. type=ea The type of accelerator to use. ..auto-scaling max-nodes=74 The maximum number of nodes to scale this model under load. The actual value will depend on resource quota and availability. min-nodes=48 Optional. The minimum number of nodes to allocate for this model. These nodes are always up, starting from the time the model is deployed. Therefore, the cost of operating this model will be at least rate * min_nodes * number of hours since last billing cycle, where rate is the cost per node-hour as documented in the pricing guide , even if no predictions are performed. There is additional cost for each prediction performed. Unlike manual scaling, if the load gets too heavy for the nodes that are up, the service will automatically add nodes to handle the increased load as well as scale back as traffic drops, always maintaining at least min_nodes . You will be charged for the time in which additional nodes are used. If min_nodes is not specified and AutoScaling is used with a legacy (MLS1) machine type , min_nodes defaults to 0, in which case, when traffic to a model stops (and after a cool-down period), nodes will be shut down and no charges will be incurred until traffic to the model resumes. If min_nodes is not specified and AutoScaling is used with a Compute Engine (N1) machine type , min_nodes defaults to 1. min_nodes must be at least 1 for use with a Compute Engine machine type. You can set min_nodes when creating the model version, and you can also update min_nodes for an existing version: update_body.json: { 'autoScaling': { 'minNodes': 5 } } HTTP request: PATCH https://ml.googleapis.com/v1/{name=projects/ /models/ /versions/*}?update_mask=autoScaling.minNodes -d @./update_body.json ..container args=sit Immutable. Specifies arguments for the command that runs when the container starts. This overrides the container's CMD . Specify this field as an array of executable and arguments, similar to a Docker CMD 's \"default parameters\" form. If you don't specify this field but do specify the command field, then the command from the command field runs without any additional arguments. See the Kubernetes documentation about how the command and args fields interact with a container's ENTRYPOINT and CMD . If you don't specify this field and don't specify the commmand field, then the container's ENTRYPOINT and CMD determine what runs based on their default behavior. See the Docker documentation about how CMD and ENTRYPOINT interact . In this field, you can reference environment variables set by AI Platform Prediction and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with $$ ; for example: $$(VARIABLE_NAME) This field corresponds to the args field of the Kubernetes Containers v1 core API . Each invocation of this argument appends the given value to the array. command=lorem Immutable. Specifies the command that runs when the container starts. This overrides the container's ENTRYPOINT . Specify this field as an array of executable and arguments, similar to a Docker ENTRYPOINT 's \"exec\" form, not its \"shell\" form. If you do not specify this field, then the container's ENTRYPOINT runs, in conjunction with the args field or the container's CMD , if either exists. If this field is not specified and the container does not have an ENTRYPOINT , then refer to the Docker documentation about how CMD and ENTRYPOINT interact . If you specify this field, then you can also specify the args field to provide additional arguments for this command. However, if you specify this field, then the container's CMD is ignored. See the Kubernetes documentation about how the command and args fields interact with a container's ENTRYPOINT and CMD . In this field, you can reference environment variables set by AI Platform Prediction and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with $$ ; for example: $$(VARIABLE_NAME) This field corresponds to the command field of the Kubernetes Containers v1 core API . Each invocation of this argument appends the given value to the array. image=stet URI of the Docker image to be used as the custom container for serving predictions. This URI must identify an image in Artifact Registry and begin with the hostname {REGION}-docker.pkg.dev , where {REGION} is replaced by the region that matches AI Platform Prediction regional endpoint that you are using. For example, if you are using the us-central1-ml.googleapis.com endpoint, then this URI must begin with us-central1-docker.pkg.dev . To use a custom container, the AI Platform Google-managed service account must have permission to pull (read) the Docker image at this URI. The AI Platform Google-managed service account has the following format: service-{PROJECT_NUMBER}@cloud-ml.google.com.iam.gserviceaccount.com {PROJECT_NUMBER} is replaced by your Google Cloud project number. By default, this service account has necessary permissions to pull an Artifact Registry image in the same Google Cloud project where you are using AI Platform Prediction. In this case, no configuration is necessary. If you want to use an image from a different Google Cloud project, learn how to grant the Artifact Registry Reader (roles/artifactregistry.reader) role for a repository to your projet's AI Platform Google-managed service account. To learn about the requirements for the Docker image itself, read Custom container requirements . .. create-time=duo Output only. The time the version was created. deployment-uri=elitr The Cloud Storage URI of a directory containing trained model artifacts to be used to create the model version. See the guide to deploying models for more information. The total number of files under this directory must not exceed 1000. During projects.models.versions.create, AI Platform Prediction copies all files from the specified directory to a location managed by the service. From then on, AI Platform Prediction uses these copies of the model artifacts to serve predictions, not the original files in Cloud Storage, so this location is useful only as a historical record. If you specify container, then this field is optional. Otherwise, it is required. Learn how to use this field with a custom container . description=aliquyam Optional. The description specified for the version when it was created. error-message=erat Output only. The details of a failure or a cancellation. etag=ut etag is used for optimistic concurrency control as a way to help prevent simultaneous updates of a model from overwriting each other. It is strongly suggested that systems make use of the etag in the read-modify-write cycle to perform model updates in order to avoid race conditions: An etag is returned in the response to GetVersion , and systems are expected to put that etag in the request to UpdateVersion to ensure that their change will be applied to the model as intended. explanation-config.integrated-gradients-attribution num-integral-steps=83 Number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. ..sampled-shapley-attribution num-paths=50 The number of feature permutations to consider when approximating the Shapley values. ..xrai-attribution num-integral-steps=35 Number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. ... framework=et Optional. The machine learning framework AI Platform uses to train this version of the model. Valid values are TENSORFLOW , SCIKIT_LEARN , XGBOOST . If you do not specify a framework, AI Platform will analyze files in the deployment_uri to determine a framework. If you choose SCIKIT_LEARN or XGBOOST , you must also set the runtime version of the model to 1.4 or greater. Do not specify a framework if you're deploying a custom prediction routine or if you're using a custom container . is-default=true Output only. If true, this version will be used to handle prediction requests that do not specify a version. You can change the default version by calling projects.methods.versions.setDefault. labels=key=aliquyam Optional. One or more labels that you can add, to organize your model versions. Each label is a key-value pair, where both the key and the value are arbitrary strings that you supply. For more information, see the documentation on using labels. Note that this field is not updatable for mls1* models. the value will be associated with the given key last-migration-model-id=kasd Output only. The AI Platform (Unified) Model ID for the last model migration . last-migration-time=lorem Output only. The last time this version was successfully migrated to AI Platform (Unified) . last-use-time=sit Output only. The time the version was last used for prediction. machine-type=kasd Optional. The type of machine on which to serve the model. Currently only applies to online prediction service. To learn about valid values for this field, read Choosing a machine type for online prediction . If this field is not specified and you are using a regional endpoint , then the machine type defaults to n1-standard-2 . If this field is not specified and you are using the global endpoint ( ml.googleapis.com ), then the machine type defaults to mls1-c1-m2 . manual-scaling nodes=62 The number of nodes to allocate for this model. These nodes are always up, starting from the time the model is deployed, so the cost of operating this model will be proportional to nodes * number of hours since last billing cycle plus the cost for each prediction performed. .. name=dolor Required. The name specified for the version when it was created. The version name must be unique within the model it is created in. package-uris=amet Optional. Cloud Storage paths ( gs://\u2026 ) of packages for custom prediction routines or scikit-learn pipelines with custom code . For a custom prediction routine, one of these packages must contain your Predictor class (see predictionClass ). Additionally, include any dependencies used by your Predictor or scikit-learn pipeline uses that are not already included in your selected runtime version . If you specify this field, you must also set runtimeVersion to 1.4 or greater. Each invocation of this argument appends the given value to the array. prediction-class=sit Optional. The fully qualified name (module_name.class_name) of a class that implements the Predictor interface described in this reference field. The module containing this class should be included in a package provided to the packageUris field . Specify this field if and only if you are deploying a custom prediction routine (beta) . If you specify this field, you must set runtimeVersion to 1.4 or greater and you must set machineType to a legacy (MLS1) machine type . The following code sample provides the Predictor interface: class Predictor(object): \"\"\"Interface for constructing custom predictors.\"\"\" def predict(self, instances, kwargs): \"\"\"Performs custom prediction. Instances are the decoded values from the request. They have already been deserialized from JSON. Args: instances: A list of prediction input instances. kwargs: A dictionary of keyword args provided as additional fields on the predict request body. Returns: A list of outputs containing the prediction results. This list must be JSON serializable. \"\"\" raise NotImplementedError() @classmethod def from_path(cls, model_dir): \"\"\"Creates an instance of Predictor using the given path. Loading of the predictor should be done in this method. Args: model_dir: The local directory that contains the exported model file along with any additional files uploaded when creating the version resource. Returns: An instance implementing this Predictor class. \"\"\" raise NotImplementedError() Learn more about the Predictor interface and custom prediction routines . python-version=rebum. Required. The version of Python used in prediction. The following Python versions are available: * Python '3.7' is available when runtime_version is set to '1.15' or later. * Python '3.5' is available when runtime_version is set to a version from '1.4' to '1.14'. * Python '2.7' is available when runtime_version is set to '1.15' or earlier. Read more about the Python versions available for each runtime version . request-logging-config bigquery-table-name=sea Required. Fully qualified BigQuery table name in the following format: \" project_id.dataset_name.table_name\" The specified table must already exist, and the \"Cloud ML Service Agent\" for your project must have permission to write to it. The table must have the following schema : Field nameType Mode model STRING REQUIRED model_version STRING REQUIRED time TIMESTAMP REQUIRED raw_data STRING REQUIRED raw_prediction STRING NULLABLE groundtruth STRING NULLABLE sampling-percentage=0.012890508443760607 Percentage of requests to be logged, expressed as a fraction from 0 to 1. For example, if you want to log 10% of requests, enter 0.1 . The sampling window is the lifetime of the model version. Defaults to 0. ..routes health=et HTTP path on the container to send health checkss to. AI Platform Prediction intermittently sends GET requests to this path on the container's IP address and port to check that the container is healthy. Read more about health checks . For example, if you set this field to /bar , then AI Platform Prediction intermittently sends a GET request to the /bar path on the port of your container specified by the first value of Version.container.ports. If you don't specify this field, it defaults to the following value: /v1/models/ MODEL/versions/VERSION The placeholders in this value are replaced as follows: * MODEL: The name of the parent Model. This does not include the \"projects/PROJECT_ID/models/\" prefix that the API returns in output; it is the bare model name, as provided to projects.models.create. * VERSION: The name of the model version. This does not include the \"projects/PROJECT_ID /models/MODEL/versions/\" prefix that the API returns in output; it is the bare version name, as provided to projects.models.versions.create. predict=elitr HTTP path on the container to send prediction requests to. AI Platform Prediction forwards requests sent using projects.predict to this path on the container's IP address and port. AI Platform Prediction then returns the container's response in the API response. For example, if you set this field to /foo , then when AI Platform Prediction receives a prediction request, it forwards the request body in a POST request to the /foo path on the port of your container specified by the first value of Version.container.ports. If you don't specify this field, it defaults to the following value: /v1/models/MODEL/versions/VERSION:predict The placeholders in this value are replaced as follows: * MODEL: The name of the parent Model. This does not include the \"projects/PROJECT_ID/models/\" prefix that the API returns in output; it is the bare model name, as provided to projects.models.create. * VERSION: The name of the model version. This does not include the \"projects/PROJECT_ID/models/MODEL/versions/\" prefix that the API returns in output; it is the bare version name, as provided to projects.models.versions.create. .. runtime-version=eirmod Required. The AI Platform runtime version to use for this deployment. For more information, see the runtime version list and how to manage runtime versions . service-account=dolor Optional. Specifies the service account for resource access control. If you specify this field, then you must also specify either the containerSpec or the predictionClass field. Learn more about using a custom service account . state=sadipscing Output only. The state of a version. About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Models Versions Create"},{"location":"projects_models-versions-create/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-versions-create ...","title":"Scopes"},{"location":"projects_models-versions-create/#required-scalar-argument","text":"<parent> (string) Required. The name of the model.","title":"Required Scalar Argument"},{"location":"projects_models-versions-create/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__Version: accelerator-config: count: string type: string auto-scaling: max-nodes: integer min-nodes: integer container: args: [string] command: [string] image: string create-time: string deployment-uri: string description: string error-message: string etag: string explanation-config: integrated-gradients-attribution: num-integral-steps: integer sampled-shapley-attribution: num-paths: integer xrai-attribution: num-integral-steps: integer framework: string is-default: boolean labels: { string: string } last-migration-model-id: string last-migration-time: string last-use-time: string machine-type: string manual-scaling: nodes: integer name: string package-uris: [string] prediction-class: string python-version: string request-logging-config: bigquery-table-name: string sampling-percentage: number routes: health: string predict: string runtime-version: string service-account: string state: string can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r .accelerator-config count=ipsum The number of accelerators to attach to each machine running the job. type=ea The type of accelerator to use. ..auto-scaling max-nodes=74 The maximum number of nodes to scale this model under load. The actual value will depend on resource quota and availability. min-nodes=48 Optional. The minimum number of nodes to allocate for this model. These nodes are always up, starting from the time the model is deployed. Therefore, the cost of operating this model will be at least rate * min_nodes * number of hours since last billing cycle, where rate is the cost per node-hour as documented in the pricing guide , even if no predictions are performed. There is additional cost for each prediction performed. Unlike manual scaling, if the load gets too heavy for the nodes that are up, the service will automatically add nodes to handle the increased load as well as scale back as traffic drops, always maintaining at least min_nodes . You will be charged for the time in which additional nodes are used. If min_nodes is not specified and AutoScaling is used with a legacy (MLS1) machine type , min_nodes defaults to 0, in which case, when traffic to a model stops (and after a cool-down period), nodes will be shut down and no charges will be incurred until traffic to the model resumes. If min_nodes is not specified and AutoScaling is used with a Compute Engine (N1) machine type , min_nodes defaults to 1. min_nodes must be at least 1 for use with a Compute Engine machine type. You can set min_nodes when creating the model version, and you can also update min_nodes for an existing version: update_body.json: { 'autoScaling': { 'minNodes': 5 } } HTTP request: PATCH https://ml.googleapis.com/v1/{name=projects/ /models/ /versions/*}?update_mask=autoScaling.minNodes -d @./update_body.json ..container args=sit Immutable. Specifies arguments for the command that runs when the container starts. This overrides the container's CMD . Specify this field as an array of executable and arguments, similar to a Docker CMD 's \"default parameters\" form. If you don't specify this field but do specify the command field, then the command from the command field runs without any additional arguments. See the Kubernetes documentation about how the command and args fields interact with a container's ENTRYPOINT and CMD . If you don't specify this field and don't specify the commmand field, then the container's ENTRYPOINT and CMD determine what runs based on their default behavior. See the Docker documentation about how CMD and ENTRYPOINT interact . In this field, you can reference environment variables set by AI Platform Prediction and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with $$ ; for example: $$(VARIABLE_NAME) This field corresponds to the args field of the Kubernetes Containers v1 core API . Each invocation of this argument appends the given value to the array. command=lorem Immutable. Specifies the command that runs when the container starts. This overrides the container's ENTRYPOINT . Specify this field as an array of executable and arguments, similar to a Docker ENTRYPOINT 's \"exec\" form, not its \"shell\" form. If you do not specify this field, then the container's ENTRYPOINT runs, in conjunction with the args field or the container's CMD , if either exists. If this field is not specified and the container does not have an ENTRYPOINT , then refer to the Docker documentation about how CMD and ENTRYPOINT interact . If you specify this field, then you can also specify the args field to provide additional arguments for this command. However, if you specify this field, then the container's CMD is ignored. See the Kubernetes documentation about how the command and args fields interact with a container's ENTRYPOINT and CMD . In this field, you can reference environment variables set by AI Platform Prediction and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with $$ ; for example: $$(VARIABLE_NAME) This field corresponds to the command field of the Kubernetes Containers v1 core API . Each invocation of this argument appends the given value to the array. image=stet URI of the Docker image to be used as the custom container for serving predictions. This URI must identify an image in Artifact Registry and begin with the hostname {REGION}-docker.pkg.dev , where {REGION} is replaced by the region that matches AI Platform Prediction regional endpoint that you are using. For example, if you are using the us-central1-ml.googleapis.com endpoint, then this URI must begin with us-central1-docker.pkg.dev . To use a custom container, the AI Platform Google-managed service account must have permission to pull (read) the Docker image at this URI. The AI Platform Google-managed service account has the following format: service-{PROJECT_NUMBER}@cloud-ml.google.com.iam.gserviceaccount.com {PROJECT_NUMBER} is replaced by your Google Cloud project number. By default, this service account has necessary permissions to pull an Artifact Registry image in the same Google Cloud project where you are using AI Platform Prediction. In this case, no configuration is necessary. If you want to use an image from a different Google Cloud project, learn how to grant the Artifact Registry Reader (roles/artifactregistry.reader) role for a repository to your projet's AI Platform Google-managed service account. To learn about the requirements for the Docker image itself, read Custom container requirements . .. create-time=duo Output only. The time the version was created. deployment-uri=elitr The Cloud Storage URI of a directory containing trained model artifacts to be used to create the model version. See the guide to deploying models for more information. The total number of files under this directory must not exceed 1000. During projects.models.versions.create, AI Platform Prediction copies all files from the specified directory to a location managed by the service. From then on, AI Platform Prediction uses these copies of the model artifacts to serve predictions, not the original files in Cloud Storage, so this location is useful only as a historical record. If you specify container, then this field is optional. Otherwise, it is required. Learn how to use this field with a custom container . description=aliquyam Optional. The description specified for the version when it was created. error-message=erat Output only. The details of a failure or a cancellation. etag=ut etag is used for optimistic concurrency control as a way to help prevent simultaneous updates of a model from overwriting each other. It is strongly suggested that systems make use of the etag in the read-modify-write cycle to perform model updates in order to avoid race conditions: An etag is returned in the response to GetVersion , and systems are expected to put that etag in the request to UpdateVersion to ensure that their change will be applied to the model as intended. explanation-config.integrated-gradients-attribution num-integral-steps=83 Number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. ..sampled-shapley-attribution num-paths=50 The number of feature permutations to consider when approximating the Shapley values. ..xrai-attribution num-integral-steps=35 Number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. ... framework=et Optional. The machine learning framework AI Platform uses to train this version of the model. Valid values are TENSORFLOW , SCIKIT_LEARN , XGBOOST . If you do not specify a framework, AI Platform will analyze files in the deployment_uri to determine a framework. If you choose SCIKIT_LEARN or XGBOOST , you must also set the runtime version of the model to 1.4 or greater. Do not specify a framework if you're deploying a custom prediction routine or if you're using a custom container . is-default=true Output only. If true, this version will be used to handle prediction requests that do not specify a version. You can change the default version by calling projects.methods.versions.setDefault. labels=key=aliquyam Optional. One or more labels that you can add, to organize your model versions. Each label is a key-value pair, where both the key and the value are arbitrary strings that you supply. For more information, see the documentation on using labels. Note that this field is not updatable for mls1* models. the value will be associated with the given key last-migration-model-id=kasd Output only. The AI Platform (Unified) Model ID for the last model migration . last-migration-time=lorem Output only. The last time this version was successfully migrated to AI Platform (Unified) . last-use-time=sit Output only. The time the version was last used for prediction. machine-type=kasd Optional. The type of machine on which to serve the model. Currently only applies to online prediction service. To learn about valid values for this field, read Choosing a machine type for online prediction . If this field is not specified and you are using a regional endpoint , then the machine type defaults to n1-standard-2 . If this field is not specified and you are using the global endpoint ( ml.googleapis.com ), then the machine type defaults to mls1-c1-m2 . manual-scaling nodes=62 The number of nodes to allocate for this model. These nodes are always up, starting from the time the model is deployed, so the cost of operating this model will be proportional to nodes * number of hours since last billing cycle plus the cost for each prediction performed. .. name=dolor Required. The name specified for the version when it was created. The version name must be unique within the model it is created in. package-uris=amet Optional. Cloud Storage paths ( gs://\u2026 ) of packages for custom prediction routines or scikit-learn pipelines with custom code . For a custom prediction routine, one of these packages must contain your Predictor class (see predictionClass ). Additionally, include any dependencies used by your Predictor or scikit-learn pipeline uses that are not already included in your selected runtime version . If you specify this field, you must also set runtimeVersion to 1.4 or greater. Each invocation of this argument appends the given value to the array. prediction-class=sit Optional. The fully qualified name (module_name.class_name) of a class that implements the Predictor interface described in this reference field. The module containing this class should be included in a package provided to the packageUris field . Specify this field if and only if you are deploying a custom prediction routine (beta) . If you specify this field, you must set runtimeVersion to 1.4 or greater and you must set machineType to a legacy (MLS1) machine type . The following code sample provides the Predictor interface: class Predictor(object): \"\"\"Interface for constructing custom predictors.\"\"\" def predict(self, instances, kwargs): \"\"\"Performs custom prediction. Instances are the decoded values from the request. They have already been deserialized from JSON. Args: instances: A list of prediction input instances. kwargs: A dictionary of keyword args provided as additional fields on the predict request body. Returns: A list of outputs containing the prediction results. This list must be JSON serializable. \"\"\" raise NotImplementedError() @classmethod def from_path(cls, model_dir): \"\"\"Creates an instance of Predictor using the given path. Loading of the predictor should be done in this method. Args: model_dir: The local directory that contains the exported model file along with any additional files uploaded when creating the version resource. Returns: An instance implementing this Predictor class. \"\"\" raise NotImplementedError() Learn more about the Predictor interface and custom prediction routines . python-version=rebum. Required. The version of Python used in prediction. The following Python versions are available: * Python '3.7' is available when runtime_version is set to '1.15' or later. * Python '3.5' is available when runtime_version is set to a version from '1.4' to '1.14'. * Python '2.7' is available when runtime_version is set to '1.15' or earlier. Read more about the Python versions available for each runtime version . request-logging-config bigquery-table-name=sea Required. Fully qualified BigQuery table name in the following format: \" project_id.dataset_name.table_name\" The specified table must already exist, and the \"Cloud ML Service Agent\" for your project must have permission to write to it. The table must have the following schema : Field nameType Mode model STRING REQUIRED model_version STRING REQUIRED time TIMESTAMP REQUIRED raw_data STRING REQUIRED raw_prediction STRING NULLABLE groundtruth STRING NULLABLE sampling-percentage=0.012890508443760607 Percentage of requests to be logged, expressed as a fraction from 0 to 1. For example, if you want to log 10% of requests, enter 0.1 . The sampling window is the lifetime of the model version. Defaults to 0. ..routes health=et HTTP path on the container to send health checkss to. AI Platform Prediction intermittently sends GET requests to this path on the container's IP address and port to check that the container is healthy. Read more about health checks . For example, if you set this field to /bar , then AI Platform Prediction intermittently sends a GET request to the /bar path on the port of your container specified by the first value of Version.container.ports. If you don't specify this field, it defaults to the following value: /v1/models/ MODEL/versions/VERSION The placeholders in this value are replaced as follows: * MODEL: The name of the parent Model. This does not include the \"projects/PROJECT_ID/models/\" prefix that the API returns in output; it is the bare model name, as provided to projects.models.create. * VERSION: The name of the model version. This does not include the \"projects/PROJECT_ID /models/MODEL/versions/\" prefix that the API returns in output; it is the bare version name, as provided to projects.models.versions.create. predict=elitr HTTP path on the container to send prediction requests to. AI Platform Prediction forwards requests sent using projects.predict to this path on the container's IP address and port. AI Platform Prediction then returns the container's response in the API response. For example, if you set this field to /foo , then when AI Platform Prediction receives a prediction request, it forwards the request body in a POST request to the /foo path on the port of your container specified by the first value of Version.container.ports. If you don't specify this field, it defaults to the following value: /v1/models/MODEL/versions/VERSION:predict The placeholders in this value are replaced as follows: * MODEL: The name of the parent Model. This does not include the \"projects/PROJECT_ID/models/\" prefix that the API returns in output; it is the bare model name, as provided to projects.models.create. * VERSION: The name of the model version. This does not include the \"projects/PROJECT_ID/models/MODEL/versions/\" prefix that the API returns in output; it is the bare version name, as provided to projects.models.versions.create. .. runtime-version=eirmod Required. The AI Platform runtime version to use for this deployment. For more information, see the runtime version list and how to manage runtime versions . service-account=dolor Optional. Specifies the service account for resource access control. If you specify this field, then you must also specify either the containerSpec or the predictionClass field. Learn more about using a custom service account . state=sadipscing Output only. The state of a version.","title":"Required Request Value"},{"location":"projects_models-versions-create/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"projects_models-versions-create/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_models-versions-create/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_models-versions-delete/","text":"Deletes a model version. Each model can have multiple versions deployed and in use at any given time. Use this method to remove a single version. Note: You cannot delete the version that is set as the default version of the model unless it is the only remaining version. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-versions-delete ... Required Scalar Argument <name> (string) Required. The name of the version. You can get the names of all the versions of a model by calling projects.models.versions.list. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Models Versions Delete"},{"location":"projects_models-versions-delete/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-versions-delete ...","title":"Scopes"},{"location":"projects_models-versions-delete/#required-scalar-argument","text":"<name> (string) Required. The name of the version. You can get the names of all the versions of a model by calling projects.models.versions.list.","title":"Required Scalar Argument"},{"location":"projects_models-versions-delete/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_models-versions-delete/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_models-versions-get/","text":"Gets information about a model version. Models can have multiple versions. You can call projects.models.versions.list to get the same information that this method returns for all of the versions of a model. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-versions-get ... Required Scalar Argument <name> (string) Required. The name of the version. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Models Versions Get"},{"location":"projects_models-versions-get/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-versions-get ...","title":"Scopes"},{"location":"projects_models-versions-get/#required-scalar-argument","text":"<name> (string) Required. The name of the version.","title":"Required Scalar Argument"},{"location":"projects_models-versions-get/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_models-versions-get/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_models-versions-list/","text":"Gets basic information about all the versions of a model. If you expect that a model has many versions, or if you need to handle only a limited number of results at a time, you can request that the list be retrieved in batches (called pages). If there are no versions that match the request parameters, the list request returns an empty response body: {}. Scopes You will need authorization for at least one of the following scopes to make a valid call: https://www.googleapis.com/auth/cloud-platform https://www.googleapis.com/auth/cloud-platform.read-only If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-versions-list ... Required Scalar Argument <parent> (string) Required. The name of the model for which to list the version. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional Method Properties You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p filter=string Optional. Specifies the subset of versions to retrieve. -p page-size=integer Optional. The number of versions to retrieve per \"page\" of results. If there are more remaining results than this number, the response message will contain a valid value in the next_page_token field. The default value is 20, and the maximum page size is 100. -p page-token=string Optional. A page token to request the next page of results. You get the token from the next_page_token field of the response from the previous call. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Models Versions List"},{"location":"projects_models-versions-list/#scopes","text":"You will need authorization for at least one of the following scopes to make a valid call: https://www.googleapis.com/auth/cloud-platform https://www.googleapis.com/auth/cloud-platform.read-only If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-versions-list ...","title":"Scopes"},{"location":"projects_models-versions-list/#required-scalar-argument","text":"<parent> (string) Required. The name of the model for which to list the version.","title":"Required Scalar Argument"},{"location":"projects_models-versions-list/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_models-versions-list/#optional-method-properties","text":"You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p filter=string Optional. Specifies the subset of versions to retrieve. -p page-size=integer Optional. The number of versions to retrieve per \"page\" of results. If there are more remaining results than this number, the response message will contain a valid value in the next_page_token field. The default value is 20, and the maximum page size is 100. -p page-token=string Optional. A page token to request the next page of results. You get the token from the next_page_token field of the response from the previous call.","title":"Optional Method Properties"},{"location":"projects_models-versions-list/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_models-versions-patch/","text":"Updates the specified Version resource. Currently the only update-able fields are description , requestLoggingConfig , autoScaling.minNodes , and manualScaling.nodes . Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-versions-patch ... Required Scalar Argument <name> (string) Required. The name of the model. Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__Version: accelerator-config: count: string type: string auto-scaling: max-nodes: integer min-nodes: integer container: args: [string] command: [string] image: string create-time: string deployment-uri: string description: string error-message: string etag: string explanation-config: integrated-gradients-attribution: num-integral-steps: integer sampled-shapley-attribution: num-paths: integer xrai-attribution: num-integral-steps: integer framework: string is-default: boolean labels: { string: string } last-migration-model-id: string last-migration-time: string last-use-time: string machine-type: string manual-scaling: nodes: integer name: string package-uris: [string] prediction-class: string python-version: string request-logging-config: bigquery-table-name: string sampling-percentage: number routes: health: string predict: string runtime-version: string service-account: string state: string can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r .accelerator-config count=dolor The number of accelerators to attach to each machine running the job. type=dolor The type of accelerator to use. ..auto-scaling max-nodes=55 The maximum number of nodes to scale this model under load. The actual value will depend on resource quota and availability. min-nodes=79 Optional. The minimum number of nodes to allocate for this model. These nodes are always up, starting from the time the model is deployed. Therefore, the cost of operating this model will be at least rate * min_nodes * number of hours since last billing cycle, where rate is the cost per node-hour as documented in the pricing guide , even if no predictions are performed. There is additional cost for each prediction performed. Unlike manual scaling, if the load gets too heavy for the nodes that are up, the service will automatically add nodes to handle the increased load as well as scale back as traffic drops, always maintaining at least min_nodes . You will be charged for the time in which additional nodes are used. If min_nodes is not specified and AutoScaling is used with a legacy (MLS1) machine type , min_nodes defaults to 0, in which case, when traffic to a model stops (and after a cool-down period), nodes will be shut down and no charges will be incurred until traffic to the model resumes. If min_nodes is not specified and AutoScaling is used with a Compute Engine (N1) machine type , min_nodes defaults to 1. min_nodes must be at least 1 for use with a Compute Engine machine type. You can set min_nodes when creating the model version, and you can also update min_nodes for an existing version: update_body.json: { 'autoScaling': { 'minNodes': 5 } } HTTP request: PATCH https://ml.googleapis.com/v1/{name=projects/ /models/ /versions/*}?update_mask=autoScaling.minNodes -d @./update_body.json ..container args=sit Immutable. Specifies arguments for the command that runs when the container starts. This overrides the container's CMD . Specify this field as an array of executable and arguments, similar to a Docker CMD 's \"default parameters\" form. If you don't specify this field but do specify the command field, then the command from the command field runs without any additional arguments. See the Kubernetes documentation about how the command and args fields interact with a container's ENTRYPOINT and CMD . If you don't specify this field and don't specify the commmand field, then the container's ENTRYPOINT and CMD determine what runs based on their default behavior. See the Docker documentation about how CMD and ENTRYPOINT interact . In this field, you can reference environment variables set by AI Platform Prediction and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with $$ ; for example: $$(VARIABLE_NAME) This field corresponds to the args field of the Kubernetes Containers v1 core API . Each invocation of this argument appends the given value to the array. command=lorem Immutable. Specifies the command that runs when the container starts. This overrides the container's ENTRYPOINT . Specify this field as an array of executable and arguments, similar to a Docker ENTRYPOINT 's \"exec\" form, not its \"shell\" form. If you do not specify this field, then the container's ENTRYPOINT runs, in conjunction with the args field or the container's CMD , if either exists. If this field is not specified and the container does not have an ENTRYPOINT , then refer to the Docker documentation about how CMD and ENTRYPOINT interact . If you specify this field, then you can also specify the args field to provide additional arguments for this command. However, if you specify this field, then the container's CMD is ignored. See the Kubernetes documentation about how the command and args fields interact with a container's ENTRYPOINT and CMD . In this field, you can reference environment variables set by AI Platform Prediction and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with $$ ; for example: $$(VARIABLE_NAME) This field corresponds to the command field of the Kubernetes Containers v1 core API . Each invocation of this argument appends the given value to the array. image=nonumy URI of the Docker image to be used as the custom container for serving predictions. This URI must identify an image in Artifact Registry and begin with the hostname {REGION}-docker.pkg.dev , where {REGION} is replaced by the region that matches AI Platform Prediction regional endpoint that you are using. For example, if you are using the us-central1-ml.googleapis.com endpoint, then this URI must begin with us-central1-docker.pkg.dev . To use a custom container, the AI Platform Google-managed service account must have permission to pull (read) the Docker image at this URI. The AI Platform Google-managed service account has the following format: service-{PROJECT_NUMBER}@cloud-ml.google.com.iam.gserviceaccount.com {PROJECT_NUMBER} is replaced by your Google Cloud project number. By default, this service account has necessary permissions to pull an Artifact Registry image in the same Google Cloud project where you are using AI Platform Prediction. In this case, no configuration is necessary. If you want to use an image from a different Google Cloud project, learn how to grant the Artifact Registry Reader (roles/artifactregistry.reader) role for a repository to your projet's AI Platform Google-managed service account. To learn about the requirements for the Docker image itself, read Custom container requirements . .. create-time=diam Output only. The time the version was created. deployment-uri=ipsum The Cloud Storage URI of a directory containing trained model artifacts to be used to create the model version. See the guide to deploying models for more information. The total number of files under this directory must not exceed 1000. During projects.models.versions.create, AI Platform Prediction copies all files from the specified directory to a location managed by the service. From then on, AI Platform Prediction uses these copies of the model artifacts to serve predictions, not the original files in Cloud Storage, so this location is useful only as a historical record. If you specify container, then this field is optional. Otherwise, it is required. Learn how to use this field with a custom container . description=invidunt Optional. The description specified for the version when it was created. error-message=stet Output only. The details of a failure or a cancellation. etag=voluptua. etag is used for optimistic concurrency control as a way to help prevent simultaneous updates of a model from overwriting each other. It is strongly suggested that systems make use of the etag in the read-modify-write cycle to perform model updates in order to avoid race conditions: An etag is returned in the response to GetVersion , and systems are expected to put that etag in the request to UpdateVersion to ensure that their change will be applied to the model as intended. explanation-config.integrated-gradients-attribution num-integral-steps=24 Number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. ..sampled-shapley-attribution num-paths=9 The number of feature permutations to consider when approximating the Shapley values. ..xrai-attribution num-integral-steps=54 Number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. ... framework=at Optional. The machine learning framework AI Platform uses to train this version of the model. Valid values are TENSORFLOW , SCIKIT_LEARN , XGBOOST . If you do not specify a framework, AI Platform will analyze files in the deployment_uri to determine a framework. If you choose SCIKIT_LEARN or XGBOOST , you must also set the runtime version of the model to 1.4 or greater. Do not specify a framework if you're deploying a custom prediction routine or if you're using a custom container . is-default=false Output only. If true, this version will be used to handle prediction requests that do not specify a version. You can change the default version by calling projects.methods.versions.setDefault. labels=key=erat Optional. One or more labels that you can add, to organize your model versions. Each label is a key-value pair, where both the key and the value are arbitrary strings that you supply. For more information, see the documentation on using labels. Note that this field is not updatable for mls1* models. the value will be associated with the given key last-migration-model-id=duo Output only. The AI Platform (Unified) Model ID for the last model migration . last-migration-time=et Output only. The last time this version was successfully migrated to AI Platform (Unified) . last-use-time=erat Output only. The time the version was last used for prediction. machine-type=sit Optional. The type of machine on which to serve the model. Currently only applies to online prediction service. To learn about valid values for this field, read Choosing a machine type for online prediction . If this field is not specified and you are using a regional endpoint , then the machine type defaults to n1-standard-2 . If this field is not specified and you are using the global endpoint ( ml.googleapis.com ), then the machine type defaults to mls1-c1-m2 . manual-scaling nodes=28 The number of nodes to allocate for this model. These nodes are always up, starting from the time the model is deployed, so the cost of operating this model will be proportional to nodes * number of hours since last billing cycle plus the cost for each prediction performed. .. name=et Required. The name specified for the version when it was created. The version name must be unique within the model it is created in. package-uris=nonumy Optional. Cloud Storage paths ( gs://\u2026 ) of packages for custom prediction routines or scikit-learn pipelines with custom code . For a custom prediction routine, one of these packages must contain your Predictor class (see predictionClass ). Additionally, include any dependencies used by your Predictor or scikit-learn pipeline uses that are not already included in your selected runtime version . If you specify this field, you must also set runtimeVersion to 1.4 or greater. Each invocation of this argument appends the given value to the array. prediction-class=accusam Optional. The fully qualified name (module_name.class_name) of a class that implements the Predictor interface described in this reference field. The module containing this class should be included in a package provided to the packageUris field . Specify this field if and only if you are deploying a custom prediction routine (beta) . If you specify this field, you must set runtimeVersion to 1.4 or greater and you must set machineType to a legacy (MLS1) machine type . The following code sample provides the Predictor interface: class Predictor(object): \"\"\"Interface for constructing custom predictors.\"\"\" def predict(self, instances, kwargs): \"\"\"Performs custom prediction. Instances are the decoded values from the request. They have already been deserialized from JSON. Args: instances: A list of prediction input instances. kwargs: A dictionary of keyword args provided as additional fields on the predict request body. Returns: A list of outputs containing the prediction results. This list must be JSON serializable. \"\"\" raise NotImplementedError() @classmethod def from_path(cls, model_dir): \"\"\"Creates an instance of Predictor using the given path. Loading of the predictor should be done in this method. Args: model_dir: The local directory that contains the exported model file along with any additional files uploaded when creating the version resource. Returns: An instance implementing this Predictor class. \"\"\" raise NotImplementedError() Learn more about the Predictor interface and custom prediction routines . python-version=ut Required. The version of Python used in prediction. The following Python versions are available: * Python '3.7' is available when runtime_version is set to '1.15' or later. * Python '3.5' is available when runtime_version is set to a version from '1.4' to '1.14'. * Python '2.7' is available when runtime_version is set to '1.15' or earlier. Read more about the Python versions available for each runtime version . request-logging-config bigquery-table-name=voluptua. Required. Fully qualified BigQuery table name in the following format: \" project_id.dataset_name.table_name\" The specified table must already exist, and the \"Cloud ML Service Agent\" for your project must have permission to write to it. The table must have the following schema : Field nameType Mode model STRING REQUIRED model_version STRING REQUIRED time TIMESTAMP REQUIRED raw_data STRING REQUIRED raw_prediction STRING NULLABLE groundtruth STRING NULLABLE sampling-percentage=0.43682361409344794 Percentage of requests to be logged, expressed as a fraction from 0 to 1. For example, if you want to log 10% of requests, enter 0.1 . The sampling window is the lifetime of the model version. Defaults to 0. ..routes health=amet HTTP path on the container to send health checkss to. AI Platform Prediction intermittently sends GET requests to this path on the container's IP address and port to check that the container is healthy. Read more about health checks . For example, if you set this field to /bar , then AI Platform Prediction intermittently sends a GET request to the /bar path on the port of your container specified by the first value of Version.container.ports. If you don't specify this field, it defaults to the following value: /v1/models/ MODEL/versions/VERSION The placeholders in this value are replaced as follows: * MODEL: The name of the parent Model. This does not include the \"projects/PROJECT_ID/models/\" prefix that the API returns in output; it is the bare model name, as provided to projects.models.create. * VERSION: The name of the model version. This does not include the \"projects/PROJECT_ID /models/MODEL/versions/\" prefix that the API returns in output; it is the bare version name, as provided to projects.models.versions.create. predict=et HTTP path on the container to send prediction requests to. AI Platform Prediction forwards requests sent using projects.predict to this path on the container's IP address and port. AI Platform Prediction then returns the container's response in the API response. For example, if you set this field to /foo , then when AI Platform Prediction receives a prediction request, it forwards the request body in a POST request to the /foo path on the port of your container specified by the first value of Version.container.ports. If you don't specify this field, it defaults to the following value: /v1/models/MODEL/versions/VERSION:predict The placeholders in this value are replaced as follows: * MODEL: The name of the parent Model. This does not include the \"projects/PROJECT_ID/models/\" prefix that the API returns in output; it is the bare model name, as provided to projects.models.create. * VERSION: The name of the model version. This does not include the \"projects/PROJECT_ID/models/MODEL/versions/\" prefix that the API returns in output; it is the bare version name, as provided to projects.models.versions.create. .. runtime-version=aliquyam Required. The AI Platform runtime version to use for this deployment. For more information, see the runtime version list and how to manage runtime versions . service-account=ipsum Optional. Specifies the service account for resource access control. If you specify this field, then you must also specify either the containerSpec or the predictionClass field. Learn more about using a custom service account . state=gubergren Output only. The state of a version. About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional Method Properties You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p update-mask=string Required. Specifies the path, relative to Version , of the field to update. Must be present and non-empty. For example, to change the description of a version to \"foo\", the update_mask parameter would be specified as description , and the PATCH request body would specify the new value, as follows: { &#34;description&#34;: &#34;foo&#34; } Currently the only supported update mask fields are description , requestLoggingConfig , autoScaling.minNodes , and manualScaling.nodes . However, you can only update manualScaling.nodes if the version uses a Compute Engine (N1) machine type . Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Models Versions Patch"},{"location":"projects_models-versions-patch/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-versions-patch ...","title":"Scopes"},{"location":"projects_models-versions-patch/#required-scalar-argument","text":"<name> (string) Required. The name of the model.","title":"Required Scalar Argument"},{"location":"projects_models-versions-patch/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__Version: accelerator-config: count: string type: string auto-scaling: max-nodes: integer min-nodes: integer container: args: [string] command: [string] image: string create-time: string deployment-uri: string description: string error-message: string etag: string explanation-config: integrated-gradients-attribution: num-integral-steps: integer sampled-shapley-attribution: num-paths: integer xrai-attribution: num-integral-steps: integer framework: string is-default: boolean labels: { string: string } last-migration-model-id: string last-migration-time: string last-use-time: string machine-type: string manual-scaling: nodes: integer name: string package-uris: [string] prediction-class: string python-version: string request-logging-config: bigquery-table-name: string sampling-percentage: number routes: health: string predict: string runtime-version: string service-account: string state: string can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r .accelerator-config count=dolor The number of accelerators to attach to each machine running the job. type=dolor The type of accelerator to use. ..auto-scaling max-nodes=55 The maximum number of nodes to scale this model under load. The actual value will depend on resource quota and availability. min-nodes=79 Optional. The minimum number of nodes to allocate for this model. These nodes are always up, starting from the time the model is deployed. Therefore, the cost of operating this model will be at least rate * min_nodes * number of hours since last billing cycle, where rate is the cost per node-hour as documented in the pricing guide , even if no predictions are performed. There is additional cost for each prediction performed. Unlike manual scaling, if the load gets too heavy for the nodes that are up, the service will automatically add nodes to handle the increased load as well as scale back as traffic drops, always maintaining at least min_nodes . You will be charged for the time in which additional nodes are used. If min_nodes is not specified and AutoScaling is used with a legacy (MLS1) machine type , min_nodes defaults to 0, in which case, when traffic to a model stops (and after a cool-down period), nodes will be shut down and no charges will be incurred until traffic to the model resumes. If min_nodes is not specified and AutoScaling is used with a Compute Engine (N1) machine type , min_nodes defaults to 1. min_nodes must be at least 1 for use with a Compute Engine machine type. You can set min_nodes when creating the model version, and you can also update min_nodes for an existing version: update_body.json: { 'autoScaling': { 'minNodes': 5 } } HTTP request: PATCH https://ml.googleapis.com/v1/{name=projects/ /models/ /versions/*}?update_mask=autoScaling.minNodes -d @./update_body.json ..container args=sit Immutable. Specifies arguments for the command that runs when the container starts. This overrides the container's CMD . Specify this field as an array of executable and arguments, similar to a Docker CMD 's \"default parameters\" form. If you don't specify this field but do specify the command field, then the command from the command field runs without any additional arguments. See the Kubernetes documentation about how the command and args fields interact with a container's ENTRYPOINT and CMD . If you don't specify this field and don't specify the commmand field, then the container's ENTRYPOINT and CMD determine what runs based on their default behavior. See the Docker documentation about how CMD and ENTRYPOINT interact . In this field, you can reference environment variables set by AI Platform Prediction and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with $$ ; for example: $$(VARIABLE_NAME) This field corresponds to the args field of the Kubernetes Containers v1 core API . Each invocation of this argument appends the given value to the array. command=lorem Immutable. Specifies the command that runs when the container starts. This overrides the container's ENTRYPOINT . Specify this field as an array of executable and arguments, similar to a Docker ENTRYPOINT 's \"exec\" form, not its \"shell\" form. If you do not specify this field, then the container's ENTRYPOINT runs, in conjunction with the args field or the container's CMD , if either exists. If this field is not specified and the container does not have an ENTRYPOINT , then refer to the Docker documentation about how CMD and ENTRYPOINT interact . If you specify this field, then you can also specify the args field to provide additional arguments for this command. However, if you specify this field, then the container's CMD is ignored. See the Kubernetes documentation about how the command and args fields interact with a container's ENTRYPOINT and CMD . In this field, you can reference environment variables set by AI Platform Prediction and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with $$ ; for example: $$(VARIABLE_NAME) This field corresponds to the command field of the Kubernetes Containers v1 core API . Each invocation of this argument appends the given value to the array. image=nonumy URI of the Docker image to be used as the custom container for serving predictions. This URI must identify an image in Artifact Registry and begin with the hostname {REGION}-docker.pkg.dev , where {REGION} is replaced by the region that matches AI Platform Prediction regional endpoint that you are using. For example, if you are using the us-central1-ml.googleapis.com endpoint, then this URI must begin with us-central1-docker.pkg.dev . To use a custom container, the AI Platform Google-managed service account must have permission to pull (read) the Docker image at this URI. The AI Platform Google-managed service account has the following format: service-{PROJECT_NUMBER}@cloud-ml.google.com.iam.gserviceaccount.com {PROJECT_NUMBER} is replaced by your Google Cloud project number. By default, this service account has necessary permissions to pull an Artifact Registry image in the same Google Cloud project where you are using AI Platform Prediction. In this case, no configuration is necessary. If you want to use an image from a different Google Cloud project, learn how to grant the Artifact Registry Reader (roles/artifactregistry.reader) role for a repository to your projet's AI Platform Google-managed service account. To learn about the requirements for the Docker image itself, read Custom container requirements . .. create-time=diam Output only. The time the version was created. deployment-uri=ipsum The Cloud Storage URI of a directory containing trained model artifacts to be used to create the model version. See the guide to deploying models for more information. The total number of files under this directory must not exceed 1000. During projects.models.versions.create, AI Platform Prediction copies all files from the specified directory to a location managed by the service. From then on, AI Platform Prediction uses these copies of the model artifacts to serve predictions, not the original files in Cloud Storage, so this location is useful only as a historical record. If you specify container, then this field is optional. Otherwise, it is required. Learn how to use this field with a custom container . description=invidunt Optional. The description specified for the version when it was created. error-message=stet Output only. The details of a failure or a cancellation. etag=voluptua. etag is used for optimistic concurrency control as a way to help prevent simultaneous updates of a model from overwriting each other. It is strongly suggested that systems make use of the etag in the read-modify-write cycle to perform model updates in order to avoid race conditions: An etag is returned in the response to GetVersion , and systems are expected to put that etag in the request to UpdateVersion to ensure that their change will be applied to the model as intended. explanation-config.integrated-gradients-attribution num-integral-steps=24 Number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. ..sampled-shapley-attribution num-paths=9 The number of feature permutations to consider when approximating the Shapley values. ..xrai-attribution num-integral-steps=54 Number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range. ... framework=at Optional. The machine learning framework AI Platform uses to train this version of the model. Valid values are TENSORFLOW , SCIKIT_LEARN , XGBOOST . If you do not specify a framework, AI Platform will analyze files in the deployment_uri to determine a framework. If you choose SCIKIT_LEARN or XGBOOST , you must also set the runtime version of the model to 1.4 or greater. Do not specify a framework if you're deploying a custom prediction routine or if you're using a custom container . is-default=false Output only. If true, this version will be used to handle prediction requests that do not specify a version. You can change the default version by calling projects.methods.versions.setDefault. labels=key=erat Optional. One or more labels that you can add, to organize your model versions. Each label is a key-value pair, where both the key and the value are arbitrary strings that you supply. For more information, see the documentation on using labels. Note that this field is not updatable for mls1* models. the value will be associated with the given key last-migration-model-id=duo Output only. The AI Platform (Unified) Model ID for the last model migration . last-migration-time=et Output only. The last time this version was successfully migrated to AI Platform (Unified) . last-use-time=erat Output only. The time the version was last used for prediction. machine-type=sit Optional. The type of machine on which to serve the model. Currently only applies to online prediction service. To learn about valid values for this field, read Choosing a machine type for online prediction . If this field is not specified and you are using a regional endpoint , then the machine type defaults to n1-standard-2 . If this field is not specified and you are using the global endpoint ( ml.googleapis.com ), then the machine type defaults to mls1-c1-m2 . manual-scaling nodes=28 The number of nodes to allocate for this model. These nodes are always up, starting from the time the model is deployed, so the cost of operating this model will be proportional to nodes * number of hours since last billing cycle plus the cost for each prediction performed. .. name=et Required. The name specified for the version when it was created. The version name must be unique within the model it is created in. package-uris=nonumy Optional. Cloud Storage paths ( gs://\u2026 ) of packages for custom prediction routines or scikit-learn pipelines with custom code . For a custom prediction routine, one of these packages must contain your Predictor class (see predictionClass ). Additionally, include any dependencies used by your Predictor or scikit-learn pipeline uses that are not already included in your selected runtime version . If you specify this field, you must also set runtimeVersion to 1.4 or greater. Each invocation of this argument appends the given value to the array. prediction-class=accusam Optional. The fully qualified name (module_name.class_name) of a class that implements the Predictor interface described in this reference field. The module containing this class should be included in a package provided to the packageUris field . Specify this field if and only if you are deploying a custom prediction routine (beta) . If you specify this field, you must set runtimeVersion to 1.4 or greater and you must set machineType to a legacy (MLS1) machine type . The following code sample provides the Predictor interface: class Predictor(object): \"\"\"Interface for constructing custom predictors.\"\"\" def predict(self, instances, kwargs): \"\"\"Performs custom prediction. Instances are the decoded values from the request. They have already been deserialized from JSON. Args: instances: A list of prediction input instances. kwargs: A dictionary of keyword args provided as additional fields on the predict request body. Returns: A list of outputs containing the prediction results. This list must be JSON serializable. \"\"\" raise NotImplementedError() @classmethod def from_path(cls, model_dir): \"\"\"Creates an instance of Predictor using the given path. Loading of the predictor should be done in this method. Args: model_dir: The local directory that contains the exported model file along with any additional files uploaded when creating the version resource. Returns: An instance implementing this Predictor class. \"\"\" raise NotImplementedError() Learn more about the Predictor interface and custom prediction routines . python-version=ut Required. The version of Python used in prediction. The following Python versions are available: * Python '3.7' is available when runtime_version is set to '1.15' or later. * Python '3.5' is available when runtime_version is set to a version from '1.4' to '1.14'. * Python '2.7' is available when runtime_version is set to '1.15' or earlier. Read more about the Python versions available for each runtime version . request-logging-config bigquery-table-name=voluptua. Required. Fully qualified BigQuery table name in the following format: \" project_id.dataset_name.table_name\" The specified table must already exist, and the \"Cloud ML Service Agent\" for your project must have permission to write to it. The table must have the following schema : Field nameType Mode model STRING REQUIRED model_version STRING REQUIRED time TIMESTAMP REQUIRED raw_data STRING REQUIRED raw_prediction STRING NULLABLE groundtruth STRING NULLABLE sampling-percentage=0.43682361409344794 Percentage of requests to be logged, expressed as a fraction from 0 to 1. For example, if you want to log 10% of requests, enter 0.1 . The sampling window is the lifetime of the model version. Defaults to 0. ..routes health=amet HTTP path on the container to send health checkss to. AI Platform Prediction intermittently sends GET requests to this path on the container's IP address and port to check that the container is healthy. Read more about health checks . For example, if you set this field to /bar , then AI Platform Prediction intermittently sends a GET request to the /bar path on the port of your container specified by the first value of Version.container.ports. If you don't specify this field, it defaults to the following value: /v1/models/ MODEL/versions/VERSION The placeholders in this value are replaced as follows: * MODEL: The name of the parent Model. This does not include the \"projects/PROJECT_ID/models/\" prefix that the API returns in output; it is the bare model name, as provided to projects.models.create. * VERSION: The name of the model version. This does not include the \"projects/PROJECT_ID /models/MODEL/versions/\" prefix that the API returns in output; it is the bare version name, as provided to projects.models.versions.create. predict=et HTTP path on the container to send prediction requests to. AI Platform Prediction forwards requests sent using projects.predict to this path on the container's IP address and port. AI Platform Prediction then returns the container's response in the API response. For example, if you set this field to /foo , then when AI Platform Prediction receives a prediction request, it forwards the request body in a POST request to the /foo path on the port of your container specified by the first value of Version.container.ports. If you don't specify this field, it defaults to the following value: /v1/models/MODEL/versions/VERSION:predict The placeholders in this value are replaced as follows: * MODEL: The name of the parent Model. This does not include the \"projects/PROJECT_ID/models/\" prefix that the API returns in output; it is the bare model name, as provided to projects.models.create. * VERSION: The name of the model version. This does not include the \"projects/PROJECT_ID/models/MODEL/versions/\" prefix that the API returns in output; it is the bare version name, as provided to projects.models.versions.create. .. runtime-version=aliquyam Required. The AI Platform runtime version to use for this deployment. For more information, see the runtime version list and how to manage runtime versions . service-account=ipsum Optional. Specifies the service account for resource access control. If you specify this field, then you must also specify either the containerSpec or the predictionClass field. Learn more about using a custom service account . state=gubergren Output only. The state of a version.","title":"Required Request Value"},{"location":"projects_models-versions-patch/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"projects_models-versions-patch/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_models-versions-patch/#optional-method-properties","text":"You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p update-mask=string Required. Specifies the path, relative to Version , of the field to update. Must be present and non-empty. For example, to change the description of a version to \"foo\", the update_mask parameter would be specified as description , and the PATCH request body would specify the new value, as follows: { &#34;description&#34;: &#34;foo&#34; } Currently the only supported update mask fields are description , requestLoggingConfig , autoScaling.minNodes , and manualScaling.nodes . However, you can only update manualScaling.nodes if the version uses a Compute Engine (N1) machine type .","title":"Optional Method Properties"},{"location":"projects_models-versions-patch/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_models-versions-set-default/","text":"Designates a version to be the default for the model. The default version is used for prediction requests made against the model that don't specify a version. The first version to be created for a model is automatically set as the default. You must make any subsequent changes to the default version setting manually using this method. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-versions-set-default ... Required Scalar Argument <name> (string) Required. The name of the version to make the default for the model. You can get the names of all the versions of a model by calling projects.models.versions.list. Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__SetDefaultVersionRequest: can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Models Versions Set Default"},{"location":"projects_models-versions-set-default/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects models-versions-set-default ...","title":"Scopes"},{"location":"projects_models-versions-set-default/#required-scalar-argument","text":"<name> (string) Required. The name of the version to make the default for the model. You can get the names of all the versions of a model by calling projects.models.versions.list.","title":"Required Scalar Argument"},{"location":"projects_models-versions-set-default/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__SetDefaultVersionRequest: can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time.","title":"Required Request Value"},{"location":"projects_models-versions-set-default/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"projects_models-versions-set-default/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_models-versions-set-default/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_operations-cancel/","text":"Starts asynchronous cancellation on a long-running operation. The server makes a best effort to cancel the operation, but success is not guaranteed. If the server doesn't support this method, it returns google.rpc.Code.UNIMPLEMENTED . Clients can use Operations.GetOperation or other methods to check whether the cancellation succeeded or whether the operation completed despite cancellation. On successful cancellation, the operation is not deleted; instead, it becomes an operation with an Operation.error value with a google.rpc.Status.code of 1, corresponding to Code.CANCELLED . Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects operations-cancel ... Required Scalar Argument <name> (string) The name of the operation resource to be cancelled. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Operations Cancel"},{"location":"projects_operations-cancel/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects operations-cancel ...","title":"Scopes"},{"location":"projects_operations-cancel/#required-scalar-argument","text":"<name> (string) The name of the operation resource to be cancelled.","title":"Required Scalar Argument"},{"location":"projects_operations-cancel/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_operations-cancel/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_operations-get/","text":"Gets the latest state of a long-running operation. Clients can use this method to poll the operation result at intervals as recommended by the API service. Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects operations-get ... Required Scalar Argument <name> (string) The name of the operation resource. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Operations Get"},{"location":"projects_operations-get/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects operations-get ...","title":"Scopes"},{"location":"projects_operations-get/#required-scalar-argument","text":"<name> (string) The name of the operation resource.","title":"Required Scalar Argument"},{"location":"projects_operations-get/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_operations-get/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_operations-list/","text":"Lists operations that match the specified filter in the request. If the server doesn't support this method, it returns UNIMPLEMENTED . Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects operations-list ... Required Scalar Argument <name> (string) The name of the operation's parent resource. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional Method Properties You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p filter=string The standard list filter. -p page-size=integer The standard list page size. -p page-token=string The standard list page token. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Operations List"},{"location":"projects_operations-list/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects operations-list ...","title":"Scopes"},{"location":"projects_operations-list/#required-scalar-argument","text":"<name> (string) The name of the operation's parent resource.","title":"Required Scalar Argument"},{"location":"projects_operations-list/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_operations-list/#optional-method-properties","text":"You may set the following properties to further configure the call. Please note that -p is followed by one or more key-value-pairs, and is called like this -p k1=v1 k2=v2 even though the listing below repeats the -p for completeness. -p filter=string The standard list filter. -p page-size=integer The standard list page size. -p page-token=string The standard list page token.","title":"Optional Method Properties"},{"location":"projects_operations-list/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"},{"location":"projects_predict/","text":"Performs online prediction on the data in the request. {% dynamic include \"/ai-platform/includes/___predict-request\" %} Scopes You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects predict ... Required Scalar Argument <name> (string) Required. The resource name of a model or a version. Authorization: requires the predict permission on the specified resource. Required Request Value The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__PredictRequest: http-body: content-type: string data: string can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r .http-body content-type=invidunt The HTTP Content-Type header value specifying the content type of the body. data=sea The HTTP request/response body as raw binary. About Cursors The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up. Optional Output Flags The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output. Optional General Properties The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Predict"},{"location":"projects_predict/#scopes","text":"You will need authorization for the https://www.googleapis.com/auth/cloud-platform scope to make a valid call. If unset, the scope for this method defaults to https://www.googleapis.com/auth/cloud-platform . You can set the scope for this method like this: ml1 --scope <scope> projects predict ...","title":"Scopes"},{"location":"projects_predict/#required-scalar-argument","text":"<name> (string) Required. The resource name of a model or a version. Authorization: requires the predict permission on the specified resource.","title":"Required Scalar Argument"},{"location":"projects_predict/#required-request-value","text":"The request value is a data-structure with various fields. Each field may be a simple scalar or another data-structure. In the latter case it is advised to set the field-cursor to the data-structure's field to specify values more concisely. For example, a structure like this: GoogleCloudMlV1__PredictRequest: http-body: content-type: string data: string can be set completely with the following arguments which are assumed to be executed in the given order. Note how the cursor position is adjusted to the respective structures, allowing simple field names to be used most of the time. -r .http-body content-type=invidunt The HTTP Content-Type header value specifying the content type of the body. data=sea The HTTP request/response body as raw binary.","title":"Required Request Value"},{"location":"projects_predict/#about-cursors","text":"The cursor position is key to comfortably set complex nested structures. The following rules apply: The cursor position is always set relative to the current one, unless the field name starts with the . character. Fields can be nested such as in -r f.s.o . The cursor position is set relative to the top-level structure if it starts with . , e.g. -r .s.s You can also set nested fields without setting the cursor explicitly. For example, to set a value relative to the current cursor position, you would specify -r struct.sub_struct=bar . You can move the cursor one level up by using .. . Each additional . moves it up one additional level. E.g. ... would go three levels up.","title":"About Cursors"},{"location":"projects_predict/#optional-output-flags","text":"The method's return value a JSON encoded structure, which will be written to standard output by default. -o out out specifies the destination to which to write the server's result to. It will be a JSON-encoded structure. The destination may be - to indicate standard output, or a filepath that is to contain the received bytes. If unset, it defaults to standard output.","title":"Optional Output Flags"},{"location":"projects_predict/#optional-general-properties","text":"The following properties can configure any call, and are not specific to this method. -p $-xgafv=string V1 error format. -p access-token=string OAuth access token. -p alt=string Data format for response. -p callback=string JSONP -p fields=string Selector specifying which fields to include in a partial response. -p key=string API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token. -p oauth-token=string OAuth 2.0 token for the current user. -p pretty-print=boolean Returns response with indentations and line breaks. -p quota-user=string Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. -p upload-type=string Legacy upload protocol for media (e.g. \"media\", \"multipart\"). -p upload-protocol=string Upload protocol for media (e.g. \"raw\", \"multipart\").","title":"Optional General Properties"}]}