initSidebarItems({"enum":[["Scope","Identifies the an OAuth2 authorization scope. A scope is needed when requesting an authorization token."]],"struct":[["AsyncRecognizeRequest","The top-level message sent by the client for the `AsyncRecognize` method."],["ListOperationsResponse","The response message for Operations.ListOperations."],["Operation","This resource represents a long-running operation that is the result of a network API call."],["OperationGetCall","Gets the latest state of a long-running operation.  Clients can use this method to poll the operation result at intervals as recommended by the API service."],["OperationListCall","Lists operations that match the specified filter in the request. If the server doesn't support this method, it returns `UNIMPLEMENTED`."],["OperationMethods","A builder providing access to all methods supported on operation resources. It is not used directly, but through the `Speech` hub."],["RecognitionAudio","Contains audio data in the encoding specified in the `RecognitionConfig`. Either `content` or `uri` must be supplied. Supplying both or neither returns google.rpc.Code.INVALID_ARGUMENT. See audio limits."],["RecognitionConfig","Provides information to the recognizer that specifies how to process the request."],["Speech","Central instance to access all Speech related resource activities"],["SpeechAsyncrecognizeCall","Performs asynchronous speech recognition: receive results via the [google.longrunning.Operations] (/speech/reference/rest/v1beta1/operations#Operation) interface. Returns either an `Operation.error` or an `Operation.response` which contains an `AsyncRecognizeResponse` message."],["SpeechContext","Provides \"hints\" to the speech recognizer to favor specific words and phrases in the results."],["SpeechMethods","A builder providing access to all methods supported on speech resources. It is not used directly, but through the `Speech` hub."],["SpeechRecognitionAlternative","Alternative hypotheses (a.k.a. n-best list)."],["SpeechRecognitionResult","A speech recognition result corresponding to a portion of the audio."],["SpeechSyncrecognizeCall","Performs synchronous speech recognition: receive results after all audio has been sent and processed."],["Status","The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by gRPC. The error model is designed to be:"],["SyncRecognizeRequest","The top-level message sent by the client for the `SyncRecognize` method."],["SyncRecognizeResponse","The only message returned to the client by `SyncRecognize`. method. It contains the result as zero or more sequential `SpeechRecognitionResult` messages."]]});