initSidebarItems({"enum":[["Scope","Identifies the an OAuth2 authorization scope. A scope is needed when requesting an authorization token."]],"struct":[["Aggregation","Describes how to combine multiple time series to provide a different view of the data. Aggregation of time series is done in two steps. First, each time series in the set is aligned to the same time interval boundaries, then the set of time series is optionally reduced in number.Alignment consists of applying the per_series_aligner operation to each time series after its data has been divided into regular alignment_period time intervals. This process takes all of the data points in an alignment period, applies a mathematical transformation such as averaging, minimum, maximum, delta, etc., and converts them into a single data point per period.Reduction is when the aligned and transformed time series can optionally be combined, reducing the number of time series through similar mathematical transformations. Reduction involves applying a cross_series_reducer to all the time series, optionally sorting the time series into subsets with group_by_fields, and applying the reducer to each subset.The raw time series data can contain a huge amount of information from multiple sources. Alignment and reduction transforms this mass of data into a more manageable and representative collection of data, for example \"the 95% latency across the average of all tasks in a cluster\". This representative data can be more easily graphed and comprehended, and the individual time series data is still available for later drilldown. For more details, see Filtering and aggregation (https://cloud.google.com/monitoring/api/v3/aggregation)."],["AlertPolicy","A description of the conditions under which some aspect of your system is considered to be \"unhealthy\" and the ways to notify people or services about this state. For an overview of alert policies, see Introduction to Alerting (https://cloud.google.com/monitoring/alerts/)."],["AppEngine","App Engine service. Learn more at https://cloud.google.com/appengine."],["AvailabilityCriteria","Future parameters for the availability SLI."],["BasicAuthentication","The authentication parameters to provide to the specified resource or URL that requires a username and password. Currently, only Basic HTTP authentication (https://tools.ietf.org/html/rfc7617) is supported in Uptime checks."],["BasicSli","An SLI measuring performance on a well-known service type. Performance will be computed on the basis of pre-defined metrics. The type of the service_resource determines the metrics to use and the service_resource.labels and metric_labels are used to construct a monitoring filter to filter that metric down to just the data relevant to this service."],["BucketOptions","BucketOptions describes the bucket boundaries used to create a histogram for the distribution. The buckets can be in a linear sequence, an exponential sequence, or each bucket can be specified explicitly. BucketOptions does not include the number of values in each bucket.A bucket has an inclusive lower bound and exclusive upper bound for the values that are counted for that bucket. The upper bound of a bucket must be strictly greater than the lower bound. The sequence of N buckets for a distribution consists of an underflow bucket (number 0), zero or more finite buckets (number 1 through N - 2) and an overflow bucket (number N - 1). The buckets are contiguous: the lower bound of bucket i (i > 0) is the same as the upper bound of bucket i - 1. The buckets span the whole range of finite values: lower bound of the underflow bucket is -infinity and the upper bound of the overflow bucket is +infinity. The finite buckets are so-called because both bounds are finite."],["CloudEndpoints","Cloud Endpoints service. Learn more at https://cloud.google.com/endpoints."],["ClusterIstio","Istio service scoped to a single Kubernetes cluster. Learn more at https://istio.io. Clusters running OSS Istio will have their services ingested as this type."],["CollectdPayload","A collection of data points sent from a collectd-based plugin. See the collectd documentation for more information."],["CollectdPayloadError","Describes the error status for payloads that were not written."],["CollectdValue","A single data point from a collectd-based plugin."],["CollectdValueError","Describes the error status for values that were not written."],["Condition","A condition is a true/false test that determines when an alerting policy should open an incident. If a condition evaluates to true, it signifies that something is wrong."],["ContentMatcher","Optional. Used to perform content matching. This allows matching based on substrings and regular expressions, together with their negations. Only the first 4 MB of an HTTP or HTTPS check's response (and the first 1 MB of a TCP check's response) are examined for purposes of content matching."],["CreateCollectdTimeSeriesRequest","The CreateCollectdTimeSeries request."],["CreateCollectdTimeSeriesResponse","The CreateCollectdTimeSeries response."],["CreateTimeSeriesRequest","The CreateTimeSeries request."],["CreateTimeSeriesSummary","Summary of the result of a failed request to write data to a time series."],["Custom","Custom view of service telemetry. Currently a place-holder pending final design."],["Distribution","Distribution contains summary statistics for a population of values. It optionally contains a histogram representing the distribution of those values across a set of buckets.The summary statistics are the count, mean, sum of the squared deviation from the mean, the minimum, and the maximum of the set of population of values. The histogram is based on a sequence of buckets and gives a count of values that fall into each bucket. The boundaries of the buckets are given either explicitly or by formulas for buckets of fixed or exponentially increasing widths.Although it is not forbidden, it is generally a bad idea to include non-finite values (infinities or NaNs) in the population of values, as this will render the mean and sum_of_squared_deviation fields meaningless."],["DistributionCut","A DistributionCut defines a TimeSeries and thresholds used for measuring good service and total service. The TimeSeries must have ValueType = DISTRIBUTION and MetricKind = DELTA or MetricKind = CUMULATIVE. The computed good_service will be the count of values x in the Distribution such that range.min <= x < range.max."],["Documentation","A content string and a MIME type that describes the content string's format."],["Empty","A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); } The JSON representation for Empty is empty JSON object {}."],["Error","Detailed information about an error category."],["Exemplar","Exemplars are example points that may be used to annotate aggregated distribution values. They are metadata that gives information about a particular value added to a Distribution bucket, such as a trace ID that was active when a value was added. They may contain further information, such as a example values and timestamps, origin, etc."],["Explicit","Specifies a set of buckets with arbitrary widths.There are size(bounds) + 1 (= N) buckets. Bucket i has the following boundaries:Upper bound (0 <= i < N-1): boundsi Lower bound (1 <= i < N); boundsi - 1The bounds field must contain at least one element. If bounds has only one element, then there are no finite buckets, and that single element is the common boundary of the overflow and underflow buckets."],["Exponential","Specifies an exponential sequence of buckets that have a width that is proportional to the value of the lower bound. Each bucket represents a constant relative uncertainty on a specific value in the bucket.There are num_finite_buckets + 2 (= N) buckets. Bucket i has the following boundaries:Upper bound (0 <= i < N-1): scale * (growth_factor ^ i). Lower bound (1 <= i < N): scale * (growth_factor ^ (i - 1))."],["FolderMethods","A builder providing access to all methods supported on folder resources. It is not used directly, but through the `Monitoring` hub."],["FolderTimeSeryListCall","Lists time series that match a filter. This method does not require a Workspace."],["GetNotificationChannelVerificationCodeRequest","The GetNotificationChannelVerificationCode request."],["GetNotificationChannelVerificationCodeResponse","The GetNotificationChannelVerificationCode request."],["GoogleMonitoringV3Range","Range of numerical values, inclusive of min and exclusive of max. If the open range \"< range.max\" is desired, set range.min = -infinity. If the open range \">= range.min\" is desired, set range.max = infinity."],["Group","The description of a dynamic collection of monitored resources. Each group has a filter that is matched against monitored resources and their associated metadata. If a group's filter matches an available monitored resource, then that resource is a member of that group. Groups can contain any number of monitored resources, and each monitored resource can be a member of any number of groups.Groups can be nested in parent-child hierarchies. The parentName field identifies an optional parent for each group. If a group has a parent, then the only monitored resources available to be matched by the group's filter are the resources contained in the parent group. In other words, a group contains the monitored resources that match its filter and the filters of all the group's ancestors. A group without a parent can contain any monitored resource.For example, consider an infrastructure running a set of instances with two user-defined tags: \"environment\" and \"role\". A parent group has a filter, environment=\"production\". A child of that parent group has a filter, role=\"transcoder\". The parent group contains all instances in the production environment, regardless of their roles. The child group contains instances that have the transcoder role and are in the production environment.The monitored resources contained in a group can change at any moment, depending on what resources exist and what filters are associated with the group and its ancestors."],["HttpCheck","Information involved in an HTTP/HTTPS Uptime check request."],["InternalChecker","An internal checker allows Uptime checks to run on private/internal GCP resources."],["IstioCanonicalService","Canonical service scoped to an Istio mesh. Anthos clusters running ASM >= 1.6.8 will have their services ingested as this type."],["LabelDescriptor","A description of a label."],["LabelValue","A label value."],["LatencyCriteria","Parameters for a latency threshold SLI."],["Linear","Specifies a linear sequence of buckets that all have the same width (except overflow and underflow). Each bucket represents a constant absolute uncertainty on the specific value in the bucket.There are num_finite_buckets + 2 (= N) buckets. Bucket i has the following boundaries:Upper bound (0 <= i < N-1): offset + (width * i). Lower bound (1 <= i < N): offset + (width * (i - 1))."],["ListAlertPoliciesResponse","The protocol for the ListAlertPolicies response."],["ListGroupMembersResponse","The ListGroupMembers response."],["ListGroupsResponse","The ListGroups response."],["ListMetricDescriptorsResponse","The ListMetricDescriptors response."],["ListMonitoredResourceDescriptorsResponse","The ListMonitoredResourceDescriptors response."],["ListNotificationChannelDescriptorsResponse","The ListNotificationChannelDescriptors response."],["ListNotificationChannelsResponse","The ListNotificationChannels response."],["ListServiceLevelObjectivesResponse","The ListServiceLevelObjectives response."],["ListServicesResponse","The ListServices response."],["ListTimeSeriesResponse","The ListTimeSeries response."],["ListUptimeCheckConfigsResponse","The protocol for the ListUptimeCheckConfigs response."],["ListUptimeCheckIpsResponse","The protocol for the ListUptimeCheckIps response."],["MeshIstio","Istio service scoped to an Istio mesh. Anthos clusters running ASM < 1.6.8 will have their services ingested as this type."],["Metric","A specific metric, identified by specifying values for all of the labels of a MetricDescriptor."],["MetricAbsence","A condition type that checks that monitored resources are reporting data. The configuration defines a metric and a set of monitored resources. The predicate is considered in violation when a time series for the specified metric of a monitored resource does not include any data in the specified duration."],["MetricDescriptor","Defines a metric type and its schema. Once a metric descriptor is created, deleting or altering it stops data collection and makes the metric type's existing data unusable."],["MetricDescriptorMetadata","Additional annotations that can be used to guide the usage of a metric."],["MetricRange","A MetricRange is used when each window is good when the value x of a single TimeSeries satisfies range.min <= x < range.max. The provided TimeSeries must have ValueType = INT64 or ValueType = DOUBLE and MetricKind = GAUGE."],["MetricThreshold","A condition type that compares a collection of time series against a threshold."],["MonitoredResource","An object representing a resource that can be used for monitoring, logging, billing, or other purposes. Examples include virtual machine instances, databases, and storage devices such as disks. The type field identifies a MonitoredResourceDescriptor object that describes the resource's schema. Information in the labels field identifies the actual resource and its attributes according to the schema. For example, a particular Compute Engine VM instance could be represented by the following object, because the MonitoredResourceDescriptor for \"gce_instance\" has labels \"instance_id\" and \"zone\": { \"type\": \"gce_instance\", \"labels\": { \"instance_id\": \"12345678901234\", \"zone\": \"us-central1-a\" }} "],["MonitoredResourceDescriptor","An object that describes the schema of a MonitoredResource object using a type name and a set of labels. For example, the monitored resource descriptor for Google Compute Engine VM instances has a type of \"gce_instance\" and specifies the use of the labels \"instance_id\" and \"zone\" to identify particular VM instances.Different APIs can support different monitored resource types. APIs generally provide a list method that returns the monitored resource descriptors used by the API."],["MonitoredResourceMetadata","Auxiliary metadata for a MonitoredResource object. MonitoredResource objects contain the minimum set of information to uniquely identify a monitored resource instance. There is some other useful auxiliary metadata. Monitoring and Logging use an ingestion pipeline to extract metadata for cloud resources of all types, and store the metadata in this message."],["Monitoring","Central instance to access all Monitoring related resource activities"],["MonitoringQueryLanguageCondition","A condition type that allows alert policies to be defined using Monitoring Query Language (https://cloud.google.com/monitoring/mql)."],["MutationRecord","Describes a change made to a configuration."],["NotificationChannel","A NotificationChannel is a medium through which an alert is delivered when a policy violation is detected. Examples of channels include email, SMS, and third-party messaging applications. Fields containing sensitive information like authentication tokens or contact info are only partially populated on retrieval."],["NotificationChannelDescriptor","A description of a notification channel. The descriptor includes the properties of the channel and the set of labels or fields that must be specified to configure channels of a given type."],["OrganizationMethods","A builder providing access to all methods supported on organization resources. It is not used directly, but through the `Monitoring` hub."],["OrganizationTimeSeryListCall","Lists time series that match a filter. This method does not require a Workspace."],["PerformanceThreshold","A PerformanceThreshold is used when each window is good when that window has a sufficiently high performance."],["Point","A single data point in a time series."],["PointData","A point's value columns and time interval. Each point has one or more point values corresponding to the entries in point_descriptors field in the TimeSeriesDescriptor associated with this object."],["ProjectAlertPolicyCreateCall","Creates a new alerting policy."],["ProjectAlertPolicyDeleteCall","Deletes an alerting policy."],["ProjectAlertPolicyGetCall","Gets a single alerting policy."],["ProjectAlertPolicyListCall","Lists the existing alerting policies for the workspace."],["ProjectAlertPolicyPatchCall","Updates an alerting policy. You can either replace the entire policy with a new one or replace only certain fields in the current alerting policy by specifying the fields to be updated via updateMask. Returns the updated alerting policy."],["ProjectCollectdTimeSeryCreateCall","Stackdriver Monitoring Agent only: Creates a new time series.This method is only for use by the Stackdriver Monitoring Agent. Use projects.timeSeries.create instead."],["ProjectGroupCreateCall","Creates a new group."],["ProjectGroupDeleteCall","Deletes an existing group."],["ProjectGroupGetCall","Gets a single group."],["ProjectGroupListCall","Lists the existing groups."],["ProjectGroupMemberListCall","Lists the monitored resources that are members of a group."],["ProjectGroupUpdateCall","Updates an existing group. You can change any group attributes except name."],["ProjectMethods","A builder providing access to all methods supported on project resources. It is not used directly, but through the `Monitoring` hub."],["ProjectMetricDescriptorCreateCall","Creates a new metric descriptor. User-created metric descriptors define custom metrics (https://cloud.google.com/monitoring/custom-metrics)."],["ProjectMetricDescriptorDeleteCall","Deletes a metric descriptor. Only user-created custom metrics (https://cloud.google.com/monitoring/custom-metrics) can be deleted."],["ProjectMetricDescriptorGetCall","Gets a single metric descriptor. This method does not require a Workspace."],["ProjectMetricDescriptorListCall","Lists metric descriptors that match a filter. This method does not require a Workspace."],["ProjectMonitoredResourceDescriptorGetCall","Gets a single monitored resource descriptor. This method does not require a Workspace."],["ProjectMonitoredResourceDescriptorListCall","Lists monitored resource descriptors that match a filter. This method does not require a Workspace."],["ProjectNotificationChannelCreateCall","Creates a new notification channel, representing a single notification endpoint such as an email address, SMS number, or PagerDuty service."],["ProjectNotificationChannelDeleteCall","Deletes a notification channel."],["ProjectNotificationChannelDescriptorGetCall","Gets a single channel descriptor. The descriptor indicates which fields are expected / permitted for a notification channel of the given type."],["ProjectNotificationChannelDescriptorListCall","Lists the descriptors for supported channel types. The use of descriptors makes it possible for new channel types to be dynamically added."],["ProjectNotificationChannelGetCall","Gets a single notification channel. The channel includes the relevant configuration details with which the channel was created. However, the response may truncate or omit passwords, API keys, or other private key matter and thus the response may not be 100% identical to the information that was supplied in the call to the create method."],["ProjectNotificationChannelGetVerificationCodeCall","Requests a verification code for an already verified channel that can then be used in a call to VerifyNotificationChannel() on a different channel with an equivalent identity in the same or in a different project. This makes it possible to copy a channel between projects without requiring manual reverification of the channel. If the channel is not in the verified state, this method will fail (in other words, this may only be used if the SendNotificationChannelVerificationCode and VerifyNotificationChannel paths have already been used to put the given channel into the verified state).There is no guarantee that the verification codes returned by this method will be of a similar structure or form as the ones that are delivered to the channel via SendNotificationChannelVerificationCode; while VerifyNotificationChannel() will recognize both the codes delivered via SendNotificationChannelVerificationCode() and returned from GetNotificationChannelVerificationCode(), it is typically the case that the verification codes delivered via SendNotificationChannelVerificationCode() will be shorter and also have a shorter expiration (e.g. codes such as \"G-123456\") whereas GetVerificationCode() will typically return a much longer, websafe base 64 encoded string that has a longer expiration time."],["ProjectNotificationChannelListCall","Lists the notification channels that have been created for the project."],["ProjectNotificationChannelPatchCall","Updates a notification channel. Fields not specified in the field mask remain unchanged."],["ProjectNotificationChannelSendVerificationCodeCall","Causes a verification code to be delivered to the channel. The code can then be supplied in VerifyNotificationChannel to verify the channel."],["ProjectNotificationChannelVerifyCall","Verifies a NotificationChannel by proving receipt of the code delivered to the channel as a result of calling SendNotificationChannelVerificationCode."],["ProjectTimeSeryCreateCall","Creates or adds data to one or more time series. The response is empty if all time series in the request were written. If any time series could not be written, a corresponding failure message is included in the error response."],["ProjectTimeSeryListCall","Lists time series that match a filter. This method does not require a Workspace."],["ProjectTimeSeryQueryCall","Queries time series using Monitoring Query Language. This method does not require a Workspace."],["ProjectUptimeCheckConfigCreateCall","Creates a new Uptime check configuration."],["ProjectUptimeCheckConfigDeleteCall","Deletes an Uptime check configuration. Note that this method will fail if the Uptime check configuration is referenced by an alert policy or other dependent configs that would be rendered invalid by the deletion."],["ProjectUptimeCheckConfigGetCall","Gets a single Uptime check configuration."],["ProjectUptimeCheckConfigListCall","Lists the existing valid Uptime check configurations for the project (leaving out any invalid configurations)."],["ProjectUptimeCheckConfigPatchCall","Updates an Uptime check configuration. You can either replace the entire configuration with a new one or replace only certain fields in the current configuration by specifying the fields to be updated via updateMask. Returns the updated configuration."],["QueryTimeSeriesRequest","The QueryTimeSeries request."],["QueryTimeSeriesResponse","The QueryTimeSeries response."],["Range","The range of the population values."],["RequestBasedSli","Service Level Indicators for which atomic units of service are counted directly."],["ResourceGroup","The resource submessage for group checks. It can be used instead of a monitored resource, when multiple resources are being monitored."],["SendNotificationChannelVerificationCodeRequest","The SendNotificationChannelVerificationCode request."],["Service","A Service is a discrete, autonomous, and network-accessible unit, designed to solve an individual concern (Wikipedia (https://en.wikipedia.org/wiki/Service-orientation)). In Cloud Monitoring, a Service acts as the root resource under which operational aspects of the service are accessible."],["ServiceCreateCall","Create a Service."],["ServiceDeleteCall","Soft delete this Service."],["ServiceGetCall","Get the named Service."],["ServiceLevelIndicator","A Service-Level Indicator (SLI) describes the \"performance\" of a service. For some services, the SLI is well-defined. In such cases, the SLI can be described easily by referencing the well-known SLI and providing the needed parameters. Alternatively, a \"custom\" SLI can be defined with a query to the underlying metric store. An SLI is defined to be good_service / total_service over any queried time interval. The value of performance always falls into the range 0 <= performance <= 1. A custom SLI describes how to compute this ratio, whether this is by dividing values from a pair of time series, cutting a Distribution into good and bad counts, or counting time windows in which the service complies with a criterion. For separation of concerns, a single Service-Level Indicator measures performance for only one aspect of service quality, such as fraction of successful queries or fast-enough queries."],["ServiceLevelObjective","A Service-Level Objective (SLO) describes a level of desired good service. It consists of a service-level indicator (SLI), a performance goal, and a period over which the objective is to be evaluated against that goal. The SLO can use SLIs defined in a number of different manners. Typical SLOs might include \"99% of requests in each rolling week have latency below 200 milliseconds\" or \"99.5% of requests in each calendar month return successfully.\""],["ServiceListCall","List Services for this workspace."],["ServiceMethods","A builder providing access to all methods supported on service resources. It is not used directly, but through the `Monitoring` hub."],["ServicePatchCall","Update this Service."],["ServiceServiceLevelObjectiveCreateCall","Create a ServiceLevelObjective for the given Service."],["ServiceServiceLevelObjectiveDeleteCall","Delete the given ServiceLevelObjective."],["ServiceServiceLevelObjectiveGetCall","Get a ServiceLevelObjective by name."],["ServiceServiceLevelObjectiveListCall","List the ServiceLevelObjectives for the given Service."],["ServiceServiceLevelObjectivePatchCall","Update the given ServiceLevelObjective."],["Status","The Status type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by gRPC (https://github.com/grpc). Each Status message contains three pieces of data: error code, error message, and error details.You can find out more about this error model and how to work with it in the API Design Guide (https://cloud.google.com/apis/design/errors)."],["TcpCheck","Information required for a TCP Uptime check request."],["Telemetry","Configuration for how to query telemetry on a Service."],["TimeInterval","A closed time interval. It extends from the start time to the end time, and includes both: [startTime, endTime]. Valid time intervals depend on the MetricKind of the metric value. The end time must not be earlier than the start time. When writing data points, the start time must not be more than 25 hours in the past and the end time must not be more than five minutes in the future. For GAUGE metrics, the startTime value is technically optional; if no value is specified, the start time defaults to the value of the end time, and the interval represents a single point in time. If both start and end times are specified, they must be identical. Such an interval is valid only for GAUGE metrics, which are point-in-time measurements. The end time of a new interval must be at least a millisecond after the end time of the previous interval. For DELTA metrics, the start time and end time must specify a non-zero interval, with subsequent points specifying contiguous and non-overlapping intervals. For DELTA metrics, the start time of the next interval must be at least a millisecond after the end time of the previous interval. For CUMULATIVE metrics, the start time and end time must specify a a non-zero interval, with subsequent points specifying the same start time and increasing end times, until an event resets the cumulative value to zero and sets a new start time for the following points. The new start time must be at least a millisecond after the end time of the previous interval. The start time of a new interval must be at least a millisecond after the end time of the previous interval because intervals are closed. If the start time of a new interval is the same as the end time of the previous interval, then data written at the new start time could overwrite data written at the previous end time."],["TimeSeries","A collection of data points that describes the time-varying values of a metric. A time series is identified by a combination of a fully-specified monitored resource and a fully-specified metric. This type is used for both listing and creating time series."],["TimeSeriesData","Represents the values of a time series associated with a TimeSeriesDescriptor."],["TimeSeriesDescriptor","A descriptor for the labels and points in a time series."],["TimeSeriesRatio","A TimeSeriesRatio specifies two TimeSeries to use for computing the good_service / total_service ratio. The specified TimeSeries must have ValueType = DOUBLE or ValueType = INT64 and must have MetricKind = DELTA or MetricKind = CUMULATIVE. The TimeSeriesRatio must specify exactly two of good, bad, and total, and the relationship good_service + bad_service = total_service will be assumed."],["Trigger","Specifies how many time series must fail a predicate to trigger a condition. If not specified, then a {count: 1} trigger is used."],["TypedValue","A single strongly-typed value."],["UptimeCheckConfig","This message configures which resources and services to monitor for availability."],["UptimeCheckIp","Contains the region, location, and list of IP addresses where checkers in the location run from."],["UptimeCheckIpListCall","Returns the list of IP addresses that checkers run from"],["UptimeCheckIpMethods","A builder providing access to all methods supported on uptimeCheckIp resources. It is not used directly, but through the `Monitoring` hub."],["ValueDescriptor","A descriptor for the value columns in a data point."],["VerifyNotificationChannelRequest","The VerifyNotificationChannel request."],["WindowsBasedSli","A WindowsBasedSli defines good_service as the count of time windows for which the provided service was of good quality. Criteria for determining if service was good are embedded in the window_criterion."]]});